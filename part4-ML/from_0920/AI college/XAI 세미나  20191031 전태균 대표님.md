# XAI 세미나 : 2019/10/31 전태균 대표님

 http://research.sualab.com/introduction/2019/08/30/interpretable-machine-learning-overview-1.html

 http://research.sualab.com/introduction/2019/10/23/interpretable-machine-learning-overview-2.html  



이게 이게 맞아? 라고 물어보면 '왜?'가 꼭 필요함

모델 / 인터페이스

### Interpretability

동작 원리에 대한 명확한 설명

DNN의 내재된 정보를 사람이 해석 가능하게

1. 모델이 내가 원하는 대로 학습한다. <= 이걸 확증할 수 있다.
2. Improve / Debugging <= 취약한 부분을 더 잘 구분할 수 있다.
3. 새로운 발견
4. AI 설명해야 할 의무, 권리



사전 분석

- 설명이 쉬운 모델 : DT 등

사후 분석

- 복잡한 모델! NN
  - 문제를 단순화 시켜서 쪼개보자?
    - 모델 자체
    - 모델의 내재적 관점
    - 모델의 인풋

### Interpretation of DNN

모델을 해석하는 것

- 내부적인 표현을 이해하다
- 사람이 이해가능한 모델로 바꿔서 해석 DT
- 몇몇 샘플로 합으로
- 뉴럴이 반응하는 특정 패턴

결과를 해석하는 것

- 왜 이런 결과? : 근거



어떤 결과를 냈을 때, back prop해서 가장 많이 활성화된 맵

noise term을 추가하면서 broad한 결과가 좁혀지고, 오히려 구별하기 쉽게 됨 (DATA Gen.)

Code Space

'데이터를 어떻게 만들어야 되느냐' : DNN의 숙명



왜 이런 결과를 내었니?

attribution 큰 곳을 찾아서 모델링

- 히트맵!
- Saliency 맵이 왜 noisy? : 너무 광범위하다 정보가
- 그래서 noise를 더 넣어 좁혀준다
- Gradient의 불연속을 noise를 통해 smoothing해줌
- activation func가 saturation 안되게 처리해주자!
- negative gradient

### Evaluation & Validation Method

"어느 지점이 가장 기여를 많이 했느냐"

시각적으로 보는 Quality

실제 점수 매기는 Quantity

ROAR & KAR

특정 att 지우고 train 해서 원래꺼랑 비교

영향 큰거 놔두고 적은 것들은 지우고 train 해서 원래꺼랑 비교



Rectified Gradient!  : activation func을 변화시켜서 더 괜찮은 sliency map을 찍어보자

Thresholding!



'왜 잘 돌아가는지 제대로 설명 해 보자!'