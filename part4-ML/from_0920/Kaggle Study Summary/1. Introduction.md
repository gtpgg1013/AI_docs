09/13

## Week 1

![curriculum](.\curriculum.jpg)

- 원하면 competition host도 할 수 있다
- real : 훨씬 복잡, 다양
- competition : 데이터 전처리 / 모델링에 국한되어 있음 : 추가로 더 공부해야 하는 경우도 꽤 있긴 하지만!
- Pipeline을 확실히 구축해 기본 Baseline을 만들되, creativity를 놓치지 말라!



- Basic ML model review
  - Linear : separate by 2
  - Tree : divide and conquer : box
  - knn : implementation : closeness
  - Neural Network



- No Free Lunch Theorem

- GB
  - To get a bit closer to the destination, we train a tree to reconstruct the difference between the target function and the current predictions of an ensemble, which is called the **residual**:
  - 새로운 Tree가 앙상블의 error를 최대한 줄이는 쪽으로 학습
  - 잔차 = ideal - 이전까지의 error
  - *R*(**x**)=*f*(**x**)−*D*(**x**)



- Additional Materials and Links
  - https://www.coursera.org/learn/competitive-data-science/supplement/AgAOD/additional-materials-and-links