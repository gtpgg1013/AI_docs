{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day27_Baysian_CNN_ResNet",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gTBe-wYl98k",
        "colab_type": "text"
      },
      "source": [
        "# ResNet 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqoJ_uTflnsJ",
        "colab_type": "code",
        "outputId": "dc3aad39-0767-4828-ae09-0ab021c1b6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJnBfwBbmHSj",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9r4Fu78l0vB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "data = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = data.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jqKI0SCmEgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = test_labels.reshape(-1,1)\n",
        "train_labels = train_labels.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI-ARwaamLfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def shuffleData(images, labels):\n",
        "  tmp = np.concatenate([images.reshape(-1,28*28),labels],axis=1)\n",
        "  tmpd = pd.DataFrame(tmp).sample(frac=1)\n",
        "  ret = tmpd.values.reshape(-1,785)\n",
        "  retImg = ret[:,:-1].reshape(-1,28,28)\n",
        "  retlab = ret[:,-1].reshape(-1,1)\n",
        "  return retImg, retlab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTfpF0oUI4b6",
        "colab_type": "text"
      },
      "source": [
        "## 실제 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42232oS5CNwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def myResNet(data,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X6e9BG_qCpJ",
        "colab_type": "text"
      },
      "source": [
        "# Baysian Filter 구현 W/O library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv5aWDfKGXfB",
        "colab_type": "code",
        "outputId": "94db0dca-6f60-4735-b2f6-6f8bcdab1bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# konlpy 설치\n",
        "!apt-get update\n",
        "\n",
        "!apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "\n",
        "!pip3 install JPype1-py3\n",
        "\n",
        "!pip3 install konlpy\n",
        "\n",
        "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "import jpype\n",
        "print(jpype.isJVMStarted())\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download(\"popular\")\n",
        "\n",
        "from nltk.corpus import *\n",
        "from nltk.stem import *\n",
        "from konlpy.tag import Kkma\n",
        "from nltk.tokenize import *\n",
        "from nltk.tag import *\n",
        "import nltk\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from keras import *\n",
        "from keras.datasets import mnist\n",
        "from collections import Counter\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,622 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [65.9 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [12.3 kB]\n",
            "Get:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [29.0 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [597 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [906 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,677 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [731 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [14.2 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,257 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [10.8 kB]\n",
            "Get:24 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [805 kB]\n",
            "Fetched 6,398 kB in 6s (985 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "g++ set to manually installed.\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jre x11-utils\n",
            "The following packages will be upgraded:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "2 upgraded, 13 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 42.8 MB of archives.\n",
            "After this operation, 20.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u222-b10-1ubuntu1~18.04.1 [8,267 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u222-b10-1ubuntu1~18.04.1 [27.4 MB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u222-b10-1ubuntu1~18.04.1 [69.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u222-b10-1ubuntu1~18.04.1 [1,756 kB]\n",
            "Fetched 42.8 MB in 6s (6,788 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 131289 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Preparing to unpack .../11-openjdk-8-jdk-headless_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) over (8u212-b03-0ubuntu1.18.04.1) ...\n",
            "Preparing to unpack .../12-openjdk-8-jre-headless_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) over (8u212-b03-0ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../13-openjdk-8-jre_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../14-openjdk-8-jdk_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting JPype1-py3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n",
            "  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp36-cp36m-linux_x86_64.whl size=2684604 sha256=f0e65470663e2a286a523697b5d2f11863d11f14e3a1e0b3fb6698e406cab59c\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n",
            "Successfully built JPype1-py3\n",
            "Installing collected packages: JPype1-py3\n",
            "Successfully installed JPype1-py3-0.5.5.4\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/3d/4e983cd98d87b50b2ab0387d73fa946f745aa8164e8888a714d5129f9765/konlpy-0.5.1-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 26.1MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.5.7 (from konlpy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 29.7MB/s \n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-0.7.0 konlpy-0.5.1\n",
            "False\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06Vf-nGZmSx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "class BayesianFilter:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.words = set() # 단어 저장\n",
        "    self.word_dict = {} # 카테고리 단어 빈도수\n",
        "    self.category_dict = {} # 카테고리(광고 / 중요) 단어 빈도수\n",
        "  def split(self, text): # 어미/조사/구두점 제외, 형태소 분석\n",
        "    result = []\n",
        "    okt = Okt()\n",
        "    malist = okt.pos(text, norm=True, stem=True)\n",
        "    for word in malist:\n",
        "      exceptlist = [\"Josa\", \"Eomi\", \"Punctuation\"]\n",
        "      # 조사, 어미, 구두점 제외한 나머지 단어만 result에 저장\n",
        "      if word[1] not in exceptlist:\n",
        "        result.append(word[0])\n",
        "    return result\n",
        "  def inc_word(self, word, category):\n",
        "    # 단어를 카테고리에 추가\n",
        "    if not category in self.word_dict:\n",
        "      self.word_dict[category] = {} # {'광고':{}}\n",
        "    if not word in self.word_dict[category]:\n",
        "      self.word_dict[category][word] = 0 # {'광고':{'파격':0}}\n",
        "    self.word_dict[category][word] += 1 # {'광고':{'파격':1}}\n",
        "    self.words.add(word) # \n",
        "\n",
        "  def inc_category(self, category):\n",
        "    if not category in self.category_dict:\n",
        "      self.category_dict[category] = 0\n",
        "    self.category_dict[category] += 1\n",
        "    \n",
        "  # 예측\n",
        "  def predict(self, text):\n",
        "    pred_word_list = self.split(text)\n",
        "    ansdict = {}\n",
        "    tot_num = 0\n",
        "    for category in self.category_dict.keys():\n",
        "      tot_num += self.category_dict[category]\n",
        "    for category in self.category_dict.keys():\n",
        "      score_by_cat = 1\n",
        "      for word in pred_word_list:\n",
        "        if word not in self.word_dict[category]:\n",
        "          freq = 1\n",
        "        else :\n",
        "          freq = self.word_dict[category][word]\n",
        "        score_by_cat *= (freq / self.category_dict[category])\n",
        "      ansdict[category] = score_by_cat * (self.category_dict[category]/tot_num)\n",
        "    anslist = list(ansdict.items()) # enum list처럼 쓸 수 있음\n",
        "    anslist.sort(key=lambda x:x[1], reverse=True)\n",
        "    res = anslist[0][0]\n",
        "    scorelist = anslist\n",
        "    \n",
        "    return res, scorelist\n",
        "    \n",
        "  def fit(self, text, category):\n",
        "    word_list = self.split(text)\n",
        "    for word in word_list:\n",
        "      self.inc_word(word, category)\n",
        "    self.inc_category(category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEBQkTpo-b5",
        "colab_type": "code",
        "outputId": "8b4196de-7c2c-49db-bffe-8fb1e4fb73ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "bf = BayesianFilter()\n",
        "bf.fit(\"파격 세일 - 오늘까지만 50% 할인\", \"광고\")\n",
        "bf.fit(\"무료 쿠폰 선물 & 무료 배송\", \"광고\")\n",
        "bf.fit(\"아사히 맥주 세일\", \"광고\")\n",
        "bf.fit(\"회의 일정 확인 부탁드립니다\", \"중요\")\n",
        "bf.fit(\"오늘 일정이 없습니다\", \"중요\")\n",
        "bf.fit(\"파격 세일 - 오늘까지만 50% 할인\", \"광고\")\n",
        "bf.fit(\"쿠폰 선물 & 무료 배송\", \"광고\")\n",
        "bf.fit(\"현데계 백화점 세일\", \"광고\")\n",
        "bf.fit(\"봄과 함께 찾아온 따뜻한 신제품 소식\", \"광고\")\n",
        "bf.fit(\"인기 제품 기간 한정 세일\", \"광고\")\n",
        "bf.fit(\"오늘 일정 확인\", \"중요\")\n",
        "bf.fit(\"프로젝트 진행 상황 보고\",\"중요\")\n",
        "bf.fit(\"계약 잘 부탁드립니다\",\"중요\")\n",
        "bf.fit(\"회의 일정이 등록되었습니다.\",\"중요\")\n",
        "bf.fit(\"오늘 일정이 없습니다.\",\"중요\")\n",
        "res, scorelist = bf.predict(\"재고 정리 할인, 무료 배송\")\n",
        "print(\"결과 : \", res)\n",
        "print(scorelist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "결과 :  광고\n",
            "[('광고', 0.0001953125), ('중요', 2.776620852422601e-05)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAh68OXoHaBW",
        "colab_type": "code",
        "outputId": "1dc654da-0090-4457-9130-90ce3293f983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "res, scorelist = bf.predict(\"결과 진행 상황 보고 부탁드립니다\")\n",
        "print(\"결과 : \", res)\n",
        "print(scorelist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "결과 :  중요\n",
            "[('중요', 5.553241704845202e-05), ('광고', 1.6276041666666666e-05)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbNnl7jrkh1f",
        "colab_type": "text"
      },
      "source": [
        "# Keras 선형회귀, logistic 회귀, softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVR94v9-txvA",
        "colab_type": "text"
      },
      "source": [
        "## linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60e9WWVZknAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S17sc3Ehn_RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.arange(10) # 공부시간\n",
        "y = np.array([12,32,36,44,33,66,75,73,93,85]) # 점수\n",
        "\n",
        "# 7.5시간 공부 => 점수?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6fqquu5oWtA",
        "colab_type": "code",
        "outputId": "9e352104-604a-46a6-f723-28e5be9a5d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation='linear'))\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
        "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 570.6097 - mean_squared_error: 570.6097\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 222.0616 - mean_squared_error: 222.0616\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 212.7865 - mean_squared_error: 212.7865\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 204.5641 - mean_squared_error: 204.5641\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 197.2821 - mean_squared_error: 197.2821\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 190.8401 - mean_squared_error: 190.8401\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 185.1478 - mean_squared_error: 185.1478\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 180.1245 - mean_squared_error: 180.1245\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 175.6979 - mean_squared_error: 175.6979\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 171.8031 - mean_squared_error: 171.8031\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 168.3820 - mean_squared_error: 168.3820\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 165.3827 - mean_squared_error: 165.3827\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 162.7589 - mean_squared_error: 162.7589\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 160.4686 - mean_squared_error: 160.4686\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 158.4749 - mean_squared_error: 158.4749\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 156.7444 - mean_squared_error: 156.7444\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 155.2474 - mean_squared_error: 155.2474\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 153.9572 - mean_squared_error: 153.9572\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.8501 - mean_squared_error: 152.8501\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.9049 - mean_squared_error: 151.9049\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.1028 - mean_squared_error: 151.1028\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 150.4268 - mean_squared_error: 150.4268\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 149.8618 - mean_squared_error: 149.8618\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 149.3944 - mean_squared_error: 149.3944\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 149.0129 - mean_squared_error: 149.0129\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 148.7063 - mean_squared_error: 148.7063\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 148.4652 - mean_squared_error: 148.4652\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 148.2814 - mean_squared_error: 148.2814\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 148.1474 - mean_squared_error: 148.1474\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 148.0564 - mean_squared_error: 148.0564\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 148.0026 - mean_squared_error: 148.0026\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 147.9809 - mean_squared_error: 147.9809\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 147.9866 - mean_squared_error: 147.9866\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 148.0157 - mean_squared_error: 148.0157\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 148.0645 - mean_squared_error: 148.0645\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 148.1299 - mean_squared_error: 148.1299\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 148.2090 - mean_squared_error: 148.2090\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 148.2996 - mean_squared_error: 148.2996\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 148.3994 - mean_squared_error: 148.3994\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 148.5066 - mean_squared_error: 148.5066\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 148.6193 - mean_squared_error: 148.6193\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 148.7364 - mean_squared_error: 148.7364\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 148.8565 - mean_squared_error: 148.8565\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 148.9785 - mean_squared_error: 148.9785\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 149.1016 - mean_squared_error: 149.1016\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 149.2250 - mean_squared_error: 149.2250\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 149.3478 - mean_squared_error: 149.3478\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 149.4697 - mean_squared_error: 149.4697\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 149.5901 - mean_squared_error: 149.5901\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 149.7085 - mean_squared_error: 149.7085\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 149.8248 - mean_squared_error: 149.8248\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 149.9384 - mean_squared_error: 149.9384\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 150.0494 - mean_squared_error: 150.0494\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 150.1573 - mean_squared_error: 150.1573\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 150.2624 - mean_squared_error: 150.2624\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 150.3642 - mean_squared_error: 150.3642\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 150.4629 - mean_squared_error: 150.4629\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 150.5582 - mean_squared_error: 150.5582\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 150.6503 - mean_squared_error: 150.6503\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 150.7392 - mean_squared_error: 150.7392\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 150.8247 - mean_squared_error: 150.8247\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 150.9070 - mean_squared_error: 150.9070\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 150.9862 - mean_squared_error: 150.9862\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 151.0622 - mean_squared_error: 151.0622\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 151.1353 - mean_squared_error: 151.1353\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.2052 - mean_squared_error: 151.2052\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.2723 - mean_squared_error: 151.2723\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 151.3366 - mean_squared_error: 151.3366\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.3981 - mean_squared_error: 151.3981\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 151.4569 - mean_squared_error: 151.4569\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.5132 - mean_squared_error: 151.5132\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 151.5670 - mean_squared_error: 151.5670\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 151.6183 - mean_squared_error: 151.6183\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 151.6674 - mean_squared_error: 151.6674\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.7142 - mean_squared_error: 151.7142\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.7589 - mean_squared_error: 151.7589\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 151.8014 - mean_squared_error: 151.8014\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 151.8421 - mean_squared_error: 151.8421\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 151.8807 - mean_squared_error: 151.8807\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 151.9177 - mean_squared_error: 151.9177\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 151.9528 - mean_squared_error: 151.9528\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 151.9863 - mean_squared_error: 151.9863\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.0181 - mean_squared_error: 152.0181\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.0484 - mean_squared_error: 152.0484\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.0773 - mean_squared_error: 152.0773\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.1048 - mean_squared_error: 152.1048\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.1309 - mean_squared_error: 152.1309\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.1557 - mean_squared_error: 152.1557\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.1793 - mean_squared_error: 152.1793\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.2018 - mean_squared_error: 152.2018\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.2232 - mean_squared_error: 152.2232\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.2435 - mean_squared_error: 152.2435\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.2628 - mean_squared_error: 152.2628\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.2812 - mean_squared_error: 152.2812\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.2986 - mean_squared_error: 152.2986\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.3151 - mean_squared_error: 152.3151\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.3309 - mean_squared_error: 152.3309\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.3458 - mean_squared_error: 152.3458\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.3600 - mean_squared_error: 152.3600\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.3735 - mean_squared_error: 152.3735\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.3863 - mean_squared_error: 152.3863\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.3985 - mean_squared_error: 152.3985\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.4100 - mean_squared_error: 152.4100\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.4210 - mean_squared_error: 152.4210\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.4314 - mean_squared_error: 152.4314\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.4412 - mean_squared_error: 152.4412\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.4507 - mean_squared_error: 152.4507\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.4595 - mean_squared_error: 152.4595\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.4680 - mean_squared_error: 152.4680\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.4760 - mean_squared_error: 152.4760\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.4836 - mean_squared_error: 152.4836\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.4909 - mean_squared_error: 152.4909\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.4978 - mean_squared_error: 152.4978\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.5043 - mean_squared_error: 152.5043\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5104 - mean_squared_error: 152.5104\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.5163 - mean_squared_error: 152.5163\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5218 - mean_squared_error: 152.5218\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.5271 - mean_squared_error: 152.5271\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5321 - mean_squared_error: 152.5321\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5368 - mean_squared_error: 152.5368\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5414 - mean_squared_error: 152.5414\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5456 - mean_squared_error: 152.5456\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5496 - mean_squared_error: 152.5496\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5535 - mean_squared_error: 152.5535\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5571 - mean_squared_error: 152.5571\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.5607 - mean_squared_error: 152.5607\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.5639 - mean_squared_error: 152.5639\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5670 - mean_squared_error: 152.5670\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.5700 - mean_squared_error: 152.5700\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5728 - mean_squared_error: 152.5728\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5754 - mean_squared_error: 152.5754\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5780 - mean_squared_error: 152.5780\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5804 - mean_squared_error: 152.5804\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.5826 - mean_squared_error: 152.5826\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 152.5847 - mean_squared_error: 152.5847\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5869 - mean_squared_error: 152.5869\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5888 - mean_squared_error: 152.5888\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5906 - mean_squared_error: 152.5906\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5924 - mean_squared_error: 152.5924\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5940 - mean_squared_error: 152.5940\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5956 - mean_squared_error: 152.5956\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5971 - mean_squared_error: 152.5971\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.5985 - mean_squared_error: 152.5985\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.5997 - mean_squared_error: 152.5997\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 152.6011 - mean_squared_error: 152.6011\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6023 - mean_squared_error: 152.6023\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6034 - mean_squared_error: 152.6034\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6045 - mean_squared_error: 152.6045\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6055 - mean_squared_error: 152.6055\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6065 - mean_squared_error: 152.6065\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6074 - mean_squared_error: 152.6074\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6083 - mean_squared_error: 152.6083\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6091 - mean_squared_error: 152.6091\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6099 - mean_squared_error: 152.6099\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6106 - mean_squared_error: 152.6106\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.6113 - mean_squared_error: 152.6113\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6120 - mean_squared_error: 152.6120\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.6126 - mean_squared_error: 152.6126\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6133 - mean_squared_error: 152.6133\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6138 - mean_squared_error: 152.6138\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6143 - mean_squared_error: 152.6143\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6149 - mean_squared_error: 152.6149\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6153 - mean_squared_error: 152.6153\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.6158 - mean_squared_error: 152.6158\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 152.6163 - mean_squared_error: 152.6163\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6167 - mean_squared_error: 152.6167\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6171 - mean_squared_error: 152.6171\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6174 - mean_squared_error: 152.6174\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6178 - mean_squared_error: 152.6178\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6181 - mean_squared_error: 152.6181\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6184 - mean_squared_error: 152.6184\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6187 - mean_squared_error: 152.6187\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6191 - mean_squared_error: 152.6191\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6193 - mean_squared_error: 152.6193\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6196 - mean_squared_error: 152.6196\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6198 - mean_squared_error: 152.6198\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6201 - mean_squared_error: 152.6201\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6203 - mean_squared_error: 152.6203\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.6205 - mean_squared_error: 152.6205\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6206 - mean_squared_error: 152.6206\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6209 - mean_squared_error: 152.6209\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6211 - mean_squared_error: 152.6211\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6212 - mean_squared_error: 152.6212\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6214 - mean_squared_error: 152.6214\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6215 - mean_squared_error: 152.6215\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6216 - mean_squared_error: 152.6216\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6219 - mean_squared_error: 152.6219\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6219 - mean_squared_error: 152.6219\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6221 - mean_squared_error: 152.6221\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6222 - mean_squared_error: 152.6222\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6223 - mean_squared_error: 152.6223\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6225 - mean_squared_error: 152.6225\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6225 - mean_squared_error: 152.6225\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6225 - mean_squared_error: 152.6225\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6227 - mean_squared_error: 152.6227\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6228 - mean_squared_error: 152.6228\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6228 - mean_squared_error: 152.6228\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6229 - mean_squared_error: 152.6229\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6229 - mean_squared_error: 152.6229\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6231 - mean_squared_error: 152.6231\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6232 - mean_squared_error: 152.6232\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 152.6232 - mean_squared_error: 152.6232\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6232 - mean_squared_error: 152.6232\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6234 - mean_squared_error: 152.6234\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6233 - mean_squared_error: 152.6233\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6234 - mean_squared_error: 152.6234\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6234 - mean_squared_error: 152.6234\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6235 - mean_squared_error: 152.6235\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6235 - mean_squared_error: 152.6235\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6236 - mean_squared_error: 152.6236\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6237 - mean_squared_error: 152.6237\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6236 - mean_squared_error: 152.6236\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6236 - mean_squared_error: 152.6236\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6238 - mean_squared_error: 152.6238\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6237 - mean_squared_error: 152.6237\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6237 - mean_squared_error: 152.6237\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6238 - mean_squared_error: 152.6238\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6239 - mean_squared_error: 152.6239\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6239 - mean_squared_error: 152.6239\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6239 - mean_squared_error: 152.6239\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6239 - mean_squared_error: 152.6239\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6239 - mean_squared_error: 152.6239\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6239 - mean_squared_error: 152.6239\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6239 - mean_squared_error: 152.6239\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6240 - mean_squared_error: 152.6240\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6241 - mean_squared_error: 152.6241\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6243 - mean_squared_error: 152.6243\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6243 - mean_squared_error: 152.6243\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6243 - mean_squared_error: 152.6243\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6243 - mean_squared_error: 152.6243\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6243 - mean_squared_error: 152.6243\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6243 - mean_squared_error: 152.6243\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.6242 - mean_squared_error: 152.6242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff91804a8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiEb-Nvfp1bC",
        "colab_type": "code",
        "outputId": "7a03a8a7-e699-459e-b7a3-d6e79d787f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x, model.predict(x), 'b',x,y,'k.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff9170684a8>,\n",
              " <matplotlib.lines.Line2D at 0x7ff917068630>,\n",
              " <matplotlib.lines.Line2D at 0x7ff917068780>,\n",
              " <matplotlib.lines.Line2D at 0x7ff917068cc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8v1UQXuqThJ",
        "colab_type": "code",
        "outputId": "dc7e8213-c76e-49a1-bcb5-122cc2a5085f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(model.predict([7.5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[63.608368]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D20K0MGet1o4",
        "colab_type": "text"
      },
      "source": [
        "## logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmQD-EoHt6MV",
        "colab_type": "code",
        "outputId": "7136c4a8-54f8-4557-8c84-19045e7ff155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = np.arange(10) # 공부시간\n",
        "y = np.array([0,0,0,0,0,0,1,1,1,1]) # 점수\n",
        "\n",
        "# 7.5시간 공부 => 점수?\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 1.1632 - binary_accuracy: 0.5000\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9817 - binary_accuracy: 0.5000\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.8364 - binary_accuracy: 0.5000\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7357 - binary_accuracy: 0.5000\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6768 - binary_accuracy: 0.5000\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6461 - binary_accuracy: 0.5000\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6301 - binary_accuracy: 0.5000\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6208 - binary_accuracy: 0.6000\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6144 - binary_accuracy: 0.6000\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.6092 - binary_accuracy: 0.6000\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6047 - binary_accuracy: 0.6000\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6005 - binary_accuracy: 0.6000\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5965 - binary_accuracy: 0.6000\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5927 - binary_accuracy: 0.6000\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5889 - binary_accuracy: 0.6000\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5852 - binary_accuracy: 0.6000\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5815 - binary_accuracy: 0.6000\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.5779 - binary_accuracy: 0.7000\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5744 - binary_accuracy: 0.7000\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5709 - binary_accuracy: 0.7000\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5674 - binary_accuracy: 0.7000\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5640 - binary_accuracy: 0.7000\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5607 - binary_accuracy: 0.7000\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5574 - binary_accuracy: 0.7000\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5541 - binary_accuracy: 0.7000\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5509 - binary_accuracy: 0.7000\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5477 - binary_accuracy: 0.7000\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5445 - binary_accuracy: 0.7000\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5414 - binary_accuracy: 0.7000\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5384 - binary_accuracy: 0.7000\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5353 - binary_accuracy: 0.7000\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5324 - binary_accuracy: 0.7000\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5294 - binary_accuracy: 0.7000\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5265 - binary_accuracy: 0.7000\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5236 - binary_accuracy: 0.7000\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5208 - binary_accuracy: 0.7000\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5180 - binary_accuracy: 0.7000\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5152 - binary_accuracy: 0.8000\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5125 - binary_accuracy: 0.8000\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.5098 - binary_accuracy: 0.8000\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5072 - binary_accuracy: 0.8000\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5045 - binary_accuracy: 0.8000\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5019 - binary_accuracy: 0.8000\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4994 - binary_accuracy: 0.8000\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4969 - binary_accuracy: 0.8000\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4944 - binary_accuracy: 0.8000\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4919 - binary_accuracy: 0.8000\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4894 - binary_accuracy: 0.8000\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4870 - binary_accuracy: 0.8000\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4847 - binary_accuracy: 0.8000\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4823 - binary_accuracy: 0.8000\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4800 - binary_accuracy: 0.8000\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4777 - binary_accuracy: 0.8000\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4754 - binary_accuracy: 0.8000\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4732 - binary_accuracy: 0.8000\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4710 - binary_accuracy: 0.8000\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4688 - binary_accuracy: 0.8000\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4666 - binary_accuracy: 0.8000\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4645 - binary_accuracy: 0.8000\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4624 - binary_accuracy: 0.8000\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4603 - binary_accuracy: 0.8000\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4582 - binary_accuracy: 0.8000\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4562 - binary_accuracy: 0.8000\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4542 - binary_accuracy: 0.8000\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4522 - binary_accuracy: 0.8000\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4502 - binary_accuracy: 0.8000\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4482 - binary_accuracy: 0.8000\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4463 - binary_accuracy: 0.8000\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.4444 - binary_accuracy: 0.8000\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4425 - binary_accuracy: 0.8000\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4407 - binary_accuracy: 0.8000\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4388 - binary_accuracy: 0.8000\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4370 - binary_accuracy: 0.8000\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4352 - binary_accuracy: 0.8000\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4334 - binary_accuracy: 0.8000\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4316 - binary_accuracy: 0.8000\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4299 - binary_accuracy: 0.8000\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4282 - binary_accuracy: 0.8000\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4265 - binary_accuracy: 0.8000\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4248 - binary_accuracy: 0.8000\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4231 - binary_accuracy: 0.8000\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4214 - binary_accuracy: 0.9000\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4198 - binary_accuracy: 0.9000\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4182 - binary_accuracy: 0.9000\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4166 - binary_accuracy: 0.9000\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4150 - binary_accuracy: 0.9000\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4134 - binary_accuracy: 0.9000\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.4119 - binary_accuracy: 0.9000\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4103 - binary_accuracy: 0.9000\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4088 - binary_accuracy: 0.9000\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.4073 - binary_accuracy: 0.9000\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4058 - binary_accuracy: 0.9000\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4043 - binary_accuracy: 0.9000\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4029 - binary_accuracy: 0.9000\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4014 - binary_accuracy: 0.9000\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.4000 - binary_accuracy: 0.9000\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3986 - binary_accuracy: 0.9000\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3972 - binary_accuracy: 0.9000\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3958 - binary_accuracy: 0.9000\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3944 - binary_accuracy: 0.9000\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3930 - binary_accuracy: 0.9000\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3917 - binary_accuracy: 0.9000\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3903 - binary_accuracy: 0.9000\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3890 - binary_accuracy: 0.9000\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3877 - binary_accuracy: 0.9000\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3864 - binary_accuracy: 0.9000\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3851 - binary_accuracy: 0.9000\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3838 - binary_accuracy: 0.9000\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3826 - binary_accuracy: 0.9000\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3813 - binary_accuracy: 0.9000\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3801 - binary_accuracy: 0.9000\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3788 - binary_accuracy: 0.9000\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3776 - binary_accuracy: 0.9000\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3764 - binary_accuracy: 0.9000\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3752 - binary_accuracy: 0.9000\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3740 - binary_accuracy: 0.9000\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3728 - binary_accuracy: 0.9000\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3717 - binary_accuracy: 0.9000\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3705 - binary_accuracy: 0.9000\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3694 - binary_accuracy: 0.9000\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3682 - binary_accuracy: 0.9000\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3671 - binary_accuracy: 0.9000\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3660 - binary_accuracy: 0.9000\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3649 - binary_accuracy: 0.9000\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3638 - binary_accuracy: 0.9000\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3627 - binary_accuracy: 0.9000\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3616 - binary_accuracy: 0.9000\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3606 - binary_accuracy: 0.9000\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3595 - binary_accuracy: 0.9000\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3585 - binary_accuracy: 0.9000\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3574 - binary_accuracy: 0.9000\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3564 - binary_accuracy: 0.9000\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3554 - binary_accuracy: 0.9000\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3544 - binary_accuracy: 0.9000\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3534 - binary_accuracy: 0.9000\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3524 - binary_accuracy: 0.9000\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3514 - binary_accuracy: 0.9000\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3504 - binary_accuracy: 0.9000\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3494 - binary_accuracy: 0.9000\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3485 - binary_accuracy: 0.9000\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3475 - binary_accuracy: 0.9000\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3466 - binary_accuracy: 0.9000\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3456 - binary_accuracy: 0.9000\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3447 - binary_accuracy: 0.9000\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3437 - binary_accuracy: 0.9000\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3428 - binary_accuracy: 0.9000\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3419 - binary_accuracy: 0.9000\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3410 - binary_accuracy: 0.9000\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3401 - binary_accuracy: 0.9000\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3392 - binary_accuracy: 0.9000\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3383 - binary_accuracy: 0.9000\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3375 - binary_accuracy: 0.9000\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3366 - binary_accuracy: 0.9000\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3357 - binary_accuracy: 0.9000\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3349 - binary_accuracy: 0.9000\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3340 - binary_accuracy: 0.9000\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3332 - binary_accuracy: 0.9000\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3323 - binary_accuracy: 0.9000\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3315 - binary_accuracy: 0.9000\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3307 - binary_accuracy: 0.9000\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3299 - binary_accuracy: 0.9000\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3291 - binary_accuracy: 0.9000\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3282 - binary_accuracy: 0.9000\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3274 - binary_accuracy: 0.9000\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3266 - binary_accuracy: 0.9000\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3259 - binary_accuracy: 0.9000\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3251 - binary_accuracy: 0.9000\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3243 - binary_accuracy: 0.9000\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3235 - binary_accuracy: 0.9000\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3228 - binary_accuracy: 0.9000\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3220 - binary_accuracy: 0.9000\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3212 - binary_accuracy: 0.9000\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3205 - binary_accuracy: 0.9000\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3197 - binary_accuracy: 0.9000\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3190 - binary_accuracy: 0.9000\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3183 - binary_accuracy: 0.9000\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3175 - binary_accuracy: 0.9000\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.3168 - binary_accuracy: 0.9000\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.3161 - binary_accuracy: 0.9000\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.3154 - binary_accuracy: 0.9000\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3147 - binary_accuracy: 0.9000\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3140 - binary_accuracy: 0.9000\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3133 - binary_accuracy: 0.9000\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3126 - binary_accuracy: 0.9000\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3119 - binary_accuracy: 0.9000\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3112 - binary_accuracy: 0.9000\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3105 - binary_accuracy: 0.9000\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3098 - binary_accuracy: 0.9000\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3092 - binary_accuracy: 0.9000\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.3085 - binary_accuracy: 0.9000\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3078 - binary_accuracy: 0.9000\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3072 - binary_accuracy: 0.9000\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.3065 - binary_accuracy: 0.9000\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3059 - binary_accuracy: 0.9000\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3052 - binary_accuracy: 0.9000\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3046 - binary_accuracy: 0.9000\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3040 - binary_accuracy: 0.9000\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.3033 - binary_accuracy: 0.9000\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3027 - binary_accuracy: 0.9000\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3021 - binary_accuracy: 0.9000\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.3014 - binary_accuracy: 0.9000\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.3008 - binary_accuracy: 0.9000\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.3002 - binary_accuracy: 0.9000\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2996 - binary_accuracy: 0.9000\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2990 - binary_accuracy: 0.9000\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2984 - binary_accuracy: 0.9000\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2978 - binary_accuracy: 0.9000\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2972 - binary_accuracy: 0.9000\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2966 - binary_accuracy: 0.9000\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2960 - binary_accuracy: 0.9000\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2954 - binary_accuracy: 0.9000\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2949 - binary_accuracy: 0.9000\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2943 - binary_accuracy: 0.9000\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2937 - binary_accuracy: 0.9000\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2931 - binary_accuracy: 0.9000\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2926 - binary_accuracy: 0.9000\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2920 - binary_accuracy: 0.9000\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2915 - binary_accuracy: 0.9000\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2909 - binary_accuracy: 0.9000\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2904 - binary_accuracy: 0.9000\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2898 - binary_accuracy: 0.9000\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2893 - binary_accuracy: 0.9000\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2887 - binary_accuracy: 0.9000\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2882 - binary_accuracy: 0.9000\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2876 - binary_accuracy: 0.9000\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2871 - binary_accuracy: 0.9000\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2866 - binary_accuracy: 0.9000\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2861 - binary_accuracy: 0.9000\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2855 - binary_accuracy: 0.9000\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2850 - binary_accuracy: 0.9000\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2845 - binary_accuracy: 0.9000\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2840 - binary_accuracy: 0.9000\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2835 - binary_accuracy: 0.9000\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2830 - binary_accuracy: 0.9000\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2824 - binary_accuracy: 0.9000\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2819 - binary_accuracy: 0.9000\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2814 - binary_accuracy: 0.9000\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2809 - binary_accuracy: 0.9000\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2805 - binary_accuracy: 0.9000\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 0.2800 - binary_accuracy: 0.9000\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2795 - binary_accuracy: 0.9000\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2790 - binary_accuracy: 0.9000\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2785 - binary_accuracy: 0.9000\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2780 - binary_accuracy: 0.9000\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2775 - binary_accuracy: 0.9000\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2771 - binary_accuracy: 0.9000\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2766 - binary_accuracy: 0.9000\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2761 - binary_accuracy: 0.9000\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2757 - binary_accuracy: 0.9000\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2752 - binary_accuracy: 0.9000\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2747 - binary_accuracy: 0.9000\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2743 - binary_accuracy: 0.9000\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2738 - binary_accuracy: 0.9000\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2733 - binary_accuracy: 0.9000\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2729 - binary_accuracy: 0.9000\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2724 - binary_accuracy: 0.9000\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2720 - binary_accuracy: 0.9000\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2715 - binary_accuracy: 0.9000\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2711 - binary_accuracy: 0.9000\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2707 - binary_accuracy: 0.9000\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2702 - binary_accuracy: 0.9000\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2698 - binary_accuracy: 0.9000\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2693 - binary_accuracy: 0.9000\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2689 - binary_accuracy: 0.9000\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2685 - binary_accuracy: 0.9000\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2681 - binary_accuracy: 0.9000\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2676 - binary_accuracy: 0.9000\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2672 - binary_accuracy: 0.9000\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2668 - binary_accuracy: 0.9000\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2664 - binary_accuracy: 0.9000\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2660 - binary_accuracy: 0.9000\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2655 - binary_accuracy: 0.9000\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2651 - binary_accuracy: 0.9000\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2647 - binary_accuracy: 0.9000\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2643 - binary_accuracy: 0.9000\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.2639 - binary_accuracy: 0.9000\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2635 - binary_accuracy: 0.9000\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2631 - binary_accuracy: 0.9000\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2627 - binary_accuracy: 0.9000\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2623 - binary_accuracy: 0.9000\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.2619 - binary_accuracy: 0.9000\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2615 - binary_accuracy: 0.9000\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2611 - binary_accuracy: 0.9000\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.2607 - binary_accuracy: 0.9000\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.2603 - binary_accuracy: 0.9000\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2599 - binary_accuracy: 0.9000\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2595 - binary_accuracy: 0.9000\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2592 - binary_accuracy: 0.9000\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2588 - binary_accuracy: 0.9000\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2584 - binary_accuracy: 0.9000\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2580 - binary_accuracy: 0.9000\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2576 - binary_accuracy: 0.9000\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2573 - binary_accuracy: 0.9000\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2569 - binary_accuracy: 0.9000\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2565 - binary_accuracy: 0.9000\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2562 - binary_accuracy: 0.9000\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2558 - binary_accuracy: 0.9000\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2554 - binary_accuracy: 0.9000\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2551 - binary_accuracy: 0.9000\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2547 - binary_accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff91774f5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-GDAno-uYGJ",
        "colab_type": "code",
        "outputId": "e7805425-d3d0-4b6b-a57d-e512310a5229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x, model.predict(x), 'b',x,y,'k.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff917044dd8>,\n",
              " <matplotlib.lines.Line2D at 0x7ff917044f60>,\n",
              " <matplotlib.lines.Line2D at 0x7ff91704d0f0>,\n",
              " <matplotlib.lines.Line2D at 0x7ff91704d630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrpRYbkkuYcV",
        "colab_type": "code",
        "outputId": "92bcfba6-c97b-4aaa-bf66-7d6b0b75ea95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(model.predict([7.5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.8650446]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNTX4MrCu6CF",
        "colab_type": "code",
        "outputId": "1f12e557-ee27-4235-e591-f9f7db53a873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = np.array([[100,90,80],[55,45,36],[77,88,90]]) # 공부시간\n",
        "y = np.array([92,70,88]) # 점수\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=3, activation='linear'))\n",
        "sgd = optimizers.SGD(lr=0.00001)\n",
        "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
        "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "3/3 [==============================] - 0s 159ms/step - loss: 6675.9724 - mean_squared_error: 6675.9724\n",
            "Epoch 2/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 969.4546 - mean_squared_error: 969.4546\n",
            "Epoch 3/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 545.3950 - mean_squared_error: 545.3950\n",
            "Epoch 4/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 498.8363 - mean_squared_error: 498.8363\n",
            "Epoch 5/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 485.9105 - mean_squared_error: 485.9105\n",
            "Epoch 6/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 477.5632 - mean_squared_error: 477.5632\n",
            "Epoch 7/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 470.2123 - mean_squared_error: 470.2123\n",
            "Epoch 8/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 463.2005 - mean_squared_error: 463.2005\n",
            "Epoch 9/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 456.3790 - mean_squared_error: 456.3790\n",
            "Epoch 10/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 449.7092 - mean_squared_error: 449.7092\n",
            "Epoch 11/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 443.1798 - mean_squared_error: 443.1798\n",
            "Epoch 12/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 436.7857 - mean_squared_error: 436.7857\n",
            "Epoch 13/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 430.5240 - mean_squared_error: 430.5240\n",
            "Epoch 14/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 424.3916 - mean_squared_error: 424.3916\n",
            "Epoch 15/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 418.3859 - mean_squared_error: 418.3859\n",
            "Epoch 16/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 412.5049 - mean_squared_error: 412.5049\n",
            "Epoch 17/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 406.7452 - mean_squared_error: 406.7452\n",
            "Epoch 18/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 401.1052 - mean_squared_error: 401.1052\n",
            "Epoch 19/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 395.5819 - mean_squared_error: 395.5819\n",
            "Epoch 20/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 390.1731 - mean_squared_error: 390.1731\n",
            "Epoch 21/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 384.8771 - mean_squared_error: 384.8771\n",
            "Epoch 22/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 379.6906 - mean_squared_error: 379.6906\n",
            "Epoch 23/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 374.6122 - mean_squared_error: 374.6122\n",
            "Epoch 24/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 369.6394 - mean_squared_error: 369.6394\n",
            "Epoch 25/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 364.7701 - mean_squared_error: 364.7701\n",
            "Epoch 26/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 360.0023 - mean_squared_error: 360.0023\n",
            "Epoch 27/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 355.3340 - mean_squared_error: 355.3340\n",
            "Epoch 28/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 350.7629 - mean_squared_error: 350.7629\n",
            "Epoch 29/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 346.2875 - mean_squared_error: 346.2875\n",
            "Epoch 30/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 341.9056 - mean_squared_error: 341.9056\n",
            "Epoch 31/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 337.6152 - mean_squared_error: 337.6152\n",
            "Epoch 32/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 333.4149 - mean_squared_error: 333.4149\n",
            "Epoch 33/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 329.3023 - mean_squared_error: 329.3023\n",
            "Epoch 34/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 325.2760 - mean_squared_error: 325.2760\n",
            "Epoch 35/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 321.3343 - mean_squared_error: 321.3343\n",
            "Epoch 36/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 317.4753 - mean_squared_error: 317.4753\n",
            "Epoch 37/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 313.6974 - mean_squared_error: 313.6974\n",
            "Epoch 38/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 309.9991 - mean_squared_error: 309.9991\n",
            "Epoch 39/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 306.3784 - mean_squared_error: 306.3784\n",
            "Epoch 40/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 302.8343 - mean_squared_error: 302.8343\n",
            "Epoch 41/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 299.3648 - mean_squared_error: 299.3648\n",
            "Epoch 42/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 295.9686 - mean_squared_error: 295.9686\n",
            "Epoch 43/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 292.6441 - mean_squared_error: 292.6441\n",
            "Epoch 44/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 289.3900 - mean_squared_error: 289.3900\n",
            "Epoch 45/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 286.2047 - mean_squared_error: 286.2047\n",
            "Epoch 46/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 283.0868 - mean_squared_error: 283.0868\n",
            "Epoch 47/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 280.0353 - mean_squared_error: 280.0353\n",
            "Epoch 48/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 277.0483 - mean_squared_error: 277.0483\n",
            "Epoch 49/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 274.1250 - mean_squared_error: 274.1250\n",
            "Epoch 50/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 271.2638 - mean_squared_error: 271.2638\n",
            "Epoch 51/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 268.4634 - mean_squared_error: 268.4634\n",
            "Epoch 52/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 265.7229 - mean_squared_error: 265.7229\n",
            "Epoch 53/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 263.0408 - mean_squared_error: 263.0408\n",
            "Epoch 54/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 260.4159 - mean_squared_error: 260.4159\n",
            "Epoch 55/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 257.8472 - mean_squared_error: 257.8472\n",
            "Epoch 56/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 255.3332 - mean_squared_error: 255.3332\n",
            "Epoch 57/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 252.8735 - mean_squared_error: 252.8735\n",
            "Epoch 58/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 250.4664 - mean_squared_error: 250.4664\n",
            "Epoch 59/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 248.1108 - mean_squared_error: 248.1108\n",
            "Epoch 60/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 245.8061 - mean_squared_error: 245.8061\n",
            "Epoch 61/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 243.5507 - mean_squared_error: 243.5507\n",
            "Epoch 62/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 241.3443 - mean_squared_error: 241.3443\n",
            "Epoch 63/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 239.1851 - mean_squared_error: 239.1851\n",
            "Epoch 64/300\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 237.0728 - mean_squared_error: 237.0728\n",
            "Epoch 65/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 235.0061 - mean_squared_error: 235.0061\n",
            "Epoch 66/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 232.9841 - mean_squared_error: 232.9841\n",
            "Epoch 67/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 231.0059 - mean_squared_error: 231.0059\n",
            "Epoch 68/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 229.0707 - mean_squared_error: 229.0707\n",
            "Epoch 69/300\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 227.1775 - mean_squared_error: 227.1775\n",
            "Epoch 70/300\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 225.3254 - mean_squared_error: 225.3254\n",
            "Epoch 71/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 223.5139 - mean_squared_error: 223.5139\n",
            "Epoch 72/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 221.7416 - mean_squared_error: 221.7416\n",
            "Epoch 73/300\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 220.0083 - mean_squared_error: 220.0083\n",
            "Epoch 74/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 218.3126 - mean_squared_error: 218.3126\n",
            "Epoch 75/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 216.6542 - mean_squared_error: 216.6542\n",
            "Epoch 76/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 215.0323 - mean_squared_error: 215.0323\n",
            "Epoch 77/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 213.4457 - mean_squared_error: 213.4457\n",
            "Epoch 78/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 211.8942 - mean_squared_error: 211.8942\n",
            "Epoch 79/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 210.3768 - mean_squared_error: 210.3768\n",
            "Epoch 80/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 208.8930 - mean_squared_error: 208.8930\n",
            "Epoch 81/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 207.4418 - mean_squared_error: 207.4418\n",
            "Epoch 82/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 206.0227 - mean_squared_error: 206.0227\n",
            "Epoch 83/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 204.6351 - mean_squared_error: 204.6351\n",
            "Epoch 84/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 203.2783 - mean_squared_error: 203.2783\n",
            "Epoch 85/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 201.9516 - mean_squared_error: 201.9516\n",
            "Epoch 86/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 200.6544 - mean_squared_error: 200.6544\n",
            "Epoch 87/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 199.3862 - mean_squared_error: 199.3862\n",
            "Epoch 88/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 198.1464 - mean_squared_error: 198.1464\n",
            "Epoch 89/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 196.9342 - mean_squared_error: 196.9342\n",
            "Epoch 90/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 195.7491 - mean_squared_error: 195.7491\n",
            "Epoch 91/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 194.5907 - mean_squared_error: 194.5907\n",
            "Epoch 92/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 193.4583 - mean_squared_error: 193.4583\n",
            "Epoch 93/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 192.3513 - mean_squared_error: 192.3513\n",
            "Epoch 94/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 191.2694 - mean_squared_error: 191.2694\n",
            "Epoch 95/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 190.2119 - mean_squared_error: 190.2119\n",
            "Epoch 96/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 189.1784 - mean_squared_error: 189.1784\n",
            "Epoch 97/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 188.1683 - mean_squared_error: 188.1683\n",
            "Epoch 98/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 187.1810 - mean_squared_error: 187.1810\n",
            "Epoch 99/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 186.2163 - mean_squared_error: 186.2163\n",
            "Epoch 100/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 185.2735 - mean_squared_error: 185.2735\n",
            "Epoch 101/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 184.3524 - mean_squared_error: 184.3524\n",
            "Epoch 102/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 183.4523 - mean_squared_error: 183.4523\n",
            "Epoch 103/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 182.5729 - mean_squared_error: 182.5729\n",
            "Epoch 104/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 181.7135 - mean_squared_error: 181.7135\n",
            "Epoch 105/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 180.8742 - mean_squared_error: 180.8742\n",
            "Epoch 106/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 180.0541 - mean_squared_error: 180.0541\n",
            "Epoch 107/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 179.2529 - mean_squared_error: 179.2529\n",
            "Epoch 108/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 178.4705 - mean_squared_error: 178.4705\n",
            "Epoch 109/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 177.7062 - mean_squared_error: 177.7062\n",
            "Epoch 110/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 176.9595 - mean_squared_error: 176.9595\n",
            "Epoch 111/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 176.2304 - mean_squared_error: 176.2304\n",
            "Epoch 112/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 175.5183 - mean_squared_error: 175.5183\n",
            "Epoch 113/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 174.8230 - mean_squared_error: 174.8230\n",
            "Epoch 114/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 174.1438 - mean_squared_error: 174.1438\n",
            "Epoch 115/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 173.4807 - mean_squared_error: 173.4807\n",
            "Epoch 116/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 172.8334 - mean_squared_error: 172.8334\n",
            "Epoch 117/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 172.2014 - mean_squared_error: 172.2014\n",
            "Epoch 118/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 171.5842 - mean_squared_error: 171.5842\n",
            "Epoch 119/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 170.9818 - mean_squared_error: 170.9818\n",
            "Epoch 120/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 170.3937 - mean_squared_error: 170.3937\n",
            "Epoch 121/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 169.8197 - mean_squared_error: 169.8197\n",
            "Epoch 122/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 169.2595 - mean_squared_error: 169.2595\n",
            "Epoch 123/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 168.7128 - mean_squared_error: 168.7128\n",
            "Epoch 124/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 168.1792 - mean_squared_error: 168.1792\n",
            "Epoch 125/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 167.6586 - mean_squared_error: 167.6586\n",
            "Epoch 126/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 167.1504 - mean_squared_error: 167.1504\n",
            "Epoch 127/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 166.6548 - mean_squared_error: 166.6548\n",
            "Epoch 128/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 166.1710 - mean_squared_error: 166.1710\n",
            "Epoch 129/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 165.6993 - mean_squared_error: 165.6993\n",
            "Epoch 130/300\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 165.2390 - mean_squared_error: 165.2390\n",
            "Epoch 131/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 164.7902 - mean_squared_error: 164.7902\n",
            "Epoch 132/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 164.3523 - mean_squared_error: 164.3523\n",
            "Epoch 133/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 163.9253 - mean_squared_error: 163.9253\n",
            "Epoch 134/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 163.5090 - mean_squared_error: 163.5090\n",
            "Epoch 135/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 163.1029 - mean_squared_error: 163.1029\n",
            "Epoch 136/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 162.7071 - mean_squared_error: 162.7071\n",
            "Epoch 137/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 162.3212 - mean_squared_error: 162.3212\n",
            "Epoch 138/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 161.9449 - mean_squared_error: 161.9449\n",
            "Epoch 139/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 161.5782 - mean_squared_error: 161.5782\n",
            "Epoch 140/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 161.2208 - mean_squared_error: 161.2208\n",
            "Epoch 141/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 160.8726 - mean_squared_error: 160.8726\n",
            "Epoch 142/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 160.5332 - mean_squared_error: 160.5332\n",
            "Epoch 143/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 160.2025 - mean_squared_error: 160.2025\n",
            "Epoch 144/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 159.8803 - mean_squared_error: 159.8803\n",
            "Epoch 145/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 159.5665 - mean_squared_error: 159.5665\n",
            "Epoch 146/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 159.2607 - mean_squared_error: 159.2607\n",
            "Epoch 147/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 158.9630 - mean_squared_error: 158.9630\n",
            "Epoch 148/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 158.6728 - mean_squared_error: 158.6728\n",
            "Epoch 149/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 158.3906 - mean_squared_error: 158.3906\n",
            "Epoch 150/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 158.1157 - mean_squared_error: 158.1157\n",
            "Epoch 151/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 157.8481 - mean_squared_error: 157.8481\n",
            "Epoch 152/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 157.5877 - mean_squared_error: 157.5877\n",
            "Epoch 153/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 157.3340 - mean_squared_error: 157.3340\n",
            "Epoch 154/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 157.0874 - mean_squared_error: 157.0874\n",
            "Epoch 155/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 156.8474 - mean_squared_error: 156.8474\n",
            "Epoch 156/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 156.6139 - mean_squared_error: 156.6139\n",
            "Epoch 157/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 156.3867 - mean_squared_error: 156.3867\n",
            "Epoch 158/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 156.1657 - mean_squared_error: 156.1657\n",
            "Epoch 159/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 155.9510 - mean_squared_error: 155.9510\n",
            "Epoch 160/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 155.7419 - mean_squared_error: 155.7419\n",
            "Epoch 161/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 155.5389 - mean_squared_error: 155.5389\n",
            "Epoch 162/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 155.3415 - mean_squared_error: 155.3415\n",
            "Epoch 163/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 155.1496 - mean_squared_error: 155.1496\n",
            "Epoch 164/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 154.9633 - mean_squared_error: 154.9633\n",
            "Epoch 165/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 154.7821 - mean_squared_error: 154.7821\n",
            "Epoch 166/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 154.6062 - mean_squared_error: 154.6062\n",
            "Epoch 167/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 154.4353 - mean_squared_error: 154.4353\n",
            "Epoch 168/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 154.2695 - mean_squared_error: 154.2695\n",
            "Epoch 169/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 154.1084 - mean_squared_error: 154.1084\n",
            "Epoch 170/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 153.9520 - mean_squared_error: 153.9520\n",
            "Epoch 171/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 153.8003 - mean_squared_error: 153.8003\n",
            "Epoch 172/300\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 153.6533 - mean_squared_error: 153.6533\n",
            "Epoch 173/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 153.5105 - mean_squared_error: 153.5105\n",
            "Epoch 174/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 153.3720 - mean_squared_error: 153.3720\n",
            "Epoch 175/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 153.2378 - mean_squared_error: 153.2378\n",
            "Epoch 176/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 153.1076 - mean_squared_error: 153.1076\n",
            "Epoch 177/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.9815 - mean_squared_error: 152.9815\n",
            "Epoch 178/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.8593 - mean_squared_error: 152.8593\n",
            "Epoch 179/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.7410 - mean_squared_error: 152.7410\n",
            "Epoch 180/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.6264 - mean_squared_error: 152.6264\n",
            "Epoch 181/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.5156 - mean_squared_error: 152.5156\n",
            "Epoch 182/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.4081 - mean_squared_error: 152.4081\n",
            "Epoch 183/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.3044 - mean_squared_error: 152.3044\n",
            "Epoch 184/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.2038 - mean_squared_error: 152.2038\n",
            "Epoch 185/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 152.1066 - mean_squared_error: 152.1066\n",
            "Epoch 186/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 152.0129 - mean_squared_error: 152.0129\n",
            "Epoch 187/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 151.9221 - mean_squared_error: 151.9221\n",
            "Epoch 188/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.8345 - mean_squared_error: 151.8345\n",
            "Epoch 189/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.7499 - mean_squared_error: 151.7499\n",
            "Epoch 190/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.6681 - mean_squared_error: 151.6681\n",
            "Epoch 191/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.5895 - mean_squared_error: 151.5895\n",
            "Epoch 192/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.5135 - mean_squared_error: 151.5135\n",
            "Epoch 193/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.4402 - mean_squared_error: 151.4402\n",
            "Epoch 194/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.3698 - mean_squared_error: 151.3698\n",
            "Epoch 195/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.3018 - mean_squared_error: 151.3018\n",
            "Epoch 196/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.2363 - mean_squared_error: 151.2363\n",
            "Epoch 197/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 151.1736 - mean_squared_error: 151.1736\n",
            "Epoch 198/300\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 151.1130 - mean_squared_error: 151.1130\n",
            "Epoch 199/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 151.0550 - mean_squared_error: 151.0550\n",
            "Epoch 200/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.9991 - mean_squared_error: 150.9991\n",
            "Epoch 201/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.9456 - mean_squared_error: 150.9456\n",
            "Epoch 202/300\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 150.8943 - mean_squared_error: 150.8943\n",
            "Epoch 203/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.8450 - mean_squared_error: 150.8450\n",
            "Epoch 204/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.7977 - mean_squared_error: 150.7977\n",
            "Epoch 205/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7529 - mean_squared_error: 150.7529\n",
            "Epoch 206/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7097 - mean_squared_error: 150.7097\n",
            "Epoch 207/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.6686 - mean_squared_error: 150.6686\n",
            "Epoch 208/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.6292 - mean_squared_error: 150.6292\n",
            "Epoch 209/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.5918 - mean_squared_error: 150.5918\n",
            "Epoch 210/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.5561 - mean_squared_error: 150.5561\n",
            "Epoch 211/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.5223 - mean_squared_error: 150.5223\n",
            "Epoch 212/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.4900 - mean_squared_error: 150.4900\n",
            "Epoch 213/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.4595 - mean_squared_error: 150.4595\n",
            "Epoch 214/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.4305 - mean_squared_error: 150.4305\n",
            "Epoch 215/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.4033 - mean_squared_error: 150.4033\n",
            "Epoch 216/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3774 - mean_squared_error: 150.3774\n",
            "Epoch 217/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3531 - mean_squared_error: 150.3531\n",
            "Epoch 218/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3300 - mean_squared_error: 150.3300\n",
            "Epoch 219/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3085 - mean_squared_error: 150.3085\n",
            "Epoch 220/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.2885 - mean_squared_error: 150.2885\n",
            "Epoch 221/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2697 - mean_squared_error: 150.2697\n",
            "Epoch 222/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2522 - mean_squared_error: 150.2522\n",
            "Epoch 223/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2361 - mean_squared_error: 150.2361\n",
            "Epoch 224/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2212 - mean_squared_error: 150.2212\n",
            "Epoch 225/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 150.2074 - mean_squared_error: 150.2074\n",
            "Epoch 226/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1948 - mean_squared_error: 150.1948\n",
            "Epoch 227/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1833 - mean_squared_error: 150.1833\n",
            "Epoch 228/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1730 - mean_squared_error: 150.1730\n",
            "Epoch 229/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1637 - mean_squared_error: 150.1637\n",
            "Epoch 230/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1553 - mean_squared_error: 150.1553\n",
            "Epoch 231/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1482 - mean_squared_error: 150.1482\n",
            "Epoch 232/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1420 - mean_squared_error: 150.1420\n",
            "Epoch 233/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.1366 - mean_squared_error: 150.1366\n",
            "Epoch 234/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1323 - mean_squared_error: 150.1323\n",
            "Epoch 235/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1289 - mean_squared_error: 150.1289\n",
            "Epoch 236/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1263 - mean_squared_error: 150.1263\n",
            "Epoch 237/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.1247 - mean_squared_error: 150.1247\n",
            "Epoch 238/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1237 - mean_squared_error: 150.1237\n",
            "Epoch 239/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1236 - mean_squared_error: 150.1236\n",
            "Epoch 240/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1244 - mean_squared_error: 150.1244\n",
            "Epoch 241/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1258 - mean_squared_error: 150.1258\n",
            "Epoch 242/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1280 - mean_squared_error: 150.1280\n",
            "Epoch 243/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1309 - mean_squared_error: 150.1309\n",
            "Epoch 244/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1345 - mean_squared_error: 150.1345\n",
            "Epoch 245/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 150.1387 - mean_squared_error: 150.1387\n",
            "Epoch 246/300\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 150.1437 - mean_squared_error: 150.1437\n",
            "Epoch 247/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1490 - mean_squared_error: 150.1490\n",
            "Epoch 248/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1552 - mean_squared_error: 150.1552\n",
            "Epoch 249/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.1621 - mean_squared_error: 150.1621\n",
            "Epoch 250/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1692 - mean_squared_error: 150.1692\n",
            "Epoch 251/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1772 - mean_squared_error: 150.1772\n",
            "Epoch 252/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.1855 - mean_squared_error: 150.1855\n",
            "Epoch 253/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.1943 - mean_squared_error: 150.1943\n",
            "Epoch 254/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.2038 - mean_squared_error: 150.2038\n",
            "Epoch 255/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.2136 - mean_squared_error: 150.2136\n",
            "Epoch 256/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2239 - mean_squared_error: 150.2239\n",
            "Epoch 257/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2348 - mean_squared_error: 150.2348\n",
            "Epoch 258/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2459 - mean_squared_error: 150.2459\n",
            "Epoch 259/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.2575 - mean_squared_error: 150.2575\n",
            "Epoch 260/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.2695 - mean_squared_error: 150.2695\n",
            "Epoch 261/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.2820 - mean_squared_error: 150.2820\n",
            "Epoch 262/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.2949 - mean_squared_error: 150.2949\n",
            "Epoch 263/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3080 - mean_squared_error: 150.3080\n",
            "Epoch 264/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3216 - mean_squared_error: 150.3216\n",
            "Epoch 265/300\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 150.3353 - mean_squared_error: 150.3353\n",
            "Epoch 266/300\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 150.3495 - mean_squared_error: 150.3495\n",
            "Epoch 267/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.3640 - mean_squared_error: 150.3640\n",
            "Epoch 268/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3788 - mean_squared_error: 150.3788\n",
            "Epoch 269/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.3937 - mean_squared_error: 150.3937\n",
            "Epoch 270/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.4090 - mean_squared_error: 150.4090\n",
            "Epoch 271/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.4247 - mean_squared_error: 150.4247\n",
            "Epoch 272/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.4405 - mean_squared_error: 150.4405\n",
            "Epoch 273/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.4567 - mean_squared_error: 150.4567\n",
            "Epoch 274/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.4728 - mean_squared_error: 150.4728\n",
            "Epoch 275/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.4894 - mean_squared_error: 150.4894\n",
            "Epoch 276/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.5062 - mean_squared_error: 150.5062\n",
            "Epoch 277/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.5230 - mean_squared_error: 150.5230\n",
            "Epoch 278/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.5402 - mean_squared_error: 150.5402\n",
            "Epoch 279/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.5575 - mean_squared_error: 150.5575\n",
            "Epoch 280/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.5749 - mean_squared_error: 150.5749\n",
            "Epoch 281/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.5926 - mean_squared_error: 150.5926\n",
            "Epoch 282/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.6103 - mean_squared_error: 150.6103\n",
            "Epoch 283/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.6282 - mean_squared_error: 150.6282\n",
            "Epoch 284/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.6463 - mean_squared_error: 150.6463\n",
            "Epoch 285/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.6645 - mean_squared_error: 150.6645\n",
            "Epoch 286/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.6828 - mean_squared_error: 150.6828\n",
            "Epoch 287/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7013 - mean_squared_error: 150.7013\n",
            "Epoch 288/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7198 - mean_squared_error: 150.7198\n",
            "Epoch 289/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7385 - mean_squared_error: 150.7385\n",
            "Epoch 290/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7572 - mean_squared_error: 150.7572\n",
            "Epoch 291/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7759 - mean_squared_error: 150.7759\n",
            "Epoch 292/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.7949 - mean_squared_error: 150.7949\n",
            "Epoch 293/300\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 150.8138 - mean_squared_error: 150.8138\n",
            "Epoch 294/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.8327 - mean_squared_error: 150.8327\n",
            "Epoch 295/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.8520 - mean_squared_error: 150.8520\n",
            "Epoch 296/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.8711 - mean_squared_error: 150.8711\n",
            "Epoch 297/300\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 150.8904 - mean_squared_error: 150.8904\n",
            "Epoch 298/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.9095 - mean_squared_error: 150.9095\n",
            "Epoch 299/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.9287 - mean_squared_error: 150.9287\n",
            "Epoch 300/300\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 150.9480 - mean_squared_error: 150.9480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff917493470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKnBjOHgv5ZL",
        "colab_type": "code",
        "outputId": "0189457a-25d4-46bf-b845-a364bb142d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(model.predict(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[103.669655]\n",
            " [ 55.873928]\n",
            " [ 86.15998 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjKavaEiwryv",
        "colab_type": "text"
      },
      "source": [
        "## multi logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnij9RBJwuR2",
        "colab_type": "code",
        "outputId": "0dc69ee0-39e3-4816-abba-096aa0bc5043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = np.array([[0,0],[0,1],[1,0],[1,1]]) # 공부시간\n",
        "y = np.array([0,1,1,1]) # 점수\n",
        "\n",
        "# 7.5시간 공부 => 점수?\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=2, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.5320 - binary_accuracy: 0.7500\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5287 - binary_accuracy: 0.5000\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5256 - binary_accuracy: 0.5000\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5225 - binary_accuracy: 0.5000\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5195 - binary_accuracy: 0.5000\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5166 - binary_accuracy: 0.5000\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5137 - binary_accuracy: 0.5000\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5109 - binary_accuracy: 0.5000\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5081 - binary_accuracy: 0.5000\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5054 - binary_accuracy: 0.5000\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5028 - binary_accuracy: 0.5000\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5002 - binary_accuracy: 0.5000\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4977 - binary_accuracy: 0.5000\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4952 - binary_accuracy: 0.5000\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4928 - binary_accuracy: 0.5000\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4904 - binary_accuracy: 0.5000\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4881 - binary_accuracy: 0.5000\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4858 - binary_accuracy: 0.5000\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4836 - binary_accuracy: 0.5000\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4814 - binary_accuracy: 0.5000\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4793 - binary_accuracy: 0.5000\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4772 - binary_accuracy: 0.5000\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4751 - binary_accuracy: 0.5000\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4731 - binary_accuracy: 0.5000\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4711 - binary_accuracy: 0.5000\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4692 - binary_accuracy: 0.5000\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4673 - binary_accuracy: 0.7500\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4654 - binary_accuracy: 0.7500\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4636 - binary_accuracy: 0.7500\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4618 - binary_accuracy: 0.7500\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4600 - binary_accuracy: 0.7500\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4583 - binary_accuracy: 0.7500\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4566 - binary_accuracy: 0.7500\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4549 - binary_accuracy: 0.7500\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4532 - binary_accuracy: 0.7500\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4516 - binary_accuracy: 0.7500\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4500 - binary_accuracy: 0.7500\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4485 - binary_accuracy: 0.7500\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4469 - binary_accuracy: 0.7500\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4454 - binary_accuracy: 0.7500\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4439 - binary_accuracy: 0.7500\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4425 - binary_accuracy: 0.7500\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4410 - binary_accuracy: 0.7500\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4396 - binary_accuracy: 0.7500\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4382 - binary_accuracy: 0.7500\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4369 - binary_accuracy: 0.7500\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4355 - binary_accuracy: 0.7500\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4342 - binary_accuracy: 0.7500\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4329 - binary_accuracy: 0.7500\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4316 - binary_accuracy: 0.7500\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4303 - binary_accuracy: 0.7500\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4291 - binary_accuracy: 0.7500\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4278 - binary_accuracy: 0.7500\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4266 - binary_accuracy: 0.7500\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4254 - binary_accuracy: 0.7500\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4243 - binary_accuracy: 0.7500\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4231 - binary_accuracy: 0.7500\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4220 - binary_accuracy: 0.7500\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4208 - binary_accuracy: 0.7500\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4197 - binary_accuracy: 0.7500\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4186 - binary_accuracy: 0.7500\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4175 - binary_accuracy: 0.7500\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4165 - binary_accuracy: 0.7500\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4154 - binary_accuracy: 0.7500\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4144 - binary_accuracy: 0.7500\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4133 - binary_accuracy: 0.7500\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4123 - binary_accuracy: 0.7500\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4113 - binary_accuracy: 0.7500\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4103 - binary_accuracy: 0.7500\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4094 - binary_accuracy: 0.7500\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4084 - binary_accuracy: 0.7500\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4075 - binary_accuracy: 0.7500\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4065 - binary_accuracy: 0.7500\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4056 - binary_accuracy: 0.7500\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4047 - binary_accuracy: 0.7500\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4038 - binary_accuracy: 0.7500\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4029 - binary_accuracy: 0.7500\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4020 - binary_accuracy: 0.7500\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4011 - binary_accuracy: 0.7500\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4002 - binary_accuracy: 0.7500\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3994 - binary_accuracy: 0.7500\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3985 - binary_accuracy: 0.7500\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3977 - binary_accuracy: 0.7500\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3968 - binary_accuracy: 0.7500\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3960 - binary_accuracy: 0.7500\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3952 - binary_accuracy: 0.7500\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3944 - binary_accuracy: 0.7500\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3936 - binary_accuracy: 0.7500\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3928 - binary_accuracy: 0.7500\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3920 - binary_accuracy: 0.7500\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3913 - binary_accuracy: 0.7500\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3905 - binary_accuracy: 0.7500\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3898 - binary_accuracy: 0.7500\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3890 - binary_accuracy: 0.7500\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3883 - binary_accuracy: 0.7500\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3875 - binary_accuracy: 0.7500\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3868 - binary_accuracy: 0.7500\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3861 - binary_accuracy: 0.7500\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3854 - binary_accuracy: 0.7500\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3846 - binary_accuracy: 0.7500\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3839 - binary_accuracy: 0.7500\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3832 - binary_accuracy: 0.7500\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3826 - binary_accuracy: 0.7500\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3819 - binary_accuracy: 0.7500\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3812 - binary_accuracy: 0.7500\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3805 - binary_accuracy: 0.7500\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3799 - binary_accuracy: 0.7500\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3792 - binary_accuracy: 0.7500\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3785 - binary_accuracy: 0.7500\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3779 - binary_accuracy: 0.7500\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3772 - binary_accuracy: 0.7500\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3766 - binary_accuracy: 0.7500\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3760 - binary_accuracy: 0.7500\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3753 - binary_accuracy: 0.7500\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3747 - binary_accuracy: 0.7500\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3741 - binary_accuracy: 0.7500\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3735 - binary_accuracy: 0.7500\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3729 - binary_accuracy: 0.7500\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3722 - binary_accuracy: 0.7500\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3716 - binary_accuracy: 0.7500\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3710 - binary_accuracy: 0.7500\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3704 - binary_accuracy: 0.7500\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3699 - binary_accuracy: 0.7500\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3693 - binary_accuracy: 0.7500\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3687 - binary_accuracy: 0.7500\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3681 - binary_accuracy: 0.7500\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3675 - binary_accuracy: 0.7500\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3670 - binary_accuracy: 0.7500\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3664 - binary_accuracy: 0.7500\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3658 - binary_accuracy: 0.7500\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3653 - binary_accuracy: 0.7500\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3647 - binary_accuracy: 0.7500\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3642 - binary_accuracy: 0.7500\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3636 - binary_accuracy: 0.7500\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3631 - binary_accuracy: 0.7500\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3625 - binary_accuracy: 0.7500\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3620 - binary_accuracy: 0.7500\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3615 - binary_accuracy: 0.7500\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3609 - binary_accuracy: 0.7500\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3604 - binary_accuracy: 0.7500\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3599 - binary_accuracy: 0.7500\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3593 - binary_accuracy: 0.7500\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3588 - binary_accuracy: 0.7500\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3583 - binary_accuracy: 0.7500\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3578 - binary_accuracy: 0.7500\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3573 - binary_accuracy: 0.7500\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3568 - binary_accuracy: 0.7500\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3563 - binary_accuracy: 0.7500\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3558 - binary_accuracy: 0.7500\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3553 - binary_accuracy: 0.7500\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3548 - binary_accuracy: 0.7500\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3543 - binary_accuracy: 0.7500\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3538 - binary_accuracy: 0.7500\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3533 - binary_accuracy: 0.7500\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3528 - binary_accuracy: 0.7500\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3523 - binary_accuracy: 0.7500\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3518 - binary_accuracy: 0.7500\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3514 - binary_accuracy: 0.7500\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3509 - binary_accuracy: 0.7500\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3504 - binary_accuracy: 0.7500\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3499 - binary_accuracy: 0.7500\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3495 - binary_accuracy: 0.7500\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3490 - binary_accuracy: 0.7500\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3485 - binary_accuracy: 0.7500\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3481 - binary_accuracy: 0.7500\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3476 - binary_accuracy: 0.7500\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3471 - binary_accuracy: 0.7500\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3467 - binary_accuracy: 0.7500\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3462 - binary_accuracy: 0.7500\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3458 - binary_accuracy: 0.7500\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3453 - binary_accuracy: 0.7500\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3449 - binary_accuracy: 0.7500\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3444 - binary_accuracy: 0.7500\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3440 - binary_accuracy: 0.7500\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3435 - binary_accuracy: 0.7500\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3431 - binary_accuracy: 0.7500\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3426 - binary_accuracy: 0.7500\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3422 - binary_accuracy: 0.7500\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3418 - binary_accuracy: 0.7500\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3413 - binary_accuracy: 0.7500\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3409 - binary_accuracy: 0.7500\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3405 - binary_accuracy: 0.7500\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3400 - binary_accuracy: 0.7500\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3396 - binary_accuracy: 0.7500\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3392 - binary_accuracy: 0.7500\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3388 - binary_accuracy: 0.7500\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3383 - binary_accuracy: 0.7500\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3379 - binary_accuracy: 0.7500\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3375 - binary_accuracy: 0.7500\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3371 - binary_accuracy: 0.7500\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3367 - binary_accuracy: 0.7500\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3362 - binary_accuracy: 0.7500\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3358 - binary_accuracy: 0.7500\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3354 - binary_accuracy: 0.7500\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3350 - binary_accuracy: 0.7500\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3346 - binary_accuracy: 0.7500\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3342 - binary_accuracy: 0.7500\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3338 - binary_accuracy: 0.7500\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3334 - binary_accuracy: 0.7500\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3330 - binary_accuracy: 0.7500\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3326 - binary_accuracy: 0.7500\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3322 - binary_accuracy: 0.7500\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3318 - binary_accuracy: 0.7500\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3314 - binary_accuracy: 0.7500\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3310 - binary_accuracy: 0.7500\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3306 - binary_accuracy: 0.7500\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3302 - binary_accuracy: 0.7500\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3298 - binary_accuracy: 0.7500\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3294 - binary_accuracy: 0.7500\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3290 - binary_accuracy: 0.7500\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3286 - binary_accuracy: 0.7500\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3282 - binary_accuracy: 0.7500\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3279 - binary_accuracy: 0.7500\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3275 - binary_accuracy: 0.7500\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3271 - binary_accuracy: 0.7500\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3267 - binary_accuracy: 0.7500\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3263 - binary_accuracy: 0.7500\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3259 - binary_accuracy: 0.7500\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3256 - binary_accuracy: 0.7500\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3252 - binary_accuracy: 0.7500\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3248 - binary_accuracy: 0.7500\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3244 - binary_accuracy: 0.7500\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3241 - binary_accuracy: 0.7500\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3237 - binary_accuracy: 0.7500\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3233 - binary_accuracy: 0.7500\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3229 - binary_accuracy: 0.7500\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3226 - binary_accuracy: 0.7500\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3222 - binary_accuracy: 0.7500\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3218 - binary_accuracy: 0.7500\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3215 - binary_accuracy: 0.7500\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3211 - binary_accuracy: 0.7500\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3207 - binary_accuracy: 0.7500\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3204 - binary_accuracy: 0.7500\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3200 - binary_accuracy: 0.7500\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3196 - binary_accuracy: 0.7500\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3193 - binary_accuracy: 0.7500\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3189 - binary_accuracy: 0.7500\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3186 - binary_accuracy: 0.7500\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3182 - binary_accuracy: 0.7500\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3178 - binary_accuracy: 0.7500\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3175 - binary_accuracy: 0.7500\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3171 - binary_accuracy: 0.7500\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3168 - binary_accuracy: 0.7500\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3164 - binary_accuracy: 0.7500\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3161 - binary_accuracy: 0.7500\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3157 - binary_accuracy: 0.7500\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3154 - binary_accuracy: 0.7500\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3150 - binary_accuracy: 0.7500\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3147 - binary_accuracy: 0.7500\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3143 - binary_accuracy: 0.7500\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3140 - binary_accuracy: 0.7500\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3136 - binary_accuracy: 0.7500\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3133 - binary_accuracy: 0.7500\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3129 - binary_accuracy: 0.7500\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3126 - binary_accuracy: 0.7500\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3123 - binary_accuracy: 0.7500\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3119 - binary_accuracy: 0.7500\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3116 - binary_accuracy: 0.7500\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3112 - binary_accuracy: 0.7500\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3109 - binary_accuracy: 0.7500\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3106 - binary_accuracy: 0.7500\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3102 - binary_accuracy: 0.7500\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3099 - binary_accuracy: 0.7500\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3096 - binary_accuracy: 0.7500\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3092 - binary_accuracy: 0.7500\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3089 - binary_accuracy: 0.7500\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3086 - binary_accuracy: 0.7500\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3082 - binary_accuracy: 0.7500\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3079 - binary_accuracy: 0.7500\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3076 - binary_accuracy: 0.7500\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3072 - binary_accuracy: 0.7500\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3069 - binary_accuracy: 0.7500\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3066 - binary_accuracy: 0.7500\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3062 - binary_accuracy: 0.7500\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3059 - binary_accuracy: 0.7500\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3056 - binary_accuracy: 0.7500\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3053 - binary_accuracy: 0.7500\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3049 - binary_accuracy: 0.7500\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3046 - binary_accuracy: 0.7500\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3043 - binary_accuracy: 0.7500\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3040 - binary_accuracy: 0.7500\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3036 - binary_accuracy: 0.7500\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3033 - binary_accuracy: 0.7500\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3030 - binary_accuracy: 0.7500\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3027 - binary_accuracy: 0.7500\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3024 - binary_accuracy: 0.7500\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3020 - binary_accuracy: 0.7500\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3017 - binary_accuracy: 0.7500\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3014 - binary_accuracy: 0.7500\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3011 - binary_accuracy: 0.7500\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3008 - binary_accuracy: 0.7500\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3005 - binary_accuracy: 0.7500\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3002 - binary_accuracy: 0.7500\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2998 - binary_accuracy: 0.7500\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2995 - binary_accuracy: 0.7500\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2992 - binary_accuracy: 0.7500\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2989 - binary_accuracy: 0.7500\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2986 - binary_accuracy: 0.7500\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2983 - binary_accuracy: 0.7500\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2980 - binary_accuracy: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff9173169e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25_TyosfwMt5",
        "colab_type": "code",
        "outputId": "2e0b03ab-c70f-421c-fd82-1a5b798e21d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(model.predict(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.52548736]\n",
            " [0.8887917 ]\n",
            " [0.75451624]\n",
            " [0.95686245]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR2ZaIbNyM_g",
        "colab_type": "text"
      },
      "source": [
        "## softmax classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kzKqOxyQp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZkQEkvNf5e9",
        "colab_type": "text"
      },
      "source": [
        "# 텐서보드 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWCQBKYSVQxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 텐서 보드 생성.\n",
        "from tensorboardcolab import * \n",
        "from datetime import datetime\n",
        "\n",
        "current_time = str(datetime.now().timestamp())\n",
        "train_log_dir = 'logs/tensorboard/train/' + current_time\n",
        "\n",
        "tbc = TensorBoardColab(graph_path = train_log_dir) # To create a tensorboardcolab object it will automatically creat a link\n",
        "writer = tbc.get_writer() # To create a FileWriter\n",
        "writer.add_graph(tf.get_default_graph()) # add the graph \n",
        "writer.flush()\n",
        "\n",
        "\n",
        "## 텐서 보드 생성.\n",
        "from tensorboardcolab import * \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}