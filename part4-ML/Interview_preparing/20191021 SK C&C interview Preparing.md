# 20191021 SK C&C interview Preparing

### '행복' : 일과 행복을 연결시키는 나만의 생각?

- 일하면서 행복하게 일해야 결국 자발적으로 / 의욕적으로 할 수 있다!
- 일하면서 나의 행복을 어떻게 찾을 수 있을까?
  - 최신 기술이 끊임없이, 빠르게 범람하는 분야로 지원했다고 생각합니다. 누군가는 이러한 새로운 배움이 부담스럽고, 각자의 행복을 방해하는 것으로 생각할수도 있습니다. 그러나 저는 이러한 새로운 배움이 즐겁고, 그로 인해 더 나은것을 만들어내는 것이 크게 즐겁습니다. 그 결과 다양한 스터디에 참여하였고, 이러한 일은 제게 부담이 아닌 즐거움으로 다가왔습니다.
  - 그리고 행복은 결국 나 스스로 만족하고, 주어진 환경에 감사하며 살아가는데서 오는 것이라고 생각합니다. 비록 삶이란게 완벽한 것 하나 없고 부족한 것이 많겠지만, 그 자체에 투정하는 것이 아니라 어떻게 하면 더 편리하게 바꿀까, 그렇게 고민하며 해결해나가는 것이 삶의 또 하나의 재미라고 생각합니다.
  - 그냥 주어진 일을 기계처럼 받아서 하는 게 아니라, '이러한 업무를 이렇게 처리하는 것'이 내가 더 행복해지는 일이라는 것을 인지하는 것이 중요하다고 생각합니다.

### 'Social Value' : 사회적 가치에 기여하라!

- 새로운 광고 캠페인, '업', '짝'만 보아도 숨은 의도를 잘 알수 있습니다.
  - 문제를 문제 그 자체, 스트레스로 받아들이는 것보다, 사회와 기업이 함께 해결해나가는 '업'
  - 사회와 기업이 함께 단짝으로 짝궁처럼 해결하는 '짝'
- 이러한 가치가 SK 주식회사에서는 '인공지능 문자통역' : 쉐어톡 으로 서비스!
- 강사 말이 문자로 (STT) / 일 대 다수의 문자 서비스 지원 : 접근성 크게 향상
- 저는 이러한 부분이 진정으로 기술이 나와 사회를 행복하게 하는 중요한 요소라고 생각하였고, 이러한 일을 저도 해 낼 기대를 하며 왔습니다. 
- 기술로 기업과 사회가 더 큰 행복을 만든다는 철학, 그 철학이 저를 SK에 지원하게 된 큰 계기 중 하나입니다. 

##### 말을 하다보면 항상 '산공인데 방향을 돌렸다' 라는 식의 표현이 자연스럽게 나오던데, 이 부분은 바꾸는게 확실히 좋겠다 : 소개를 하고 대답을 할때 AtoZ로 다 말한다기보다는 담백하게 

##### **'진짜 내가 왜 이 직무를 하고 싶은지, 어떻게 준비해왔는지 대답'**



- 인공지능 에이브릴
  - 얼굴 인식 : 얼굴 detection
  - 대화 : 의도 파악 기반의 챗봇
  - WKS : watson knowledge studio : 머신러닝 알고리즘을 통해 자동 데이터 분석 / 추출
  - 음성 합성서비스 : Watson TTS
  - 음성 인식 : Watson STT



- 빅데이터 AccuInsight+
  - 빅데이터 수집 / 처리 / 분석 / 시각화 서비스 지원
  - ML modeler
  - DL modeler
  - Cloud search
  - data insight



#### 어떻게 준비하는가?

##### 면접 통과 신입사원이 말하는 중요한 면 1

자기소개서 완벽 숙지 : 각 문항 잘 준비 + 부족한 자소서는 돌려막을 수 있는 대답을 준비하자!

거울 보며 예상 질문 뽑아 : 입모양 / 표정 신경쓰며 대답

대학원이나 공부 말고 대학에 돌아가면 뭘 하고 싶어요? : 나는 뮤지컬 활동을 하는게 참 즐거웠다

회사 언제 그만둘거 같냐 : 나는 사실 늙어서까지 계속 일하는게 목표이다! 그냥 회사를 다니는 일은 10년 혹은 20년 있을 수도 있지만, 그 이후에도 계속 커리어를 개발해나가며 프리랜서로도 일하고싶다. 그리고 이 쪽 분야 일은 새로운 지식이 끊임없이 범람하고, 기술들도 너무나 빠르게 발전한다. 계속 그러한 것들을 공부하고 정복해나가며 도전적이고 진취적인 삶을 살아나가는 게 인생에서 참 중요한 요소중 하나라고 생각한다.

**프로젝트 중간에 어려웠던 점은 무엇이었고** , **내가 맡았던 일은 무엇이었는지 정확히 설명 가능히 준비!** : 하나하나 다 정리를 하고, 무엇을 물어봐도 바로 답을 할 수 있도록 완벽히 숙지

전공책이 필요한 부분이 있으면 다시 봄!

실제로 일을 잘 할 수 있는 사람 : 인재상이 사실 정해져 있다!

면접관에 따라 1분소개를 하는 => 구지 튀는 모습보다는:

​	**진솔하게 본인이 어떤 경험을 했고 / 어떤 개인 역량 향상 노력 / 어떤 노력으로 회사에 가치를 줄것인지 => 담백하게 정리해서 말하는 소개가 더 좋겠다!**



##### 면접 통과 신입사원이 말하는 중요한 면 2

제일 중요 : 어떤 일을 했는지 => 스스로 알고 정리

​	대학 생활 어떤 프로젝트 : 무슨 일 / 결과 / 무엇을 얻었는지

​	예상 질문 별로 이 질문에는 어떤 프로젝트를 이야기 해야겠다 정리!

**실패했던 경험이 무엇인가? : 공모전에서 떨어진 이유 / 실제 그 공모전에서 수상을 한 팀은 어떤 식으로 준비를 하여서 성공했는지 : '우리는 이런게 부족해서 떨어졌구나' : 실패를 분석하는 모습! 	=> 빅 콘테스트의 실패 사례도 잘 분석해서 가보자! + 수상자와 비교**

1분 자기소개 기반으로 질문이 들어왔다 : 글로벌 회사 성장 기여? (1분 자기소개도 생각을 해야되는구만!)

시간 부족 : 단순 지식보다는 프로젝트 경험에서 경험에 비중을 높여!



##### 면접 통과 신입사원이 말하는 중요한 면 3

예상 질문들 쫘-악 뽑아서 30초 분량 대답할 수 있게 정리

​	내가 어떤 사람인지 찾아나가는 과정 : 예상 답변 달달 외우기보다는 '내용 위주의 대답' 숙지

기술을 물어보는 질문 : 학교 프로젝트 / 과제 : 꼬리 + 꼬리 => 너, 기술에 관심 있는 사람이니?

해당 기술에 대해 숙지하고 있니? 아는 것은 최대한 아는 선에서 설명

내가 데이터직군인데 일단 : 객체지향 또는 데이터 기본 직무 질문들이 들어올텐데 뭘 물어볼까?

**모르는 지식을 싹 다 커버할 수는 없다 : 여태까지 했던 기술들을 내가 잘 아는 기술들을 싹 다 잘 정리해서 : 꼬리질문들을 예상하면서 담백하게, 사실 위주로 준비!**

**SK C&C 안에서 어떤 구체적인 목표를 세우고 있는지, 일에 대한 진정성?**

주변 어른들에게 말하듯이 편안한 분위기에서 얘기!

'답'이 없는 질문을 할 때가 많다 : 가끔은 본인이 아는 경우도 있지만, 어떤 태도들을 가지고 있는지!

**프로젝트를 수행하며 내가 얻은 것, 심지어 실패하였더라도!**





## 면접을 보는 이유!

- 전문 면접관이 아니다 : 대부분은 현업에서 일 하시는 팀장급
- '이런 애'가 내 밑에서 일했으면 좋겠다!
- 객관적으로 기준이 정해져 있지 않다
- '굉장히 보수적인 마인드' : 굉장히 성격 / 외모 / 무난히 : 생각보다 고지식! : 깔끔히
- 살짝 미소지음
- 말하는 분을 한명씩 쳐다보기 : 스윽-미소짓기 (계속해서~!)
- 말하는 사람의 눈을 턱 / 목 쳐다보기
- 누가 말하면 자신감있게 2초간 보기
- 자신감있게 못들었으면 : 잘 못들었는데 한번 더 말씀해주시겠어요?
- => 정중히, 그러나 당당하게
- 말하는 태도 / 인성을 사실 보려고 함 : **열정 / 패기 / 겸손함 / 자신감**
- 만약 진짜진짜 모르겠다면 : 제가 나중에 엘리베이터에서 마주쳤을 때, 다시 한번 제대로 말씀드릴 수 있도록 찾아보고 공부하도록 하겠습니다!
- 걍 까칠하게 들어오더라도 결국은 넉살있게, 웃으면서 넘길 수 있는 그런 인성, 하하, 죄송합니다! => **'표정관리'**
- '상사들의 입장에서 생각하라' : **부드럽게, 위트있게, 상사에게 도움을 줄 수 있는**
- '니 잘 모르네?' : 제가 아직 아는것도 별로 없고, 현업에서 오랫동안 일하신 분들의 내공을 따라가기엔 훨씬 못 미칠거라 생각합니다, 하지만 기회가 주어진다면 적극적으로, 열심히 배울 자신이 있습니다.
- 마지막말 : 주인정신 : 회사에서 그냥 자리지키다가 월급받아가는 사람이 아니라, 상사입장에서 '든든한' 후임이 되고싶다!
- 이 회사 너무 좋다 / 나는 존나 커서 이 회사에서 임원되는게 목표다! / 그리고 위의 두 이슈 잘 종합해서 얘기하는 것도 좋을듯!
- 무슨 일 있어도 이 회사에 남아있을 거 같다!는 이미지 남겨주기
- **쫄지말고 / 당당하고 / 그러나 남을 까진 말자**



### 자소서 기반 질문

**프로젝트 중간에 어려웠던 점은 무엇이었고** , **내가 맡았던 일은 무엇이었는지 정확히 설명 가능히 준비!** : 하나하나 다 정리를 하고, 무엇을 물어봐도 바로 답을 할 수 있도록 완벽히 숙지

**실패했던 경험이 무엇인가? : 공모전에서 떨어진 이유 / 실제 그 공모전에서 수상을 한 팀은 어떤 식으로 준비를 하여서 성공했는지 : '우리는 이런게 부족해서 떨어졌구나' : 실패를 분석하는 모습! 	=> 빅 콘테스트의 실패 사례도 잘 분석해서 가보자! + 수상자와 비교**

**모르는 지식을 싹 다 커버할 수는 없다 : 여태까지 했던 기술들을 내가 잘 아는 기술들을 싹 다 잘 정리해서 : 꼬리질문들을 예상하면서 담백하게, 사실 위주로 준비!**

**SK C&C 안에서 어떤 구체적인 목표를 세우고 있는지, 일에 대한 진정성?**

- 높은 목표 설정
  - 이제 실제로 바닥부터 구현하였으므로 내용을 정확히 이해했다.
  - 더 쉽게, 빠르게 구현하기 위해서 keras의 만들어진 모델 및 가중치까지 로드해서 학습시킬 수 있다
    - transfer learning : 훨씬 빠르고, 높은 acc를 얻으며 학습할 수 있었다.
  - 최근에 더 발전된 이미지 관련 딥러닝 알고리즘 (object detection)을 더 알아야겠다는 생각이 들어서 YoloV3에 대해서 공부함
  - Yolo v3 : yolo랑 기본아키텍쳐는 비숫 : CNN 레이어를 어떤 것을 사용했는지 정도가 다름
    - 정확하다기보다는 빠르다!
    - '알고리즘적으로' 빠르다!
    - 알고리즘 과정
      - 448 * 448 * 3 Input
      - googleNet layer 20 layer => 14 * 14 *1024
      - conv 4회
      - FC layer 2회
      - 7 * 7 * 30 => last output
    - bounding box : from 7 * 7 * 30 <= 요게 타겟데이터!
      - 맨 마지막에 7 * 7 * 30 그리드인데, 30개의 각 값이 다른 의미를 가짐
      - 앞에 5개는 상 - 하 좌표들 값
      - 5 -10개는 좌 - 우 좌표들 값
      - 나머지 20개는 number of classes
    - inference시 인접한 부분의 것 중 확률이 너무 낮으면 제거
    - 결국 grid 하나당 (x, y, w, h, c) 의 쌍이 2개이다 => 최대 하나의 사진에서 96개 검출이 한계!
    - 각 class마다 98개의 bounding box의 확률을 계산!
      - IoU 계산으로 조건에 부합하지 못하는 bounding box는 드롭!
  - loss function이 중요!
    - x,y 끼리 mse / w,h 끼리 rmse / grid 안에 obj가 있을 확률 mse / grid 안에 obj가 없을 확률 mse / class 값끼리도 mse
    - regression 으로 나는 그냥 풀었다 (cross entropy 안쓰고)
- 기존의 틀을 깨는 과감한 실행 
  - 일단 그냥 진짜 돈을 보내주거나, 식량을 보내주는 것이 아닌, '식량을 만드는 시설'을 우리가 직접 만들어서 보내줄 수 있었다는 점이 상당히 기존의 틀을 깨는, 새로운 도전이었다.
  - 양배추, 양상추, 토마토의 수확을 올렸다
  - 핸드펌프 사용
  - 액체 비료를 사용함
  - 솜을 사용
  - 가장 중요했던 부분은 외국인 친구들과 영어로 커뮤니케이션하면서 타협점을 만들면서 좋은 결과를 냈다는 것이라고 생각합니다.
  - 미국에서 기본적인 수경재배 방법은 전기를 이용하는 모터를 사용하는 것으로 고정관념이 잡혀 있었는데, 이를 간단히 포기하고 차선책을 빠르게 선택한 것이 참 좋았던 부분이라 생각합니다.
- 빅 콘테스트 : 챔피언 리그
  - 게임 데이터를 이용해서 이탈 유저와 평균 결제액을 예측하는 프로젝트
  - EDA 및 Feature Engineering
    - 전투 / 지출 / 혈맹 / 거래 / 활동 등으로 나누어져 있는 테이블을 하나로 합침
    - Null data는 implementation 함 id별 average / group별 average 등 기준
    - EDA를 하던 도중 : 40000명의 data 중 오직 0.065%의 사람이 매출의 11%를 차지하고 있음!
      - 모델을 구축할 때 타겟 레이블의 편향이 매우 큼을 인지함
    - knn, kmeans 머신러닝 혹은 평균, 중간값 등으로 NaN을 보간함
    - 데이터의 feature를 하나하나 시각화하여 특성을 분석하려고 노력함
    - 모델링 (LSTM)에 너무 집중하여 실제 더 중요한 데이터를 더 등한시했다
    - 정형 데이터 컴페티션에는 사실 부스팅 계열의 머신러닝 알고리즘이 더 강력한 경우가 많다

### 자소서 / 경험에서 부족한 내용 추가





### 예상 질문 LIST





### Kaggle 수업에서 배운 ML 기본개념 정리

- 보팅 / 부스팅 / 스태킹
- TP / TN / FP / FN : T / F는 실제로 맞췄느냐, 못맞췄느냐 : P / N 은 예측값이 어떻게 나왔느냐
- Accuracy : 그냥 정확도 : TP + TN / TP + TN + FP + FN
- Precision : 모델이 True라고 분류한 것 중 실제 True의 비율 : TP / TP + FP
- Recall : 실제 True 중 모델이 True라고 예측한 것의 비율 : TP / TP + FN
- Precision이나 Recall은 모두 실제 True인 정답을 모델이 True라고 예측한 경우에 관심이 있으나, 바라보고자 하는 관점만 다름 => Precision (모델 입장) / Recall (실제 정답(data)입장)
  - 확실한 날만 맞다고 하면 precision은 올라가겠지만 그게 의미가 있나?
    - ex: 20일 비옴, 그 중 이틀은 특정한 날 확신. 그 두날만 하면 100% => meaningless
  - 그래서 Recall도 같이 고려해야 함
  - Acc가 좋긴 하나, data의 domain이 불균형하면 성능지표로 부적합!
    - 비 오는거 예측하는데 그 지역이 비가 엄청 안오는 곳이다. 의미가 있는가? => 노의미
  - **그래서 Precision과 Recall 조화평균 => F1 score**
- ROC curve
  - TPR : True Positive Rate : 민감도 : 1인 케이스에 대해 1로 잘 예측한 반응
  - FPR : False Positivie Rate : 1-특이도 : 0인 케이스에 대해 1로 잘못 예측한 반응
  - ROC curve가 위로 볼록할수록 잘못 예측하는 확률이 낮으면서 잘 예측하는 확률은 높은 것이기 때문에 좋은 모델! => 그래서 AUC 구해서 모델의 Metric으로 사용 가능
- 언제 l1, l2 정규화 각각 사용하는가?
  - l1-> 변수 각각에 걸리는 가중치 중 일부가 아예 0이 되어버리길 원할 때 (그래서 feature selection으로도 사용됨)
  - l2-> 변수 각각에 걸리는 가중치 전부가 엇비슷하게 되길 바랄때 (튀는 값이 없도록; shrinkage method)
  - https://images.app.goo.gl/5pEwP9EhHRcwz73d9

