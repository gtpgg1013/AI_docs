{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AqQ8HrwAamhl",
    "outputId": "39ff1d71-cf30-4a01-a698-69740b81b252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GsPSo8VonyN"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDJkCMdhot4r"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "7JR-RIS-o2tA",
    "outputId": "7f0c4c13-1580-44d1-d3c4-7963d3c61536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-bYg56XEpEYS",
    "outputId": "71f67e7e-5594-4c72-a8d1-a400ffd1d50c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gUEby7Qpcy1"
   },
   "outputs": [],
   "source": [
    "from keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Rv4ZH3Hpi6k"
   },
   "outputs": [],
   "source": [
    "# 모델 작성\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation=\"relu\", input_shape=(28*28,)))\n",
    "# (28*28,) 맨 뒤에 , 붙여줘야 여러 이미지 받는다는 뜻\n",
    "network.add(layers.Dense(10, activation=\"softmax\")) # 맨 위의 놈만 input_shape쓰면 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYiFtAgqrC9y"
   },
   "outputs": [],
   "source": [
    "# 훈련(컴파일)\n",
    "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SoOWLCchsSqf",
    "outputId": "d0d7fec3-6e63-4468-d850-570abc84bf58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화 : cost를 최소화하는 방향으로 parameter를 업데이트하는 것\n",
    "# 1. 경사하강법 : Gradient Descent : 기울기 * 학습률(lr) => 가중치 갱신\n",
    "# 2. 모멘텀 : 운동량, 속도 크면 => 기울기 크게 업데이트\n",
    "# 3. AdaGrad : 제곱 => 개선 : RMSProp : 새로운 기울기만 학습에 반영!\n",
    "# 4. Adam(모멘텀+AdaGrad\n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IjDG_XJyuk4"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000,28*28))\n",
    "test_images = test_images.reshape((10000,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2nythrQCy-ff",
    "outputId": "ab7ea2c4-ff37-4280-8c49-7ab8577c3a6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udAF8nSpwjNH"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vHg7YrK2wutM",
    "outputId": "7ec77ef7-961b-42ac-ff1c-8f6a10cf6f83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTx-jxjzxJPS"
   },
   "outputs": [],
   "source": [
    "test_images = test_images.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUVjflk9x78D"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "tLxKwV90yFP8",
    "outputId": "e95395d8-abbd-4bd4-d9c9-f4fe7b269993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(train_labels) # OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPUY3O-_yGq5"
   },
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4AffzJXQ2odr",
    "outputId": "b8d96aba-f50a-4727-e8b1-6803a773e29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 8.6449e-04 - acc: 0.9998\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 9.0543e-04 - acc: 0.9999\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 7.0941e-04 - acc: 0.9999\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 7.0627e-04 - acc: 0.9999\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 5.3789e-04 - acc: 0.9999\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 5.6440e-04 - acc: 0.9999\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 4.2609e-04 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 4.3466e-04 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 4.7352e-04 - acc: 0.9999\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 3.9167e-04 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.4569e-04 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 4.0648e-04 - acc: 0.9999\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.0081e-04 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.4191e-04 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.1833e-04 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.7459e-04 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2.7652e-04 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.7608e-04 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.0089e-04 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.7041e-04 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.7031e-04 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.6895e-04 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.6879e-04 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.6877e-04 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.6877e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1ae54be10>"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Lu9G8K1pyQpK",
    "outputId": "bb6a1405-9ca4-4753-beb6-fea88409795c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/step\n"
     ]
    }
   ],
   "source": [
    "test_cost, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ajLNUMyjyeI-",
    "outputId": "c9828c9e-409d-401a-c39a-98b5a2ca9bb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12605582723021377"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nf5loGsd259x",
    "outputId": "dd938146-a946-4a37-e2c1-1b846ecbb606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc\n",
    "# 총 45epoch를 해서 training data는 완전 fitting 되었지만, test data는 accuracy가 잘 안올가누.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "6Loi7A8k26_J",
    "outputId": "8d4799aa-29bd-4c3a-ad74-5450dcb76cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "\r",
      "0% [Waiting for headers] [1 InRelease 2,586 B/88.7 kB 3%] [Connecting to cloud.\r",
      "                                                                               \r",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "\r",
      "0% [1 InRelease 34.4 kB/88.7 kB 39%] [Connecting to cloud.r-project.org] [Conne\r",
      "                                                                               \r",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "\r",
      "                                                                               \r",
      "Get:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "\r",
      "0% [3 InRelease 17.1 kB/88.7 kB 19%] [1 InRelease 34.4 kB/88.7 kB 39%] [Connect\r",
      "0% [2 InRelease gpgv 242 kB] [3 InRelease 20.0 kB/88.7 kB 23%] [1 InRelease 40.\r",
      "                                                                               \r",
      "Hit:5 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "\r",
      "0% [2 InRelease gpgv 242 kB] [3 InRelease 46.0 kB/88.7 kB 52%] [1 InRelease 85.\r",
      "0% [2 InRelease gpgv 242 kB] [3 InRelease 51.8 kB/88.7 kB 58%] [Connecting to c\r",
      "0% [2 InRelease gpgv 242 kB] [Connecting to cloud.r-project.org] [Waiting for h\r",
      "                                                                               \r",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "\r",
      "0% [2 InRelease gpgv 242 kB] [6 InRelease 12.7 kB/74.6 kB 17%] [Connecting to c\r",
      "0% [2 InRelease gpgv 242 kB] [Connecting to cloud.r-project.org] [Waiting for h\r",
      "                                                                               \r",
      "Ign:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "\r",
      "0% [2 InRelease gpgv 242 kB] [Connecting to cloud.r-project.org] [Waiting for h\r",
      "                                                                               \r",
      "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "\r",
      "0% [2 InRelease gpgv 242 kB] [8 InRelease 3,626 B/3,626 B 100%] [Waiting for he\r",
      "                                                                               \r",
      "0% [2 InRelease gpgv 242 kB] [Waiting for headers]\r",
      "                                                  \r",
      "0% [Waiting for headers]\r",
      "0% [4 InRelease gpgv 21.3 kB] [Waiting for headers]\r",
      "                                                   \r",
      "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "\r",
      "                                                   \r",
      "0% [4 InRelease gpgv 21.3 kB]\r",
      "                             \r",
      "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "\r",
      "0% [4 InRelease gpgv 21.3 kB]\r",
      "                             \r",
      "Get:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
      "\r",
      "0% [4 InRelease gpgv 21.3 kB] [11 Release 564 B/564 B 100%]\r",
      "                                                           \r",
      "0% [4 InRelease gpgv 21.3 kB]\r",
      "                             \r",
      "Get:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
      "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [29.0 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [730 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [597 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [906 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [10.8 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [14.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,256 kB]\n",
      "Get:21 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [12.3 kB]\n",
      "Fetched 3,834 kB in 2s (2,080 kB/s)\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "# konlpy 설치\n",
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VCOPZFlW9YuH",
    "outputId": "bc08098b-54c3-4bdf-ad98-8bfd5272d010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python-dev is already the newest version (2.7.15~rc1-1).\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "g++ set to manually installed.\n",
      "python3-dev is already the newest version (3.6.7-1~18.04).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-410\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
      "  openjdk-8-jre-headless x11-utils\n",
      "Suggested packages:\n",
      "  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jre x11-utils\n",
      "The following packages will be upgraded:\n",
      "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
      "2 upgraded, 13 newly installed, 0 to remove and 33 not upgraded.\n",
      "Need to get 42.8 MB of archives.\n",
      "After this operation, 20.3 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u222-b10-1ubuntu1~18.04.1 [8,267 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u222-b10-1ubuntu1~18.04.1 [27.4 MB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u222-b10-1ubuntu1~18.04.1 [69.3 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u222-b10-1ubuntu1~18.04.1 [1,756 kB]\n",
      "Fetched 42.8 MB in 1s (66.1 MB/s)\n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "(Reading database ... 131289 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+3build1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
      "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libgtk2.0-common.\n",
      "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
      "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-0:amd64.\n",
      "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail18:amd64.\n",
      "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail-common:amd64.\n",
      "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-bin.\n",
      "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Preparing to unpack .../11-openjdk-8-jdk-headless_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) over (8u212-b03-0ubuntu1.18.04.1) ...\n",
      "Preparing to unpack .../12-openjdk-8-jre-headless_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) over (8u212-b03-0ubuntu1.18.04.1) ...\n",
      "Selecting previously unselected package openjdk-8-jre:amd64.\n",
      "Preparing to unpack .../13-openjdk-8-jre_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
      "Preparing to unpack .../14-openjdk-8-jdk_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
      "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Setting up fonts-dejavu-extra (2.37-1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
      "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
      "Setting up x11-utils (7.7+3build1) ...\n",
      "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Setting up openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
      "Setting up openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install g++ openjdk-8-jdk python-dev python3-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "tJXLBgRL9e0Z",
    "outputId": "b1d1f6bc-a389-4b76-c69c-63bdb494d640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting JPype1-py3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 7.4MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n",
      "  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp36-cp36m-linux_x86_64.whl size=2693094 sha256=0e5da098c7d190a10d3d9287c4e2af050b77b2c4cc712830f57fe377f09c7a1a\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n",
      "Successfully built JPype1-py3\n",
      "Installing collected packages: JPype1-py3\n",
      "Successfully installed JPype1-py3-0.5.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install JPype1-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "qTKCs-T_9nc9",
    "outputId": "ac3d9556-9f65-43b2-8b05-4a4823c50550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/3d/4e983cd98d87b50b2ab0387d73fa946f745aa8164e8888a714d5129f9765/konlpy-0.5.1-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 6.5MB/s \n",
      "\u001b[?25hCollecting JPype1>=0.5.7 (from konlpy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7MB 33.1MB/s \n",
      "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-0.7.0 konlpy-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_wSvuBx91BH"
   },
   "outputs": [],
   "source": [
    "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "y7-dILZb93QD",
    "outputId": "d27af781-d912-4f7a-9fee-ca76872b7fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import jpype\n",
    "print(jpype.isJVMStarted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78mKsPuU989M"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "colab_type": "code",
    "id": "Nq5rCaOP-ELF",
    "outputId": "07d04992-bb34-4b01-ea00-698a0d369039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1GhRW7LRVnoY",
    "outputId": "eea2b1b8-f14a-4b5d-d209-d62b23ae2a39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "FnoWWhT0-7Y4",
    "outputId": "a96abc19-3f99-4b7f-8a3c-76527ebc75d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'are', 'you', '?']\n",
      "['Do', \"n't\", 'touch', 'me']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(\"How are you?\"))\n",
    "print(word_tokenize(\"Don't touch me\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "VThsy6GeYeAL",
    "outputId": "cfa176c9-3ec9-44d6-8191-7c2926a0e74b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'are', 'you', '?']\n",
      "['Don', \"'\", 't', 'touch', 'me']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "print(WordPunctTokenizer().tokenize(\"How are you?\"))\n",
    "print(WordPunctTokenizer().tokenize(\"Don't touch me\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "rQIT-IrQVWON",
    "outputId": "fffd8450-1f83-44ef-d61e-3c95ecb6f730"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/jpype/_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('아버지', 'Noun'), ('가방', 'Noun'), ('에', 'Josa'), ('들어가신다', 'Verb')]"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "okt.pos(\"아버지 가방에 들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "ZHyTsx1lWzb7",
    "outputId": "4a2ba2c7-31be-4b8b-ba6f-b0ecdf2871b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아버지', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('방', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('들어가신다', 'Verb')]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(\"아버지가 방에 들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "v8qAtYvrXGWh",
    "outputId": "cfa0ab4f-204c-4df9-d3b6-4ac54878cd69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '도', '지각', '하지', '않고', '열심히', '공부', '한', '여러분', ',', '이번', '주도', '힘냅시다']\n",
      "['오늘', '도', '지각', '하', '지', '않', '고', '열심히', '공부', '하', 'ㄴ', '여러분', ',', '이번', '주도', '힘내', 'ㅂ시다']\n",
      "****************************************\n",
      "[('오늘', 'Noun'), ('도', 'Josa'), ('지각', 'Noun'), ('하지', 'Verb'), ('않고', 'Verb'), ('열심히', 'Adverb'), ('공부', 'Noun'), ('한', 'Josa'), ('여러분', 'Noun'), (',', 'Punctuation'), ('이번', 'Noun'), ('주도', 'Noun'), ('힘냅시다', 'Verb')]\n",
      "****************************************\n",
      "['오늘', '지각', '공부', '여러분', '이번', '주도']\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kma = Kkma()\n",
    "\n",
    "print(okt.morphs(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번주도 힘냅시다\"))\n",
    "print(kma.morphs(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번주도 힘냅시다\"))\n",
    "print(\"*\"*40)\n",
    "print(okt.pos(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번주도 힘냅시다\"))\n",
    "print(\"*\"*40)\n",
    "print(okt.nouns(\"오늘도 지각하지 않고 열심히 공부한 여러분, 이번주도 힘냅시다\"))\n",
    "print(\"*\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apBoST4Ycu47"
   },
   "outputs": [],
   "source": [
    "# 대소문자 통합, 불용어 제거(대체), 특수문자 처리\n",
    "# training, train, trains\n",
    "# are, is, was, were => be\n",
    "# 정규표현식\n",
    "# 형태소 : 어간(stem) + 접사\n",
    "# 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_wy8V0r3kV7e",
    "outputId": "d493409a-9065-4749-c70d-e0fe2a1c2381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have\n",
      "be\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "# text 전처리에서 많이 쓰임!\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "print(wnl.lemmatize(\"has\",\"v\"))\n",
    "print(wnl.lemmatize(\"were\",\"v\"))\n",
    "print(wnl.lemmatize(\"was\",\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYukoK4mkn8A"
   },
   "outputs": [],
   "source": [
    "text = \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[27]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "Lisx6jUVlNW6",
    "outputId": "4a4b34b0-a56d-4a09-8c81-38ce818ea841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'an', 'interpreted', ',', 'high-level', ',', 'general-purpose', 'programming', 'language', '.', 'Created', 'by', 'Guido', 'van', 'Rossum', 'and', 'first', 'released', 'in', '1991', ',', 'Python', \"'s\", 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'its', 'notable', 'use', 'of', 'significant', 'whitespace', '.', 'Its', 'language', 'constructs', 'and', 'object-oriented', 'approach', 'aim', 'to', 'help', 'programmers', 'write', 'clear', ',', 'logical', 'code', 'for', 'small', 'and', 'large-scale', 'projects', '.', '[', '27', ']']\n",
      "==============================\n",
      "['python', 'is', 'an', 'interpret', ',', 'high-level', ',', 'general-purpos', 'program', 'languag', '.', 'creat', 'by', 'guido', 'van', 'rossum', 'and', 'first', 'releas', 'in', '1991', ',', 'python', \"'s\", 'design', 'philosophi', 'emphas', 'code', 'readabl', 'with', 'it', 'notabl', 'use', 'of', 'signific', 'whitespac', '.', 'it', 'languag', 'construct', 'and', 'object-ori', 'approach', 'aim', 'to', 'help', 'programm', 'write', 'clear', ',', 'logic', 'code', 'for', 'small', 'and', 'large-scal', 'project', '.', '[', '27', ']']\n"
     ]
    }
   ],
   "source": [
    "# 포터 알고리즘(어간추출)\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "words = word_tokenize(text)\n",
    "print(words)\n",
    "print(\"=\"*30)\n",
    "pswords = [ps.stem(w) for w in words]\n",
    "print(pswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "MAxkU-x4lcT7",
    "outputId": "cc9ada37-67de-4989-d256-b7006b947209"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'need',\n",
       " 'your',\n",
       " 'help',\n",
       " '.',\n",
       " 'I',\n",
       " 'like',\n",
       " 'coding',\n",
       " '.',\n",
       " 'What',\n",
       " \"'s\",\n",
       " 'your',\n",
       " 'hobby']"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "test = \"I need your help. I like coding. What's your hobby\"\n",
    "test = word_tokenize(test)\n",
    "test\n",
    "# stopword에 있는거 빼고싶다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsaaMu6Nmnuu"
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for w in test:\n",
    "  if w not in sw:\n",
    "    res.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ztgZOWnuny5F",
    "outputId": "13baf8ab-5a54-4b12-bb04-43c297b763e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'need', 'help', '.', 'I', 'like', 'coding', '.', 'What', \"'s\", 'hobby']"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HXeF_u_rnzQy",
    "outputId": "b0f33f79-d6c0-45c6-ee37-3a398898e5ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['열심히', '하기싫어', '싫거든', '안해']"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = \"열심히 하기싫어 싫거든 안해\"\n",
    "test = \"파이썬 코딩을 열심히 해야합니다. 하기싫어도 해요. 그래도 싫거든 하세요 안해 안해 안해\"\n",
    "sw = sw.split(\" \")\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAByF19Coldz"
   },
   "outputs": [],
   "source": [
    "test = word_tokenize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-LIt-pnosxV"
   },
   "outputs": [],
   "source": [
    "res2 = []\n",
    "for w in test:\n",
    "  if w not in sw:\n",
    "    res2.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1_Yp94wSo7fY",
    "outputId": "d19e77be-922d-4c1a-a5d9-529bd28914f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['파이썬', '코딩을', '해야합니다', '.', '하기싫어도', '해요', '.', '그래도', '하세요']"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nk6TEEOco8Jm"
   },
   "outputs": [],
   "source": [
    "# ranksnl이라는 한국어 불용어 사전도 존재한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cA8NhF0KqD3q"
   },
   "outputs": [],
   "source": [
    "# 정수 인코딩 : tf_idf table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "YUj8mswWqKjW",
    "outputId": "ff12e0ea-1d77-4e50-80f2-029742e89fb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[27]\""
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPFhWyU4qL4e"
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "test = text.split(\" \")\n",
    "\n",
    "worddic = {}\n",
    "for word in test:\n",
    "  word = word.lower()\n",
    "  if len(word) > 2:\n",
    "    if word not in sw:\n",
    "      if word in worddic:\n",
    "        worddic[word] += 1\n",
    "      else:\n",
    "        worddic[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "id": "r7pSY_Qyqoqn",
    "outputId": "3f31f8dc-4042-4304-a530-d493520b5fa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1991,': 1,\n",
       " 'aim': 1,\n",
       " 'approach': 1,\n",
       " 'clear,': 1,\n",
       " 'code': 2,\n",
       " 'constructs': 1,\n",
       " 'created': 1,\n",
       " 'design': 1,\n",
       " 'emphasizes': 1,\n",
       " 'first': 1,\n",
       " 'general-purpose': 1,\n",
       " 'guido': 1,\n",
       " 'help': 1,\n",
       " 'high-level,': 1,\n",
       " 'interpreted,': 1,\n",
       " 'language': 1,\n",
       " 'language.': 1,\n",
       " 'large-scale': 1,\n",
       " 'logical': 1,\n",
       " 'notable': 1,\n",
       " 'object-oriented': 1,\n",
       " 'philosophy': 1,\n",
       " 'programmers': 1,\n",
       " 'programming': 1,\n",
       " 'projects.[27]': 1,\n",
       " 'python': 1,\n",
       " \"python's\": 1,\n",
       " 'readability': 1,\n",
       " 'released': 1,\n",
       " 'rossum': 1,\n",
       " 'significant': 1,\n",
       " 'small': 1,\n",
       " 'use': 1,\n",
       " 'van': 1,\n",
       " 'whitespace.': 1,\n",
       " 'write': 1}"
      ]
     },
     "execution_count": 154,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worddic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzIVFDsFrK6g"
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "test = word_tokenize(text)\n",
    "\n",
    "worddic = {}\n",
    "for word in test:\n",
    "  word = word.lower()\n",
    "  if len(word) > 2:\n",
    "    if word not in sw:\n",
    "      if word in worddic:\n",
    "        worddic[word] += 1\n",
    "      else:\n",
    "        worddic[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "0l0sW3kErX5a",
    "outputId": "758002fa-1cc9-47a9-b888-0aed16d9c212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1991': 1,\n",
       " 'aim': 1,\n",
       " 'approach': 1,\n",
       " 'clear': 1,\n",
       " 'code': 2,\n",
       " 'constructs': 1,\n",
       " 'created': 1,\n",
       " 'design': 1,\n",
       " 'emphasizes': 1,\n",
       " 'first': 1,\n",
       " 'general-purpose': 1,\n",
       " 'guido': 1,\n",
       " 'help': 1,\n",
       " 'high-level': 1,\n",
       " 'interpreted': 1,\n",
       " 'language': 2,\n",
       " 'large-scale': 1,\n",
       " 'logical': 1,\n",
       " 'notable': 1,\n",
       " 'object-oriented': 1,\n",
       " 'philosophy': 1,\n",
       " 'programmers': 1,\n",
       " 'programming': 1,\n",
       " 'projects': 1,\n",
       " 'python': 2,\n",
       " 'readability': 1,\n",
       " 'released': 1,\n",
       " 'rossum': 1,\n",
       " 'significant': 1,\n",
       " 'small': 1,\n",
       " 'use': 1,\n",
       " 'van': 1,\n",
       " 'whitespace': 1,\n",
       " 'write': 1}"
      ]
     },
     "execution_count": 156,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worddic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ll-gLDcr3gx"
   },
   "outputs": [],
   "source": [
    "summary = \"\"\n",
    "with open(\"/content/summary.txt\", 'r') as f:\n",
    "  summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "U5v3YaZMvQ7Y",
    "outputId": "5a925915-372b-4f2a-ebd6-bfa5ffe02138"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffWinston Smith is a low-ranking member of the ruling Party in London, in the nation of Oceania. Everywhere Winston goes, even his own home, the Party watches him through telescreens; everywhere he looks he sees the face of the Party’s seemingly omniscient leader, a figure known only as Big Brother. The Party controls everything in Oceania, even the people’s history and language. Currently, the Party is forcing the implementation of an invented language called Newspeak, which attempts to prevent political rebellion by eliminating all words related to it. Even thinking rebellious thoughts is illegal. Such thoughtcrime is, in fact, the worst of all crimes.\\n\\nAs the novel opens, Winston feels frustrated by the oppression and rigid control of the Party, which prohibits free thought, sex, and any expression of individuality. Winston dislikes the party and has illegally purchased a diary in which to write his criminal thoughts. He has also become fixated on a powerful Party member named O’Brien, whom Winston believes is a secret member of the Brotherhood—the mysterious, legendary group that works to overthrow the Party.\\n\\nWinston works in the Ministry of Truth, where he alters historical records to fit the needs of the Party. He notices a coworker, a beautiful dark-haired girl, staring at him, and worries that she is an informant who will turn him in for his thoughtcrime. He is troubled by the Party’s control of history: the Party claims that Oceania has always been allied with Eastasia in a war against Eurasia, but Winston seems to recall a time when this was not true. The Party also claims that Emmanuel Goldstein, the alleged leader of the Brotherhood, is the most dangerous man alive, but this does not seem plausible to Winston. Winston spends his evenings wandering through the poorest neighborhoods in London, where the proletarians, or proles, live squalid lives, relatively free of Party monitoring.\\n\\nOne day, Winston receives a note from the dark-haired girl that reads “I love you.” She tells him her name, Julia, and they begin a covert affair, always on the lookout for signs of Party monitoring. Eventually they rent a room above the secondhand store in the prole district where Winston bought the diary. This relationship lasts for some time. Winston is sure that they will be caught and punished sooner or later (the fatalistic Winston knows that he has been doomed since he wrote his first diary entry), while Julia is more pragmatic and optimistic. As Winston’s affair with Julia progresses, his hatred for the Party grows more and more intense. At last, he receives the message that he has been waiting for: O’Brien wants to see him.\\n\\nWinston and Julia travel to O’Brien’s luxurious apartment. As a member of the powerful Inner Party (Winston belongs to the Outer Party), O’Brien leads a life of luxury that Winston can only imagine. O’Brien confirms to Winston and Julia that, like them, he hates the Party, and says that he works against it as a member of the Brotherhood. He indoctrinates Winston and Julia into the Brotherhood, and gives Winston a copy of Emmanuel Goldstein’s book, the manifesto of the Brotherhood. Winston reads the book—an amalgam of several forms of class-based twentieth-century social theory—to Julia in the room above the store. Suddenly, soldiers barge in and seize them. Mr. Charrington, the proprietor of the store, is revealed as having been a member of the Thought Police all along.\\n\\nTorn away from Julia and taken to a place called the Ministry of Love, Winston finds that O’Brien, too, is a Party spy who simply pretended to be a member of the Brotherhood in order to trap Winston into committing an open act of rebellion against the Party. O’Brien spends months torturing and brainwashing Winston, who struggles to resist. At last, O’Brien sends him to the dreaded Room 101, the final destination for anyone who opposes the Party. Here, O’Brien tells Winston that he will be forced to confront his worst fear. Throughout the novel, Winston has had recurring nightmares about rats; O’Brien now straps a cage full of rats onto Winston’s head and prepares to allow the rats to eat his face. Winston snaps, pleading with O’Brien to do it to Julia, not to him.\\n\\nGiving up Julia is what O’Brien wanted from Winston all along. His spirit broken, Winston is released to the outside world. He meets Julia but no longer feels anything for her. He has accepted the Party entirely and has learned to love Big Brother.'"
      ]
     },
     "execution_count": 163,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Dm65dfOvSdI"
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "test = word_tokenize(summary)\n",
    "\n",
    "worddic = {}\n",
    "for word in test:\n",
    "  word = word.lower()\n",
    "  if len(word) > 2:\n",
    "    if word not in sw:\n",
    "      if word in worddic:\n",
    "        worddic[word] += 1\n",
    "      else:\n",
    "        worddic[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J5B3pAUsvY-9",
    "outputId": "5eb7c766-4a43-4a53-acb2-e0405ddbf953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'101': 1,\n",
       " 'accepted': 1,\n",
       " 'act': 1,\n",
       " 'affair': 2,\n",
       " 'alive': 1,\n",
       " 'alleged': 1,\n",
       " 'allied': 1,\n",
       " 'allow': 1,\n",
       " 'along': 2,\n",
       " 'also': 2,\n",
       " 'alters': 1,\n",
       " 'always': 2,\n",
       " 'amalgam': 1,\n",
       " 'anyone': 1,\n",
       " 'anything': 1,\n",
       " 'apartment': 1,\n",
       " 'attempts': 1,\n",
       " 'away': 1,\n",
       " 'barge': 1,\n",
       " 'beautiful': 1,\n",
       " 'become': 1,\n",
       " 'begin': 1,\n",
       " 'believes': 1,\n",
       " 'belongs': 1,\n",
       " 'big': 2,\n",
       " 'book': 1,\n",
       " 'book—an': 1,\n",
       " 'bought': 1,\n",
       " 'brainwashing': 1,\n",
       " 'brien': 12,\n",
       " 'broken': 1,\n",
       " 'brother': 2,\n",
       " 'brotherhood': 5,\n",
       " 'brotherhood—the': 1,\n",
       " 'cage': 1,\n",
       " 'called': 2,\n",
       " 'caught': 1,\n",
       " 'charrington': 1,\n",
       " 'claims': 2,\n",
       " 'class-based': 1,\n",
       " 'committing': 1,\n",
       " 'confirms': 1,\n",
       " 'confront': 1,\n",
       " 'control': 2,\n",
       " 'controls': 1,\n",
       " 'copy': 1,\n",
       " 'covert': 1,\n",
       " 'coworker': 1,\n",
       " 'crimes': 1,\n",
       " 'criminal': 1,\n",
       " 'currently': 1,\n",
       " 'dangerous': 1,\n",
       " 'dark-haired': 2,\n",
       " 'day': 1,\n",
       " 'destination': 1,\n",
       " 'diary': 3,\n",
       " 'dislikes': 1,\n",
       " 'district': 1,\n",
       " 'doomed': 1,\n",
       " 'dreaded': 1,\n",
       " 'eastasia': 1,\n",
       " 'eat': 1,\n",
       " 'eliminating': 1,\n",
       " 'emmanuel': 2,\n",
       " 'entirely': 1,\n",
       " 'entry': 1,\n",
       " 'eurasia': 1,\n",
       " 'even': 3,\n",
       " 'evenings': 1,\n",
       " 'eventually': 1,\n",
       " 'everything': 1,\n",
       " 'everywhere': 2,\n",
       " 'expression': 1,\n",
       " 'face': 2,\n",
       " 'fact': 1,\n",
       " 'fatalistic': 1,\n",
       " 'fear': 1,\n",
       " 'feels': 2,\n",
       " 'figure': 1,\n",
       " 'final': 1,\n",
       " 'finds': 1,\n",
       " 'first': 1,\n",
       " 'fit': 1,\n",
       " 'fixated': 1,\n",
       " 'forced': 1,\n",
       " 'forcing': 1,\n",
       " 'forms': 1,\n",
       " 'free': 2,\n",
       " 'frustrated': 1,\n",
       " 'full': 1,\n",
       " 'girl': 2,\n",
       " 'gives': 1,\n",
       " 'giving': 1,\n",
       " 'goes': 1,\n",
       " 'goldstein': 2,\n",
       " 'group': 1,\n",
       " 'grows': 1,\n",
       " 'hates': 1,\n",
       " 'hatred': 1,\n",
       " 'head': 1,\n",
       " 'historical': 1,\n",
       " 'history': 2,\n",
       " 'home': 1,\n",
       " 'illegal': 1,\n",
       " 'illegally': 1,\n",
       " 'imagine': 1,\n",
       " 'implementation': 1,\n",
       " 'individuality': 1,\n",
       " 'indoctrinates': 1,\n",
       " 'informant': 1,\n",
       " 'inner': 1,\n",
       " 'intense': 1,\n",
       " 'invented': 1,\n",
       " 'julia': 11,\n",
       " 'known': 1,\n",
       " 'knows': 1,\n",
       " 'language': 2,\n",
       " 'last': 2,\n",
       " 'lasts': 1,\n",
       " 'later': 1,\n",
       " 'leader': 2,\n",
       " 'leads': 1,\n",
       " 'learned': 1,\n",
       " 'legendary': 1,\n",
       " 'life': 1,\n",
       " 'like': 1,\n",
       " 'live': 1,\n",
       " 'lives': 1,\n",
       " 'london': 2,\n",
       " 'longer': 1,\n",
       " 'lookout': 1,\n",
       " 'looks': 1,\n",
       " 'love': 3,\n",
       " 'low-ranking': 1,\n",
       " 'luxurious': 1,\n",
       " 'luxury': 1,\n",
       " 'man': 1,\n",
       " 'manifesto': 1,\n",
       " 'meets': 1,\n",
       " 'member': 7,\n",
       " 'message': 1,\n",
       " 'ministry': 2,\n",
       " 'monitoring': 2,\n",
       " 'months': 1,\n",
       " 'mr.': 1,\n",
       " 'mysterious': 1,\n",
       " 'name': 1,\n",
       " 'named': 1,\n",
       " 'nation': 1,\n",
       " 'needs': 1,\n",
       " 'neighborhoods': 1,\n",
       " 'newspeak': 1,\n",
       " 'nightmares': 1,\n",
       " 'note': 1,\n",
       " 'notices': 1,\n",
       " 'novel': 2,\n",
       " 'oceania': 3,\n",
       " 'omniscient': 1,\n",
       " 'one': 1,\n",
       " 'onto': 1,\n",
       " 'open': 1,\n",
       " 'opens': 1,\n",
       " 'opposes': 1,\n",
       " 'oppression': 1,\n",
       " 'optimistic': 1,\n",
       " 'order': 1,\n",
       " 'outer': 1,\n",
       " 'outside': 1,\n",
       " 'overthrow': 1,\n",
       " 'party': 23,\n",
       " 'people': 1,\n",
       " 'place': 1,\n",
       " 'plausible': 1,\n",
       " 'pleading': 1,\n",
       " 'police': 1,\n",
       " 'political': 1,\n",
       " 'poorest': 1,\n",
       " 'powerful': 2,\n",
       " 'pragmatic': 1,\n",
       " 'prepares': 1,\n",
       " 'pretended': 1,\n",
       " 'prevent': 1,\n",
       " 'progresses': 1,\n",
       " 'prohibits': 1,\n",
       " 'prole': 1,\n",
       " 'proles': 1,\n",
       " 'proletarians': 1,\n",
       " 'proprietor': 1,\n",
       " 'punished': 1,\n",
       " 'purchased': 1,\n",
       " 'rats': 3,\n",
       " 'reads': 2,\n",
       " 'rebellion': 2,\n",
       " 'rebellious': 1,\n",
       " 'recall': 1,\n",
       " 'receives': 2,\n",
       " 'records': 1,\n",
       " 'recurring': 1,\n",
       " 'related': 1,\n",
       " 'relationship': 1,\n",
       " 'relatively': 1,\n",
       " 'released': 1,\n",
       " 'rent': 1,\n",
       " 'resist': 1,\n",
       " 'revealed': 1,\n",
       " 'rigid': 1,\n",
       " 'room': 3,\n",
       " 'ruling': 1,\n",
       " 'says': 1,\n",
       " 'secondhand': 1,\n",
       " 'secret': 1,\n",
       " 'see': 1,\n",
       " 'seem': 1,\n",
       " 'seemingly': 1,\n",
       " 'seems': 1,\n",
       " 'sees': 1,\n",
       " 'seize': 1,\n",
       " 'sends': 1,\n",
       " 'several': 1,\n",
       " 'sex': 1,\n",
       " 'signs': 1,\n",
       " 'simply': 1,\n",
       " 'since': 1,\n",
       " 'smith': 1,\n",
       " 'snaps': 1,\n",
       " 'social': 1,\n",
       " 'soldiers': 1,\n",
       " 'sooner': 1,\n",
       " 'spends': 2,\n",
       " 'spirit': 1,\n",
       " 'spy': 1,\n",
       " 'squalid': 1,\n",
       " 'staring': 1,\n",
       " 'store': 3,\n",
       " 'straps': 1,\n",
       " 'struggles': 1,\n",
       " 'suddenly': 1,\n",
       " 'sure': 1,\n",
       " 'taken': 1,\n",
       " 'telescreens': 1,\n",
       " 'tells': 2,\n",
       " 'theory—to': 1,\n",
       " 'thinking': 1,\n",
       " 'thought': 2,\n",
       " 'thoughtcrime': 2,\n",
       " 'thoughts': 2,\n",
       " 'throughout': 1,\n",
       " 'time': 2,\n",
       " 'torn': 1,\n",
       " 'torturing': 1,\n",
       " 'trap': 1,\n",
       " 'travel': 1,\n",
       " 'troubled': 1,\n",
       " 'true': 1,\n",
       " 'truth': 1,\n",
       " 'turn': 1,\n",
       " 'twentieth-century': 1,\n",
       " 'waiting': 1,\n",
       " 'wandering': 1,\n",
       " 'wanted': 1,\n",
       " 'wants': 1,\n",
       " 'war': 1,\n",
       " 'watches': 1,\n",
       " 'winston': 29,\n",
       " 'words': 1,\n",
       " 'works': 3,\n",
       " 'world': 1,\n",
       " 'worries': 1,\n",
       " 'worst': 2,\n",
       " 'write': 1,\n",
       " 'wrote': 1,\n",
       " 'you.': 1,\n",
       " '\\ufeffwinston': 1}"
      ]
     },
     "execution_count": 171,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worddic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIubMpFEv3sh"
   },
   "outputs": [],
   "source": [
    "ans = list(worddic.items()).sort(key=lambda x:x[1])\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SNFB3SSxByz"
   },
   "outputs": [],
   "source": [
    "tmp = list(worddic.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTl38FcJxUD5"
   },
   "outputs": [],
   "source": [
    "tmp.sort(key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Io5p70aKxCI_",
    "outputId": "47931119-b62d-4e53-c420-a60d8c3c8ef3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('winston', 29),\n",
       " ('party', 23),\n",
       " ('brien', 12),\n",
       " ('julia', 11),\n",
       " ('member', 7),\n",
       " ('brotherhood', 5),\n",
       " ('oceania', 3),\n",
       " ('even', 3),\n",
       " ('diary', 3),\n",
       " ('works', 3),\n",
       " ('love', 3),\n",
       " ('room', 3),\n",
       " ('store', 3),\n",
       " ('rats', 3),\n",
       " ('london', 2),\n",
       " ('everywhere', 2),\n",
       " ('face', 2),\n",
       " ('leader', 2),\n",
       " ('big', 2),\n",
       " ('brother', 2),\n",
       " ('history', 2),\n",
       " ('language', 2),\n",
       " ('called', 2),\n",
       " ('rebellion', 2),\n",
       " ('thoughts', 2),\n",
       " ('thoughtcrime', 2),\n",
       " ('worst', 2),\n",
       " ('novel', 2),\n",
       " ('feels', 2),\n",
       " ('control', 2),\n",
       " ('free', 2),\n",
       " ('thought', 2),\n",
       " ('also', 2),\n",
       " ('powerful', 2),\n",
       " ('ministry', 2),\n",
       " ('dark-haired', 2),\n",
       " ('girl', 2),\n",
       " ('claims', 2),\n",
       " ('always', 2),\n",
       " ('time', 2),\n",
       " ('emmanuel', 2),\n",
       " ('goldstein', 2),\n",
       " ('spends', 2),\n",
       " ('monitoring', 2),\n",
       " ('receives', 2),\n",
       " ('reads', 2),\n",
       " ('tells', 2),\n",
       " ('affair', 2),\n",
       " ('last', 2),\n",
       " ('along', 2),\n",
       " ('\\ufeffwinston', 1),\n",
       " ('smith', 1),\n",
       " ('low-ranking', 1),\n",
       " ('ruling', 1),\n",
       " ('nation', 1),\n",
       " ('goes', 1),\n",
       " ('home', 1),\n",
       " ('watches', 1),\n",
       " ('telescreens', 1),\n",
       " ('looks', 1),\n",
       " ('sees', 1),\n",
       " ('seemingly', 1),\n",
       " ('omniscient', 1),\n",
       " ('figure', 1),\n",
       " ('known', 1),\n",
       " ('controls', 1),\n",
       " ('everything', 1),\n",
       " ('people', 1),\n",
       " ('currently', 1),\n",
       " ('forcing', 1),\n",
       " ('implementation', 1),\n",
       " ('invented', 1),\n",
       " ('newspeak', 1),\n",
       " ('attempts', 1),\n",
       " ('prevent', 1),\n",
       " ('political', 1),\n",
       " ('eliminating', 1),\n",
       " ('words', 1),\n",
       " ('related', 1),\n",
       " ('thinking', 1),\n",
       " ('rebellious', 1),\n",
       " ('illegal', 1),\n",
       " ('fact', 1),\n",
       " ('crimes', 1),\n",
       " ('opens', 1),\n",
       " ('frustrated', 1),\n",
       " ('oppression', 1),\n",
       " ('rigid', 1),\n",
       " ('prohibits', 1),\n",
       " ('sex', 1),\n",
       " ('expression', 1),\n",
       " ('individuality', 1),\n",
       " ('dislikes', 1),\n",
       " ('illegally', 1),\n",
       " ('purchased', 1),\n",
       " ('write', 1),\n",
       " ('criminal', 1),\n",
       " ('become', 1),\n",
       " ('fixated', 1),\n",
       " ('named', 1),\n",
       " ('believes', 1),\n",
       " ('secret', 1),\n",
       " ('brotherhood—the', 1),\n",
       " ('mysterious', 1),\n",
       " ('legendary', 1),\n",
       " ('group', 1),\n",
       " ('overthrow', 1),\n",
       " ('truth', 1),\n",
       " ('alters', 1),\n",
       " ('historical', 1),\n",
       " ('records', 1),\n",
       " ('fit', 1),\n",
       " ('needs', 1),\n",
       " ('notices', 1),\n",
       " ('coworker', 1),\n",
       " ('beautiful', 1),\n",
       " ('staring', 1),\n",
       " ('worries', 1),\n",
       " ('informant', 1),\n",
       " ('turn', 1),\n",
       " ('troubled', 1),\n",
       " ('allied', 1),\n",
       " ('eastasia', 1),\n",
       " ('war', 1),\n",
       " ('eurasia', 1),\n",
       " ('seems', 1),\n",
       " ('recall', 1),\n",
       " ('true', 1),\n",
       " ('alleged', 1),\n",
       " ('dangerous', 1),\n",
       " ('man', 1),\n",
       " ('alive', 1),\n",
       " ('seem', 1),\n",
       " ('plausible', 1),\n",
       " ('evenings', 1),\n",
       " ('wandering', 1),\n",
       " ('poorest', 1),\n",
       " ('neighborhoods', 1),\n",
       " ('proletarians', 1),\n",
       " ('proles', 1),\n",
       " ('live', 1),\n",
       " ('squalid', 1),\n",
       " ('lives', 1),\n",
       " ('relatively', 1),\n",
       " ('one', 1),\n",
       " ('day', 1),\n",
       " ('note', 1),\n",
       " ('you.', 1),\n",
       " ('name', 1),\n",
       " ('begin', 1),\n",
       " ('covert', 1),\n",
       " ('lookout', 1),\n",
       " ('signs', 1),\n",
       " ('eventually', 1),\n",
       " ('rent', 1),\n",
       " ('secondhand', 1),\n",
       " ('prole', 1),\n",
       " ('district', 1),\n",
       " ('bought', 1),\n",
       " ('relationship', 1),\n",
       " ('lasts', 1),\n",
       " ('sure', 1),\n",
       " ('caught', 1),\n",
       " ('punished', 1),\n",
       " ('sooner', 1),\n",
       " ('later', 1),\n",
       " ('fatalistic', 1),\n",
       " ('knows', 1),\n",
       " ('doomed', 1),\n",
       " ('since', 1),\n",
       " ('wrote', 1),\n",
       " ('first', 1),\n",
       " ('entry', 1),\n",
       " ('pragmatic', 1),\n",
       " ('optimistic', 1),\n",
       " ('progresses', 1),\n",
       " ('hatred', 1),\n",
       " ('grows', 1),\n",
       " ('intense', 1),\n",
       " ('message', 1),\n",
       " ('waiting', 1),\n",
       " ('wants', 1),\n",
       " ('see', 1),\n",
       " ('travel', 1),\n",
       " ('luxurious', 1),\n",
       " ('apartment', 1),\n",
       " ('inner', 1),\n",
       " ('belongs', 1),\n",
       " ('outer', 1),\n",
       " ('leads', 1),\n",
       " ('life', 1),\n",
       " ('luxury', 1),\n",
       " ('imagine', 1),\n",
       " ('confirms', 1),\n",
       " ('like', 1),\n",
       " ('hates', 1),\n",
       " ('says', 1),\n",
       " ('indoctrinates', 1),\n",
       " ('gives', 1),\n",
       " ('copy', 1),\n",
       " ('book', 1),\n",
       " ('manifesto', 1),\n",
       " ('book—an', 1),\n",
       " ('amalgam', 1),\n",
       " ('several', 1),\n",
       " ('forms', 1),\n",
       " ('class-based', 1),\n",
       " ('twentieth-century', 1),\n",
       " ('social', 1),\n",
       " ('theory—to', 1),\n",
       " ('suddenly', 1),\n",
       " ('soldiers', 1),\n",
       " ('barge', 1),\n",
       " ('seize', 1),\n",
       " ('mr.', 1),\n",
       " ('charrington', 1),\n",
       " ('proprietor', 1),\n",
       " ('revealed', 1),\n",
       " ('police', 1),\n",
       " ('torn', 1),\n",
       " ('away', 1),\n",
       " ('taken', 1),\n",
       " ('place', 1),\n",
       " ('finds', 1),\n",
       " ('spy', 1),\n",
       " ('simply', 1),\n",
       " ('pretended', 1),\n",
       " ('order', 1),\n",
       " ('trap', 1),\n",
       " ('committing', 1),\n",
       " ('open', 1),\n",
       " ('act', 1),\n",
       " ('months', 1),\n",
       " ('torturing', 1),\n",
       " ('brainwashing', 1),\n",
       " ('struggles', 1),\n",
       " ('resist', 1),\n",
       " ('sends', 1),\n",
       " ('dreaded', 1),\n",
       " ('101', 1),\n",
       " ('final', 1),\n",
       " ('destination', 1),\n",
       " ('anyone', 1),\n",
       " ('opposes', 1),\n",
       " ('forced', 1),\n",
       " ('confront', 1),\n",
       " ('fear', 1),\n",
       " ('throughout', 1),\n",
       " ('recurring', 1),\n",
       " ('nightmares', 1),\n",
       " ('straps', 1),\n",
       " ('cage', 1),\n",
       " ('full', 1),\n",
       " ('onto', 1),\n",
       " ('head', 1),\n",
       " ('prepares', 1),\n",
       " ('allow', 1),\n",
       " ('eat', 1),\n",
       " ('snaps', 1),\n",
       " ('pleading', 1),\n",
       " ('giving', 1),\n",
       " ('wanted', 1),\n",
       " ('spirit', 1),\n",
       " ('broken', 1),\n",
       " ('released', 1),\n",
       " ('outside', 1),\n",
       " ('world', 1),\n",
       " ('meets', 1),\n",
       " ('longer', 1),\n",
       " ('anything', 1),\n",
       " ('accepted', 1),\n",
       " ('entirely', 1),\n",
       " ('learned', 1)]"
      ]
     },
     "execution_count": 198,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "L31rVeurvZxl",
    "outputId": "2727ead4-b7b3-4f14-cc6b-f12e054e5494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "PHPFmzrvu98U",
    "outputId": "ef104fd2-1b16-4778-d90e-331a22895491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
      "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from folium) (0.3.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from folium) (1.12.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from folium) (2.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from folium) (1.16.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from folium) (2.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->folium) (1.1.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "gx8k6L5ZvEQ6",
    "outputId": "ec66e5bb-50af-470e-e7c8-5c9255422d9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7ff12f5c66d8>"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "myMap = folium.Map(location=[36.123, 127.123], zoom_start=12, tiles=\"Stamen Terrain\")\n",
    "folium.Marker([36.123, 127.123], popup=\"우리짐\").add_to(myMap)\n",
    "myMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuaNwKJQvnl4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day25_0807_CNN+konlpy setting.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
