# 4. Hyper parameter Tuning, Advanced Feature Engineering, Ensembling

- 지난시간 추가설명 : Weight of evidence / Information Value
-  https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb 



### Hyperparameter Tuning

가장 중요한 건 뭘까요?

- **어떤 파라미터가 가장 큰 영향 미치는지 알아야 함!**
  - 전체 다 파라미터를 수정할 수는 없음!
- 그 파라미터가 학습에 어떤 영향 끼치는지 이해하라!
- 튜닝해라! : 손으로 or 자동으로
- 라이브러리 많고 좋으니까 써라 : hyperopt
  - 파라미터 범위 실행하고 유효성 점수 결과 돌려줌
  - 시간 오래걸릴수도 있음 : search에 적절한 범위를 지정해줘

다른 종류 파라미터 값은 다른 결과들을 가져옴

- 현재 파라미터가 언더피팅인지 오버피팅인지 좋은 값인지 파악해야 함!
- parameter in red
  - 상승되면 fitting에 방해되는 요소
- parameter in green
  - 상승되면 피팅에 도움되는 요소

어쨌든 각 모델마다 튜닝 방법이 다르다

- 트리기반
  - xgboost / lightgbm / catboost
    - 이 친구들은 주어진 목표를 점진적으로 최적화 하는 Decision Tree를 만듬!
    - 여기서 중요한 변수는 무엇?
      - Max_depth : 최적 깊이 : task따라 다름!
        - 최대 깊이 7 시작 추천 : 깊이 깊어지면 오래걸림
      - subsample : 전체 feature 안쓰고 sampling해서 씀
        - 오버피팅 안나고 general한 모델을 만든다
      - colsample_bytree / colsample_bylevel
      - min_child_weight : 0이면 자유도 높음, 아니면 제약커짐
      - eta : learning rate
      - num_round : how many trees we want to make (num_iteration)
        - 학습 속도가 너무 높으면 모델이 수렴하지 않을 수 있음!
        - 너무 낮으면 수렴을 못함
        - 적절히 학습률을 맞게 정해서 수렴하게 만들어봅시다
      - seed : random seed : 만약 이것때문에 리더보드 결과가 많이 바뀐다면 생각해봐야 한다!
    - 보통 val loss 떨어지면 학습 종료
    - 적절한 hyperparam 찾았을 때 trick : iteration 수 2배로 늘리고 eta를 2로 나눔 => 보통 모델 성능 향상됨
  - RF , extraTrees
    - 두 모델은 기본적으로 같음, but ET는 그냥 무작위성이 훨씬 큰 것 뿐!
    - 1그루씩 나무 만듬
    - RF는 각 나무가 독립적
      - n_estimator : 나무의 수
        - 너무 크게 잡으면 오래걸림 : 보통 10개로 맨처음 테스트하고 시간 측정하고 나무 수 결정
      - max_depth : 무제한 : 7로 시작하기를 추천 : 보통 GBM보다 더 큼 
      - max_features : 사용하는 feature 수
      - min_sample_leaf : 자유도를 제약하는 값
      - criterion : 지니 or 엔트로피
      - random_state
      - n_jobs <= sklearn에서 defalut = 1
  - RGF
- 뉴럴넷
  - 각 레이어의 뉴런 갯수
  - 층의 갯수
  - optimizers
    - SGD + momentum
    - Adam / Ada.. : 오버피팅 위험, 빠름
  - Batch size : 오버피팅 => 배치크기 줄여라 : 작아지면 iteration 증가
  - learning rate
    - L2 L1 정규화
    - dropout : node를 학습할 때 없애는 것
    - static dropconnect : connection을 학습할 때 없애는 것
- 선형 모델
  - SVC / SVR
    - SVM은 보통 튜닝 필요하지 않음
  - Logistic / Linear Regression
  - SGD classifier / SGD regressor
  - L1 L2 정규화
    - 아주 작은 값부터 C를 시작하다가 점점 늘려나감
- Factorization models : 설명은 안되있지만 찾아봐라.
- Do not spend too much time for hyperparameter
- Be patient : 조금 더 학습하면 더 좋은 결과 나올 수 있다!
- 모델 여러개 만들고 / Average : 랜덤 시드를 다르게 해서도!



참고자료

-  https://scikit-learn.org/stable/modules/grid_search.html 
-  http://fastml.com/optimizing-hyperparams-with-hyperopt/ 
-  https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/ 



### Advanced features II

#### Statistics and distance based features

- 위치와 페이지 => 광고 가격 : 문제가 있다면?
  - 각 페이지 별 어디 부분에 있을 때 최소 가격인지? : 사람들은 싼 가격을 좋아하니까!
  - 코딩 : groupby해서 그룹별로 min max 구하고 원래 df에 merge
  - 그 외에도 많은 피쳐들을 추가할 수 있다!
    - 유저가 각 페이지당 몇 번 방문했니?
    - 가격의 std
    - 가장 많이 방문된 페이지.. 등등!
  - 만약에 그룹화가 안된다면?
    - nearest neighbor를 찾자!
      - 단순히 그대로인 그룹은 필요가 없음!
      - 유연하다
      - 적용하기 어렵당
      - 예) 500m, 1000m안에 집이 몇개 있어? / 지역 안에 1평당 가격 얼마야?
      - 지역 내 학교 등 시설 몇개있어? / 가장 가까운 지하철역까지 거리 얼마야?
  - **균일한 feature space를 만들었다? : 새 feature 만들기!**
    - 모든 특성을 mean encoding함
    - 각 포인트마다 2000개의 NN을 찾음 : Bray-Curtis metric으로!
    - 각 5, 10, 15 ... 2000개 그룹 단위로 mean target을 구해서 feature에 추가함!
    - 10개의 가까운 이웃에 대한 mean distance
    - 타겟이 0인 10개의 가까운 이웃에 대한 mean distance
    - 타겟이 1인 10개의 가까운 이웃에 대한 mean distance

####  Matrix factorizations for Feature Extraction

- 행렬 분해를 하면 feature를 분석하는 데 도움이 될 수 있다!
- feature matrix의 사이즈를 줄이는 효율적인 방법!
- ex )  td-idf 행렬도 쪼갤 수 있을걸?
- 너무 행렬이 크면 트리에 안들어감! => 잘 줄이면 넣을 수 있다
- 특징
  - 몇 특정 컬럼에만 적용될 수 있다
  - 추가로 다양함을 제공할 수 있다 : 앙상블에 좋음
  - 어찌되었건 feature의 특징이 상실된다 : 특정 task에 사용 : 속도 / 연산량 증대되기 때문에 이득!
- 적용
  - sklearn에서 MF method로 구현되어있음
  - SVD / PCA
  - TruncatedSVD : sparse에서만 사용가능
  - NMF : 모든 값이 양수 혹은 0일때만 사용가능한 MF
    - 근데 이거 꽤나 잘 된다고 하던데!
    - 요거에다가 logarimathic까지 적용하면 target을 더 잘 분류해내는 feature를 찾을 수도 있을걸!
- 훈련가능 / 매개변수 존재
  - 모든 데이터 정보를 입력하여 PCA를 수행하고, 각 train / test를 변환하여 사용하는게 좋다.

#### Feature Interactions

- decision trees에서 feature extraction 하기!
- 두 feature를 합쳐서 또다른 의미있는 조합 feature를 만들어내기!
  - ex) 광고 클릭 했는지 안했는지 예측 문제 : 광고의 종류 / 사이트의 종류 => 중요한 건 조합!
  - 조합 컬럼을 만든 다음 / 그 컬럼으로 OHE로 피쳐 생성!
  - 혹은 두 컬럼 혹은 여러 컬럼에 대한 사칙연산
- N개의 feature가 있으면 N*N개가 만들어짐! (뭐 일단 수치적으로..)
  - 어떤 애들은 interaction이 있을 때 더 빛을 발함
- 이게 너무 커지니까 숫자를 줄이기 위해
  - 차원 축소
  - 피쳐 선택
- 결정 트리에서 사용하는 피쳐를 사용하는 법!
- 우리는 categorical attributes의 interaction을 만들기 위해 봤다!
- 실제 가치있는 특성들로 확장!
- 의사결정 나무를 통해 어떻게 feature를 뽑아내는 지 배운다
  - xgboost에서는 어떻게 leaf를 만드는 지 보여주는 기능 제공! : pred_leaf=True
  - sklearn에서는 tree_model.apply() 하면 됨!

#### t-SNE

- 개괄
  - intergrating 데이터 visualization!
  - tSNE를 써보자!
  - 지금까지 했던 것들은 선형 모델을 위한 친구들!
- 이거는 비선형적인 차원감소!
  - 새로운 매니폴드 러닝 방법?
  - 고차원 공간에서 점 사이의 거리가 대략적으로 보존되도록!
  - 투사 형태가 명시적 클러스터를 나타냄!
    - 이러한 클러스터가 의미가 있고, 각 숫자에 잘 부합함
    - 클러스터끼리 비슷하면 숫자간의 간격도 좁다?
  - 그러나 hyperparam 잘못 설정하면 이상하게 분류될 수도 있다
  - perplexity? 에 따라서 다양한 방법으로 분류됨!
    - 결과 해석이 단순한 작업이 아님!
    - 원래 클러스터를 유추할 수가 없다.
- 예비 데이터 외에도 새로운 기능을 얻을 수 있는 방법!
- 결론
  - 결과가 hyperparameter에 큰 영향 받음 (좋은 결과는 보통 5-100 사이)
  - stochastic해서 심지어 같은 hp에서도 다른 결과 나올 수도 있음
    - 그래서 projection할 때 train / test를 함께 해야 함!
  - feature가 너무 많으면 엄청 오래 걸릴 수 있음
    - 보통 projection 전에 차원 축소 하는게 좋음
  - sklearn or 별도 tSNE 패키지
  - **데이터 시각화를 위한 아주 좋은 도구!**
  - **근데 해석 시 주의해야 함!**
    - **구조가 있는데도 없다고 볼 수도 있고**
    - **없는데도 있다고 볼 수 있음!**
  - **그러므로 다양한 perplexities에서 시행해 보세요!**
- 추가 공부하면 좋은 내용
  - Matrix Factorization
    -  [Overview of Matrix Decomposition methods (sklearn)](http://scikit-learn.org/stable/modules/decomposition.html) 
  - t-SNE
    -  [Multicore t-SNE implementation](https://github.com/DmitryUlyanov/Multicore-TSNE) 
    -  [Comparison of Manifold Learning methods (sklearn)](http://scikit-learn.org/stable/auto_examples/manifold/plot_compare_methods.html)
    -  [How to Use t-SNE Effectively (distill.pub blog)](https://distill.pub/2016/misread-tsne/) 
    -  [tSNE homepage (Laurens van der Maaten)](https://lvdmaaten.github.io/tsne/) 
    -  [Example: tSNE with different perplexities (sklearn)](http://scikit-learn.org/stable/auto_examples/manifold/plot_t_sne_perplexity.html#sphx-glr-auto-examples-manifold-plot-t-sne-perplexity-py) 
  - Interactions
    -  [Facebook Research's paper about extracting categorical features from trees](https://research.fb.com/publications/practical-lessons-from-predicting-clicks-on-ads-at-facebook/) 
    -  [Example: Feature transformations with ensembles of trees (sklearn)](http://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html) 

### Ensemble

#### Introduction into ensemble methods

앙상블 모델링은 뭘까요? : 더 좋은 결과를 얻으려고 스까보자! 모델들을 합쳐보자!

- Examined ensemble methods
  - Averaging (or blending)
  - Weighted averaging
  - Conditional averaging
  - **Bagging**
  - **Boosting**
  - **Stacking**
  - StackNet

- 평균 앙상블 방법
  - 여러개의 상호 보완적인(예측 수준이 비슷한) 모델이 존재할 경우 그것을 평균을 내서 해보자!
  - 걍 간단한 평균의 방법이다 => general하고 robust한 결과를 좀 더 기대할 수 있다!
  - 평균적인 점들은 현실과 좀 더 가까워 지는 경향이 큼 => 전체적인 에러 감소!
  - 가중치 있는 평균 : 뭐 그냥 7:3 or 2:8 등등 : **만약 모델의 파워가 다르다면 이렇게 하는게 좋을까?**
    - 만약 어떤 threshold를 기준으로 잘하고 못하는 다른 두 모델이 있다면
      - 그냥 잘하는 부분끼리만 갖다 붙이는 게 정답이 될 수도 있다!



#### Bagging

**살짝 다른 버전의 같은 모델들을 평균하는 것!**

- random forest가 그 좋은 예시

모델링에는 크게 두가지 오류가 있음

- errors due to Bias : underfitting
- errors due to Variance : overfitting
- Bias - Variance 관계 : Bias : 정답을 맞추니? / Variance : 얼마나 일반적이니?
  - 어느 순간을 넘어가면 모든 정보를 소진하고, 일반화할 수 없는 예측을 만들어냄
  - 이 때 bagging을 하면 좀 더 일반화된 모델을 만들어 낸다!
    - 오히려 이렇게 평균을 낼 때 정보를 더 낭비하지 않는다?!

관련 매개 변수

- Changing the seed
- Row subsampling or bootstraping
  - bootstraping : 랜덤 샘플링을 통해서 training data를 늘리는 방법!
- Shuffling : 섞기
- Column (Sub) sampling : 컬럼 샘플링
- Model-specific parameters : 모델에 특정된 파라미터 사용
- Number of models (or bags)
  - 일반적으로 큰게 좋긴 함
  - 글구 각 모델은 독립적임
- Bagging의 예시
  - BaggingClassifier / BaggingRegressor from sklearn



#### Boosting

**이전 모델의 성능을 고려하여 각 모델이 순차적으로 만들어지는 모델의 가중 평균 형식**

앙상블에 새로 추가되는 모델들은 이전 모델이 얼마나 잘 했는지를 고려함!

2가지 유명한 알고리즘

- Weighted based

  - 이전 모델의 절대 오류를 계산
    - 이 절대 오류를 바탕으로 새로운 weight를 만들어서 다음 모델의 오류를 계산할때 고려함
    - 약한 분류기를 더 강하게 하는 알고리즘
  - 특정 매개변수
    - Learning rate (shrinkage or eta) : 한 모델을 믿는것보다 다양한 모델을 조금씩 신뢰함으로 만든다!
    - Number of estimators : 매우 중요
      - 적절한 거 찾기 참 힘들다 : CV로 찾자 : 보통 estmators 100개정도로 시작
    - 아까 말했던 것 처럼 괜찮은 값 찾았다 싶으면 # of est / eta 변화시키기 : 100, 0.1 => 200, 0.05
  - Input model - can be anything that accept weights
  - sub boosting type : adaboost / logitboost
- Residual error based

  - 이미지 분류나 비디오 어떤 것에서든 꽤나 지배적으로 강력하다!

  - 여기서 관심 있는 것 : **"오류의 방향" **: Gradient

  - 일단 error를 구하고, target과의 residual을 구함

    - 그리고 그 residual이 새로운 타겟! : residual을 줄이는 새로운 모델을 계속해서 추가해 나감!
    - 상당히 효과적

  - 매개변수

    - Learning rate : 계속해서 나오는 model들을 얼마만큼 반영할 것인지!

    - Number of estimators : CV

    - row / col (sub)sampling

    - Input model - better be trees

    - sub boosting type:

      - Fully gradient based
      - Dart(나무의 기여 제어) : 낙하 메커니즘? : 새로운 샘플 / 추정치 할 때 마다 / 내가 이전의 모든 것을 믿지 않고, 일부만 믿는다 : ex) 11번째 모델 만들때 무작위로 2개 제외 => 일반화된 모델
  
- Residual based favorite implemetations
  - Xgboost
  - Lightgbm
  - H2O's GBM
  - Catboost : strong initial set of parameter
  - sklearn's GBM



**너무 많은 시간을 튜닝하는데 쓰지 마세요!**



#### Stacking

**'쌓아가기'**

보통 할 수 있는 한 최대로 땡겨내려면 stacking 맨 마지막에!

Stacking means : 서로 다른 타입의 모델 결합 : 처음에는 hold-out set의 평균으로 prediction 구한 다음, 나머지 **메타 모델**을 이전 모델의 output으로 학습

메타 모델은 input data를 알 필요가 없음!

**방법론**

- spliting train set into 2 disjoint sets
- train several base learners on the first part
- make predictions with the base learners on the second part
- using the predictions from [before step] as the input data to train a **higher level learner**
  - higher level learner => Meta model

**예시**

일단 train / test 나누고, base learner들에게 '각각' 학습시켜 '학습용 input'과 '테스트용 input'을 만든다!

(각 메타모델의 새로운 input은 여러개 모델 결과의 concat)

그리고 메타모델을 학습용 input으로 학습시키고 / 테스트용 input으로 테스트!



**사용시 유의점**

- time-series : 데이터 만들 때 고려해야 함!
  - 시간 요소를 존중해야 일반화 가능!
- 모델 다양성은 performance에 중요 : 다른게 많이 올수록 더 좋은 메타 모델 만든당
  - base learner가 weak learner이지만, 분명 **'중요한, 새로운 정보를 가지고 있는가?'** 의 여부가 중요
- 두가지 형태의 다양성
  - 다른 알고리즘 사용
    - 비선형 - 선형
  - 다른 인풋 피쳐 사용
    - 동일 모델일 경우 입력 데이터를 변형시키면 더 좋을 수 있다
- Performance plateauing after N models
- 메타 모델은 modest : 그냥 결과들 결합 : 그렇게 복잡하고 깊을 필요가 없다! (간단히!)