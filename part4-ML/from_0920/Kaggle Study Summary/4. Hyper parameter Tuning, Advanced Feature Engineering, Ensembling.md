# 4. Hyper parameter Tuning, Advanced Feature Engineering, Ensembling

- 지난시간 추가설명 : Weight of evidence / Information Value
-  https://medium.com/@sundarstyles89/weight-of-evidence-and-information-value-using-python-6f05072e83eb 



### Hyperparameter Tuning

가장 중요한 건 뭘까요?

- **어떤 파라미터가 가장 큰 영향 미치는지 알아야 함!**
  - 전체 다 파라미터를 수정할 수는 없음!
- 그 파라미터가 학습에 어떤 영향 끼치는지 이해하라!
- 튜닝해라! : 손으로 or 자동으로
- 라이브러리 많고 좋으니까 써라 : hyperopt
  - 파라미터 범위 실행하고 유효성 점수 결과 돌려줌
  - 시간 오래걸릴수도 있음 : search에 적절한 범위를 지정해줘

다른 종류 파라미터 값은 다른 결과들을 가져옴

- 현재 파라미터가 언더피팅인지 오버피팅인지 좋은 값인지 파악해야 함!
- parameter in red
  - 상승되면 fitting에 방해되는 요소
- parameter in green
  - 상승되면 피팅에 도움되는 요소

어쨌든 각 모델마다 튜닝 방법이 다르다

- 트리기반
  - xgboost / lightgbm / catboost
    - 이 친구들은 주어진 목표를 점진적으로 최적화 하는 Decision Tree를 만듬!
    - 여기서 중요한 변수는 무엇?
      - Max_depth : 최적 깊이 : task따라 다름!
        - 최대 깊이 7 시작 추천 : 깊이 깊어지면 오래걸림
      - subsample : 전체 feature 안쓰고 sampling해서 씀
        - 오버피팅 안나고 general한 모델을 만든다
      - colsample_bytree / colsample_bylevel
      - min_child_weight : 0이면 자유도 높음, 아니면 제약커짐
      - eta : learning rate
      - num_round : how many trees we want to make (num_iteration)
        - 학습 속도가 너무 높으면 모델이 수렴하지 않을 수 있음!
        - 너무 낮으면 수렴을 못함
        - 적절히 학습률을 맞게 정해서 수렴하게 만들어봅시다
      - seed : random seed : 만약 이것때문에 리더보드 결과가 많이 바뀐다면 생각해봐야 한다!
    - 보통 val loss 떨어지면 학습 종료
    - 적절한 hyperparam 찾았을 때 trick : iteration 수 2배로 늘리고 eta를 2로 나눔 => 보통 모델 성능 향상됨
  - RF , extraTrees
    - 두 모델은 기본적으로 같음, but ET는 그냥 무작위성이 훨씬 큰 것 뿐!
    - 1그루씩 나무 만듬
    - RF는 각 나무가 독립적
      - n_estimator : 나무의 수
        - 너무 크게 잡으면 오래걸림 : 보통 10개로 맨처음 테스트하고 시간 측정하고 나무 수 결정
      - max_depth : 무제한 : 7로 시작하기를 추천 : 보통 GBM보다 더 큼 
      - max_features : 사용하는 feature 수
      - min_sample_leaf : 자유도를 제약하는 값
      - criterion : 지니 or 엔트로피
      - random_state
      - n_jobs <= sklearn에서 defalut = 1
  - RGF
- 뉴럴넷
  - 각 레이어의 뉴런 갯수
  - 층의 갯수
  - optimizers
    - SGD + momentum
    - Adam / Ada.. : 오버피팅 위험, 빠름
  - Batch size : 오버피팅 => 배치크기 줄여라 : 작아지면 iteration 증가
  - learning rate
    - L2 L1 정규화
    - dropout : node를 학습할 때 없애는 것
    - static dropconnect : connection을 학습할 때 없애는 것
- 선형 모델
  - SVC / SVR
    - SVM은 보통 튜닝 필요하지 않음
  - Logistic / Linear Regression
  - SGD classifier / SGD regressor
  - L1 L2 정규화
    - 아주 작은 값부터 C를 시작하다가 점점 늘려나감
- Factorization models : 설명은 안되있지만 찾아봐라.
- Do not spend too much time for hyperparameter
- Be patient : 조금 더 학습하면 더 좋은 결과 나올 수 있다!
- 모델 여러개 만들고 / Average : 랜덤 시드를 다르게 해서도!



참고자료

-  https://scikit-learn.org/stable/modules/grid_search.html 
-  http://fastml.com/optimizing-hyperparams-with-hyperopt/ 
-  https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/ 