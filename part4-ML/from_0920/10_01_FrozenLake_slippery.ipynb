{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros([env.observation_space.n, env.action_space.n]) # Q table 생성!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .75\n",
    "dis = .99\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5075\n",
      "[[6.49751331e-01 4.68968405e-03 3.09179137e-02 3.72378146e-02]\n",
      " [1.00247939e-02 2.80063062e-02 5.73646369e-04 3.52880506e-01]\n",
      " [2.32366584e-03 2.43269812e-03 1.28994514e-02 3.75365460e-01]\n",
      " [1.33273676e-03 1.10948014e-04 2.10403611e-02 4.15654695e-01]\n",
      " [5.59572326e-01 1.38923602e-04 1.60609449e-02 1.46699343e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.63740084e-02 7.40244876e-05 3.41871313e-05 4.03825840e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.03060064e-04 1.67853886e-04 7.17959873e-05 7.41804848e-01]\n",
      " [1.26803233e-03 3.44241104e-01 8.98385808e-04 2.33574167e-03]\n",
      " [8.06720836e-01 2.70914177e-04 2.43631690e-04 2.43406877e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.32077338e-03 1.47769372e-04 9.05371664e-01 8.01948120e-04]\n",
      " [7.47989364e-03 2.92058417e-04 9.55966198e-01 2.21930800e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.argmax(Q[state, :] + np.random.randn(1,env.action_space.n)/(i+1))\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        Q[state,action] = (1-learning_rate) * Q[state,action] \\\n",
    "        + learning_rate * (reward + dis*np.max(Q[new_state,:])) # 고집 + 새로운 갱신\n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "    rList.append(rAll)\n",
    "print(sum(rList)/num_episodes)\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandit을 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손잡이 : 4개, 밴딧(슬롯머신) : 3대\n",
    "# 각각의 밴딧은 각각의 손잡이에 대해 서로 다른 성공 확률 가짐\n",
    "# 최고의 결과를 얻어내기 위한 동작\n",
    "# 최고 결과 주는 손잡이를 항상 선택하도록 하는 방법을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contextual_bandit():#밴딧 클래스\n",
    "    def __init__(self): #태어나는 아기(객체)\n",
    "        self.state=0    #슬롯머신 상태,아기의 몸무게(속성)\n",
    "        self.bandits=np.array([[0.2,0,-0.1,-5],[0.1,-5,1,0.25],[-5,5,5,5]]) #슬롯머신(밴딧) 3대\n",
    "        self.num_bandits=self.bandits.shape[0]\n",
    "        self.num_actions=self.bandits.shape[1]\n",
    "    def getBandit(self):\n",
    "        self.state=np.random.randint(0,len(self.bandits))\n",
    "        return self.state\n",
    "    def pullArm(self, action):#action:레버(4개의 레버중에서 당긴 레버의 번호)\n",
    "        bandit=self.bandits[self.state, action]\n",
    "        result=np.random.randn(1)\n",
    "        if result>bandit:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent(): #에이전트\n",
    "    def __init__(self, lr, s_size, a_size):\n",
    "        #에이전트 초기화\n",
    "        self.state_in=tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "        state_in_OH=slim.one_hot_encoding(self.state_in, s_size)\n",
    "        output=slim.fully_connected(state_in_OH, a_size, biases_initializer=None, activation_fn=tf.nn.sigmoid, weights_initializer=tf.ones_initializer())\n",
    "        self.output=tf.reshape(output,[-1])\n",
    "        self.chosen_action=tf.argmax(self.output,0)\n",
    "        \n",
    "        self.reward_holder=tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "        self.action_holder=tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "        self.responsible_weight=tf.slice(self.output,self.action_holder, [1])\n",
    "        self.loss=-(tf.log(self.responsible_weight)*self.reward_holder)\n",
    "        optimizer=tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "        self.update=optimizer.minimize(self.loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet_inputs=tf.placeholder(tf.float32,[None,None,None,1])\n",
    "net_outputs=tf.placeholder(tf.float32,[None,None,None,1])\n",
    "\n",
    "#1번째 계층\n",
    "w=tf.Variable(tf.random_normal([11,11,1,10]))\n",
    "b=tf.Variable(tf.random_normal([10]))\n",
    "net=tf.nn.conv2d(net_inputs, filter=w, strides=[1,4,4,1], padding='SAME')\n",
    "net=tf.nn.bias_add(net,b)\n",
    "net=tf.nn.relu(net)\n",
    "\n",
    "w=tf.Variable(tf.random_normal([5,5,10,20]))\n",
    "#2번째 계층\n",
    "net=tf.nn.conv2d(net, filter=w, strides=[1,2,2,1], padding='SAME')\n",
    "net=tf.nn.relu(net)\n",
    "\n",
    "#3번째 계층\n",
    "w=tf.Variable(tf.random_normal([3,3, 20,50]))\n",
    "net=tf.nn.conv2d(net, filter=w, strides=[1,2,2,1], padding='SAME')\n",
    "net=tf.nn.relu(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'fully_connected/weights:0' shape=(3, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable:0' shape=(11, 11, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(5, 5, 10, 20) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(3, 3, 20, 50) dtype=float32_ref>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'fully_connected/weights:0' shape=(3, 4) dtype=float32_ref>\n",
      "<tf.Variable 'Variable:0' shape=(11, 11, 1, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_2:0' shape=(5, 5, 10, 20) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_3:0' shape=(3, 3, 20, 50) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "train_var = [var for var in tf.trainable_variables()]\n",
    "for tv in train_var:\n",
    "    print(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 보상의 평균 : 3 밴딧:[ 0.   -0.25  0.  ]\n",
      "각 보상의 평균 : 3 밴딧:[32.5  43.5  37.25]\n",
      "각 보상의 평균 : 3 밴딧:[72.75 80.   78.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[108.   118.   114.75]\n",
      "각 보상의 평균 : 3 밴딧:[148.5  160.5  148.75]\n",
      "각 보상의 평균 : 3 밴딧:[191.75 197.25 181.75]\n",
      "각 보상의 평균 : 3 밴딧:[228.   233.   222.25]\n",
      "각 보상의 평균 : 3 밴딧:[267.   270.25 261.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[305.25 306.75 296.25]\n",
      "각 보상의 평균 : 3 밴딧:[340.25 347.   328.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[378.25 385.5  366.  ]\n",
      "각 보상의 평균 : 3 밴딧:[414.   425.25 401.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[453.5  467.25 436.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[493.75 509.   464.  ]\n",
      "각 보상의 평균 : 3 밴딧:[533.5  544.5  496.25]\n",
      "각 보상의 평균 : 3 밴딧:[575.25 579.5  533.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[616.25 613.   568.  ]\n",
      "각 보상의 평균 : 3 밴딧:[652.25 658.5  599.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[692.25 695.5  632.5 ]\n",
      "각 보상의 평균 : 3 밴딧:[733.   730.25 668.5 ]\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "tf.reset_default_graph()\n",
    "cBandit=contextual_bandit() #객체 생성\n",
    "myAgent=agent(lr=0.001,s_size=cBandit.num_bandits, a_size=cBandit.num_actions) #객체 생성\n",
    "weights=tf.trainable_variables()[0]\n",
    "\n",
    "total_episodes=10000\n",
    "total_reward=np.zeros([cBandit.num_bandits, cBandit.num_actions])\n",
    "e=0.1\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    i=0\n",
    "    while i < total_episodes:\n",
    "        s=cBandit.getBandit()\n",
    "        \n",
    "        if np.random.rand(1)<e: #exploration\n",
    "            action=np.random.randint(cBandit.num_actions)\n",
    "        else:  #exploit\n",
    "            action=sess.run(myAgent.chosen_action,feed_dict={myAgent.state_in:[s]})\n",
    "        \n",
    "        reward=cBandit.pullArm(action)\n",
    "        \n",
    "        #네트워크 업데이트\n",
    "        feed_dict={myAgent.reward_holder:[reward],myAgent.action_holder:[action],myAgent.state_in:[s]}\n",
    "        _, ww=sess.run([myAgent.update, weights], feed_dict=feed_dict)\n",
    "        \n",
    "        total_reward[s,action]+=reward\n",
    "        \n",
    "        if i%500==0:\n",
    "            print(\"각 보상의 평균 : \"+str(cBandit.num_bandits)+\" 밴딧:\"+str(np.mean(total_reward,axis=1)))\n",
    "        i+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
