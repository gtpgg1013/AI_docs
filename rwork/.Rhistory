ngram.tdm$dimnames$Terms
apply(ngram.tdm)
ngram.tdm[,]
ngram.tdm[1,]
apply(ngram.tdm[,], 1, sum)
class(apply(ngram.tdm[,], 1, sum))
#2:열단위 연산(문서)
apply(ngram.tdm[,], 2, sum)
#matix도 활용가능
#1:행단위 연산(단어) : 전체 문서에서 해당 단어가 몇번 등장?
df<-apply(ngram.tdm[,], 1, sum)
df
table(df)
str(df)
library(dplyr)
df %>% arrange(desc(names))
#matix도 활용가능
#1:행단위 연산(단어) : 전체 문서에서 해당 단어가 몇번 등장?
bigramlist<-apply(ngram.tdm[,], 1, sum)
sort(bigramlist, decreasing =TRUE )
str(bigramlist)
#한국어 처리
install.packages("KoNLP")
library(KoNLP)
library(KoNLP)
library(stringr)
library(rJava)
library(KoNLP)
#한국어 처리
install.packages("KoNLP")
library(KoNLP)
library(rJava)
library(KoNLP)
library(rJava)
library(stringr)
library(KoNLP)
txt<-"멀티캠퍼스에 비 오는 날에 오는 것은 그리 쉽지 않다"
useSejongDic()
extractNoun(txt)
install.packages("Sys")
mytextlocation<-"Data/논문/"
library(RWeka)
library(tm)
library(dplyr)
#파일들 전부 가져와서 코퍼스 생성
mypaper<-VCorpus(DirSource(mytextlocation))
mypaper
mypaper[[1]]$content
mypaper[[1]]
mypaper[[1]]$meta$author
mypaper[[1]]$meta
mypaper[[19]]$content
mykorean<-mypaper[[19]]$content
#영문자, 괄호, 홑따옴표 등 특수문자 제거
str_replace_all(mykorean,"[[:lower:]]","")
str_replace_all(mykorean,"[a-zA-Z]","")
#영문자, 괄호, 홑따옴표 등 특수문자 제거
mytext<-str_replace_all(mykorean,"[[:lower:]]","")
str_replace_all(mykorean,"[a-zA-Z]|[[:punct:]]{1,}","")
str_replace_all(mytext,"(\\()","")
str_replace_all(mytext,"(\\))","")
str_replace_all(mykorean,"^[a-zA-Z]*$|[[:punct:]]{1,}","") #일케하면 한꺼번에 날리기 가능
str_replace_all(mykorean,"^[a-zA-Z]*$,"")
str_replace_all(mykorean,"^[a-zA-Z]*$","")
str_replace_all(mykorean,"^[a-zA-Z]*$","")
str_replace_all(mykorean,"^[[::punct::]]*[a-zA-Z]*[[::punct::]]*$","")
str_replace_all(mykorean,"^[[:punct:]]*[a-zA-Z]*[[:punct:]]*$","")
str_replace_all(mykorean,"^[가-힣]*[[:punct:]]*[a-zA-Z]*[[:punct:]]*$","")
str_replace_all(mykorean,"^[가-힣]*[[:punct:]]*[a-zA-Z]*[[:punct:]]*$","")
str_replace_all(mykorean,"[a-zA-Z]|[[:punct:]]{1,}","") #일케하면 한꺼번에 날리기 가능
str_extract_all(mytext,"[가-힣]")
str_extract_all(mytext,"[[:space:]][가-힣]*{1,}[[:space:]]")
str_extract_all(mytext,"[[:space:]]{1}[가-힣]*{1,}[[:space:]]{1}")
str_extract_all(mytext,"[[:space:]]{1}[가-힣][[:space:]]{1}")
str_extract_all(mytext,"[[:space:]]{1}[가-힣]*[[:space:]]{1}")
str_extract_all(mykorean,"[[:space:]]{1}[가-힣]*[[:space:]]{1}")
mytempkor<-str_replace_all(mykorean,"[a-zA-Z]|[[:punct:]]{1,}","") #일케하면 한꺼번에 날리기 가능
str_extract_all(mytempkor,"[[:space:]]{1}[가-힣]*[[:space:]]{1}")
str_extract_all(mytempkor,"[[:space:]]{1}[가-힣]+[[:space:]]{1}")
str_extract_all(mytempkor,"[[:space:]]*[가-힣]+[[:space:]]*")
str_replace_all(mytext,"(\\))","")
str_replace_all(mytext,"(\\.)","")
str_replace_all(mytext,"(\\')","")
str_replace_all(mytext,"(\\,)","")
str_replace_all(mytext,"'","")
mytempkor<-str_replace_all(mykorean,"[a-zA-Z]|[[:punct:]]{1,}","") #일케하면 한꺼번에 날리기 가능
mykorean<-str_replace_all(mykorean,"[a-zA-Z]|[[:punct:]]{1,}","") #일케하면 한꺼번에 날리기 가능
#단어별 짜르기기
str_extract_all(mykorean,"[[:space:]]*[가-힣]+[[:space:]]*")
mykorean
str_replace_all(mytext,",","")
extractNoun(mykorean
extractNoun(mykorean)
extractNoun(mykorean)
noun.mytext<-extractNoun(mykorean)
table(noun.mytext)
#숫자표현 추출
mypaper
#숫자표현 추출
lapply(mypaper, function(x) {
str_extract_all(x,"[[:digit:]]{1,}")
})
#숫자표현 추출
mydigits<-lapply(mypaper, function(x) {
str_extract_all(x,"[[:digit:]]{1,}")
})
mydigits
mypaper[[4]]$content
unlist(mydigits)
table(unlist(mydigits))
sort(table(unlist(mydigits)))
sort(table(unlist(mydigits)),decreasing = True)
sort(table(unlist(mydigits)),decreasing = TRUE)
#코퍼스 안에 있는 모든것들에 대해 일괄적으로 처리하고 싶은 게 있다 : tm_map
tm_map(mypaper, removeNumbers)
#코퍼스 안에 있는 모든것들에 대해 일괄적으로 처리하고 싶은 게 있다 : tm_map
mycorpus<-tm_map(mypaper, removeNumbers)
lapply(mycorpus, function(x) {
str_extract_all(x,"[[:digit:]]{1,}")
})
inspect(mycorpus[[3]])
lapply(mypaper, function(x){
str_extract_all(x,"\\b[[:alpha:]]{1,}")
})
#특수문자를 기준으로 좌 우에 어떤 문자들이 왔는지?
lapply(mypaper, function(x){
str_extract_all(x,"\\b[[:alpha:]]{1,}[[:punct:]]{1,}b[[:alpha:]]{1,}[[:punct:]]{1,}\\b")
})
str_extract_all(x,"\\b[[:alpha:]]{1,}[[:punct:]]{1,}b[[:alpha:]]{1,}\\b")
str_extract_all(x,"\\b[[:alpha:]]{1,}[[:punct:]]{1,}[[:alpha:]]{1,}\\b")
#특수문자를 기준으로 좌 우에 어떤 문자들이 왔는지?
lapply(mypaper, function(x){
str_extract_all(x,"\\b[[:alpha:]]{1,}[[:punct:]]{1,}[[:alpha:]]{1,}\\b")
})
#특수문자를 기준으로 좌 우에 어떤 문자들이 왔는지?
mypuncts<-lapply(mypaper, function(x){
str_extract_all(x,"\\b[[:alpha:]]{1,}[[:punct:]]{1,}[[:alpha:]]{1,}\\b")
})
table(unlist(mypuncts))
sort(table(unlist(mypuncts)),decreasing = TRUE)
mytempfunct(mycorpus, "[[:lower:]]","")
mytempfunct(mycorpus, "[[:lower:]]","")
mytempfunct(mycorpus, "[[:lower:]]","")
mytempfunct(mycorpus, "[[:lower:]]","")
#oldexp를 newexp로 바꾸겠다
#x=myobject
mytempfunct<-function(myobject, oldexp, newexp){
tm_map(myobject,
content_transformer(function(x,pattern) gsub(pattern, newexp,x)),
oldexp)
}
mytempfunct(mycorpus, "[[:lower:]]","")
mycorpus<-tm_map(mycorpus,stripWhitespace)
mycorpus<-mytempfunct(mycorpus, "[[:lower:]]","")
mycorpus<-mytempfunct(mycorpus, "[[:upper:]]","")
mycorpus<-mytempfunct(mycorpus, "\\(","")
mycorpus<-mytempfunct(mycorpus, "\\)","")
mycorpus<-mytempfunct(mycorpus, "\\,","")
mycorpus<-mytempfunct(mycorpus, "_","")
mycorpus<-mytempfunct(mycorpus, "-","")
mycorpus<-mytempfunct(mycorpus, "\\.","")
mycorpus<-mytempfunct(mycorpus, "\\?","")
mycorpus<-mytempfunct(mycorpus, "/,","")
mycorpus<-mytempfunct(mycorpus, "‘","")
mycorpus<-mytempfunct(mycorpus, "’","")
mycorpus<-mytempfunct(mycorpus, "·","")
mycorpus<-tm_map(mycorpus,stripWhitespace)
inspect(mycorpus)
inspect([mycorpus[[1]])
inspect(mycorpus[[1]])
lapply(mycorpus, function(x) {
str_extract_all(x,"[[:digit:]]{1,}")
})
mytemp<-lapply(mypaper, function(x) {
str_replace_all(x,"[[:digit:]]{1,}")
})
mytemp<-lapply(mypaper, function(x) {
str_replace_all(x,"[[:digit:]]{1,}","")
})
mytemp[[1]]
mytemp<-lapply(mypaper, function(x) {
str_replace_all(x,"[[:digit:]]{1,}|[[:punct:]]*","")
})
mytemp[[1]]
myNounFun<-function(mytext) {
myNounList<-paste(extractNoun(mytext), collapse = " ")
}
myNounFun(mycorpus[[1]])
mycorpus[[1]]
myNounFun(mycorpus[[1]]$content)
myNounFun(mycorpus[[1]]$content)
print(myNounFun(mycorpus[[1]]$content))
myNounFun<-function(mytext) {
myNounList<-paste(extractNoun(mytext), collapse = " ")
return(myNounList)
}
myNounFun(mycorpus[[1]]$content)
myNounFun(mycorpus[[2]]$content)
myNounFun(mycorpus[[2]]$content)
myNounListRes<-myNounFun(mycorpus[[2]]$content)
myNounListRes
length(mycorpus)
for(i in 1:length(mycorpus)){
myNounCorpus[[i]]$content<-myNounFun(mycorpus[[i]])
}
myNounCorpus<-list()
length(mycorpus)
for(i in 1:length(mycorpus)){
myNounCorpus[[i]]$content<-myNounFun(mycorpus[[i]])
}
myNounListRes
for(i in 1:length(mycorpus)){
myNounCorpus[[i]]$content<-myNounFun(mycorpus[[i]])
}
for(i in 1:length(mycorpus)){
myNounCorpus[[i]]$content<-myNounFun(mycorpus)
}
myNounCorpus
lapply(mycorpus,function(x) str_extract_all(x,boundary("word")))
myNounCorpus<-mycorpus
for(i in 1:length(mycorpus)){
myNounCorpus[[i]]$content<-myNounFun(mycorpus[[i]])
}
myNounCorpus
lapply(myNouncorpus,function(x) str_extract_all(x,boundary("word")))
lapply(myNounCorpus,function(x) str_extract_all(x,boundary("word")))
for(i in 1:length(mycorpus)){
myNounCorpus[[i]]$content<-myNounFun(mycorpus[[i]]$content)
}
myNounCorpus
lapply(myNounCorpus,function(x) str_extract_all(x,boundary("word")))
corplist<-lapply(myNounCorpus,function(x) str_extract_all(x,boundary("word")))
unlist(corplist)
table(unlist(corplist))
sort(table(unlist(corplist)))
sort(table(unlist(corplist)), decreasing = TRUE)
length(myNounCorpus)
imsi<-length(myNounCorpus)
imsi<-myNounCorpus
length(myNounCorpus)
imsi<-myNounCorpus
for(i in 1:length(myNounCorpus)){
myNounCorpus[[i]]$content<-
str_replace_all(imsi[[1]]$content,
"커뮤니[[:alpha:]]{1,}",
"커뮤니케이션")
}
corplist<-lapply(myNounCorpus,function(x) str_extract_all(x,boundary("word")))
sort(table(unlist(corplist)), decreasing = TRUE)
dtm.k<-DocumentTermMatrix(myNounCorpus)
dtm.k
for(i in 1:length(myNounCorpus)){
myNounCorpus[[i]]$content<-
str_replace_all(imsi[[i]]$content,
"커뮤니[[:alpha:]]{1,}",
"커뮤니케이션")
}
dtm.k<-DocumentTermMatrix(myNounCorpus)
dtm.k
colnames(dtm.k)
inspect(dtm.k)
for(i in 1:length(myNounCorpus)){
myNounCorpus[[i]]$content<-
str_replace_all(imsi[[i]]$content,
"위키리크스[[:alpha:]]{1,}",
"위키리크스")
}
dtm.k<-DocumentTermMatrix(myNounCorpus)
dtm.k
colnames(dtm.k)
dtm.k
apply(dtm.k[,],2,sum)
word.freq<-apply(dtm.k[,],2,sum)
head(word.freq)
apply(dtm.k[,],1,sum)
word.freq<-apply(dtm.k[,],2,sum)
apply(dtm.k[,],1,sum)
head(word.freq)
length(word.freq)
head(sort(word.freq,decreasing = TRUE))
sort.word.freq<-sort(word.freq, decreasing = TRUE)
sort.word.freq[1:20]
#cum 시리즈 : 누적값
cumsum.word.freq<-cumsum(sort.word.freq)
cumsum.word.freq
length(cumsum.word.freq)
#/전체누적합
cumsum.word.freq/cumsum.word.freq[length(cumsum.word.freq)]
#누적합/전체누적합
prop.word.freq<-cumsum.word.freq/cumsum.word.freq[length(cumsum.word.freq)]
prop.word.freq[1:20]
plot(1:length(word.freq))
plot(1:length(word.freq),prop.word.freq)
plot(1:length(word.freq),prop.word.freq, type='l')
plot(x=1:length(word.freq),prop.word.freq)
plot(1:length(word.freq),prop.word.freq)
plot(1:length(word.freq),prop.word.freq, type='l')
word.freq
library("wordcloud")
library(RColorBrewer)
wordcloud(names(word.freq),min.freq = 5, max.words = 25, col=mypal)
mypal=brewer.pal(8,"Pastel1")
wordcloud(names(word.freq),min.freq = 5, max.words = 25, col=mypal)
mypal<-brewer.pal(8,"Pastel1")
wordcloud(names(word.freq),min.freq = 5, max.words = 25, col=mypal)
wordcloud(names(word.freq),min.freq = 5, max.words = 70, col=mypal)
wordcloud(names(word.freq),min.freq = 5, max.words = 70, col=mypal, random.order = FALSE)
wordcloud(names(word.freq),min.freq = 5, max.words = 70, col=mypal, random.order = FALSE, scale(4,0.2))
wordcloud(names(word.freq),min.freq = 3, max.words = 70, col=mypal, random.order = FALSE, scale(4,0.2))
wordcloud(names(word.freq),freq=word.freq,min.freq = 3, max.words = 70, col=mypal, random.order = FALSE, scale(4,0.2))
wordcloud(names(word.freq),freq=word.freq,min.freq = 3, max.words = 70, col=mypal, random.order = FALSE, scale(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, col=mypal, random.order = FALSE, scale(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, col=mypal, random.order = FALSE, scale=c(4,0.2))
mypal<-brewer.pal(8,"Pastel2")
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, col=mypal, random.order = FALSE, scale=c(4,0.2))
mypal<-brewer.pal(8,"Accent")
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, col=mypal, random.order = FALSE, scale=c(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 40, col=mypal, random.order = FALSE, scale=c(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 25, col=mypal, random.order = FALSE, scale=c(4,0.2))
mypal<-brewer.pal(8,"Set3")
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 25, col=mypal, random.order = FALSE, scale=c(4,0.2))
mypal<-brewer.pal(8,"Paired")
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 25, col=mypal, random.order = FALSE, scale=c(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 50, col=mypal, random.order = FALSE, scale=c(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 100, col=mypal, random.order = FALSE, scale=c(4,0.2))
#미국 twitter 학생들 대화로그 : k-means 클러스터링
teens<-read.csv("Data/sns.csv")
str(teens)
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 300, col=mypal, random.order = FALSE, scale=c(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 300, col=mypal, random.order = FALSE, scale=c(4,0.2))
wordcloud(names(word.freq),freq=word.freq, min.freq = 3, max.words = 200, col=mypal, random.order = FALSE, scale=c(4,0.2))
table(teens$gender)
table(teens$gender, useNA = "ifany")
#데이터는 최대한 살리는 게 좋다
summary(teens$age
)
#데이터는 최대한 살리는 게 좋다
summary(teens$age)
boxplot(teens$age)
head(sort(teens$age))
head(sort(teens$age, decreasing = TRUE))
teens$age<-ifelse(teens$age>13 & teens$age<20,teens$age,NA)
boxplot(teens$age)
#데이터는 최대한 살리는 게 좋다
#teens$age를 보면 뭔가 이상치가 많다?
summary(teens$age)
teens$female<-ifelse(teens$gender=="F",1,0)
table(teens$female)
#teens$female<-ifelse(teens$gender=="F",1,0)
teens$female<-ifelse(teens$gender=="F" & !is.na(teens$gender),1,0)
table(teens$female)
teens$nogender<-ifelse(is.na(teens$gender),1,0)
table(teens$nogender)
mean(teens$age)
mean(teens$age, na.rm = TRUE)
table(teens$gradyear)
#서머리 함수 (데이터, y~x, 함수수)
aggregate(data=teens,age~gradyear,mean)
#서머리 함수 (데이터, y~x, 함수수)
aggregate(data=teens,age~gradyear,mean,na.rm=TRUE)
ave(teens$age, teens$gradyear, FUN=function(x) mean(x,na.rm = TRUE))
class(aggregate(data=teens,age~gradyear,mean,na.rm=TRUE))
#ave(함수를 적용할 데이터, 기준, 함수)
ave_age<-ave(teens$age, teens$gradyear, FUN=function(x) mean(x,na.rm = TRUE))
#벡터로 출력
ave_age
#서머리 함수 (데이터, y~x, 함수)
aggregate(data=teens,age~gradyear,mean,na.rm=TRUE)
#서머리 함수 (데이터, y~x, 함수)
df<-aggregate(data=teens,age~gradyear,mean,na.rm=TRUE)
df %>% filter(gradyear==2006)
#벡터로 출력
class(ave_age)
summary(teens$age)
teens$age<-ifelse(is.na(teens$age),ave_age,teens$age)
summary(teens$age)
str(teens)
teens[5:40]
interests<-teens[5:40]
teens[,5:40]
teens[5:40,]
teens[,5:40]
lapply(interests, scale)
interests_z<-as.data.frame(lapply(interests, scale))
interests_z
#클러스터링 하자!
set.seed(2019527)
teen_clusters<-kmeans(interests_z,centers = 5)
teen_clusters
str(teen_clusters)
teen_clusters$size
teen_clusters$cluster
teen_clusters$size
teen_clusters$centers
#클러스터링 하자!
#시드 주고
set.seed(21424)
#kmeans 함수 활용
teen_clusters<-kmeans(interests_z,centers=5)
teen_clusters
str(teen_clusters)
teen_clusters$size
teen_clusters$cluster
teen_clusters$centers
#클러스터링 하자!
#시드 주고
set.seed(2345)
#kmeans 함수 활용
teen_clusters<-kmeans(interests_z,centers=5)
teen_clusters
str(teen_clusters)
str(teen_clusters)
teen_clusters
str(teen_clusters)
teen_clusters$size
teen_clusters$cluster
teen_clusters$centers
teens$cluster<-teen_clusters$centers
teen$cluster<-teen_clusters$centers
teen_clusters$clustercen<-teen_clusters$centers
teen_clusters[1:5,]
teens[1:5,]
str(teen_clusters)
table(teen_clusters$cluster)
#각 클러스터의 나이 평균값 출력
df_teen_cluster<-as.data.frame(teen_clusters)
str(teen_clusters)
teens$cluster<-teen_clusters$cluster
str(teens)
teens %>%
group_by(cluster) %>%
summarise(meanAge=mean(age))
#각 클러스터의 나이 평균값 출력
teen_clusters
#aggregate 함수
aggregate(data=teens,age~cluster,mean)
aggregate(data=teens,female~cluster,mean)
#ave 함수
ave_age<-ave(x=teens$age, y=teens$cluster, FUN=function(x) mean(x,na.rm = TRUE))
ave_age
aggregate(data=teens,female~cluster,mean)
aggregate(data=teens,friends~cluster,mean)
library(tm)
library(KoNLP)
library(rJava)
library(stringr)
mytextlocation<-"Data/논문"
mypaper<-VCorpus(DirSource(mytextlocation))
mypaper
#코퍼스 안 통째로 처리 : tm_map
mycorpus<-tm_map(mypaper,removeNumbers)
mycorpus<-tm_map(mypaper,removePunctuation)
mytemp<-lapply(mycorpus,function(x){
str_replace_all(x,"[[:digit:]]*|[[:punct:]]*","")
})
mypaper
mypaper[[1]]
mypaper[[1]]$content
mytemp<-lapply(mypaper,function(x){
str_replace_all(x,"[[:digit:]]*|[[:punct:]]*","")
})
mytemp[[1]]
mytemp<-lapply(mypaper,function(x){
str_replace_all(x,"[[:digit:]]{1,}|[[:punct:]]{1,}","")
})
mytemp[[1]]
myNounFun<-function(mytext){
myNounList<-paste(extractNoun(mytext), collapse = " ")
return(myNounList)
}
myNounListRes<-myNounFun(mytemp)
myNounListRes
mytemp<-lapply(mypaper,function(x){
str_replace_all(x,"[[:digit:]]{1,}|[[:punct:]]{1,}|[[:lower:]]","")
})
mypaper[[1]]$content
mytemp<-lapply(mypaper,function(x){
str_replace_all(x,"[[:digit:]]{1,}|[[:punct:]]{1,}|[[:lower:]]{1,}","")
})
myNounListRes<-myNounFun(mytemp[[1]])
myNounListRes
mytemp
str(mytemp)
myNounCorpus<-mytemp
myNounCorpus<-mycorpus
for(i in 1:length(mytemp)){
myNounCorpus[[i]]$content<-mytemp[[i]]
}
myNounCorpus[[1]]$content
mytemp[[1]]
for(i in 1:length(mytemp)){
myNounCorpus[[i]]$content<-myNounFun(mycorpus[[i]]$content)
}
myNounCorpus[[1]]$content
#그리구 이 myNounCorpus로 n-gram 사용
ngram.tdm<-TermDocumentMatrix(myNounCorpus[[1]]$content)
library(RWeka)
biandtrigramTokenizer<-function(x){
NGramTokenizer(x,Weka_control(min=2,max=3))
}
ngram.tdm<-TermDocumentMatrix(myNounCorpus,control = list(tokenize=biandtrigramTokenizer))
ngram.tdm
inspect(ngram.tdm)
str(ngram.tm)
str(ngram.tdm)
ngram.tdm$dimnames$Terms
ngram.tdm$dimnames$Docs
sort(ngram.tdm$dimnames$Terms,decreasing = TRUE)
sort(ngram.tdm,decreasing = TRUE)
inspect(ngram.tdm)
sort(inspect(ngram.tdm),decreasing = TRUE)
sort(ngram.tdm$dimnames$Terms,decreasing = TRUE)
