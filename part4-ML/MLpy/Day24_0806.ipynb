{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day24_0806.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0zwWf2ig8eX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R9lq3tKmdcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3d3a0e4c-5b1a-4d25-80ea-0987a32c4da9"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnEW_lqHmxjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuJdbFpbnBDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# graph에 있는 모든 tensor 초기화!\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28*28])\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "w1 = tf.get_variable(name=\"w1\", shape=[28*28, 16*16],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([16*16]))\n",
        "L1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
        "\n",
        "w2 = tf.get_variable(name=\"w2\", shape=[16*16, 16*16],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([16*16]))\n",
        "L2 = tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
        "\n",
        "w3 = tf.get_variable(name=\"w3\", shape=[16*16, 10],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "hf = tf.matmul(L2,w3)+b3\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y))\n",
        "\n",
        "train = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97TQlxEDpC5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "6840ba25-b881-4e8a-f51a-422c05c0c413"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples/batch_size)\n",
        "    for i in range(total_batch):\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      myfeed = {x:batch_xs, y:batch_ys}\n",
        "      cv, _ = sess.run([cost, train], feed_dict=myfeed)\n",
        "      avg_cost += cv/total_batch\n",
        "    print(\"cost: {:.9f}\".format(avg_cost))\n",
        "    \n",
        "  c_pre = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))\n",
        "  acc = tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
        "  print(\"acc: {}\".format(sess.run(acc, feed_dict={x:mnist.test.images,y:mnist.test.labels})))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost: 0.304808350\n",
            "cost: 0.110608818\n",
            "cost: 0.072338051\n",
            "cost: 0.053155470\n",
            "cost: 0.038621707\n",
            "cost: 0.029877179\n",
            "cost: 0.022208641\n",
            "cost: 0.018917425\n",
            "cost: 0.016415381\n",
            "cost: 0.015246934\n",
            "cost: 0.012983449\n",
            "cost: 0.010256912\n",
            "cost: 0.011718637\n",
            "cost: 0.010002678\n",
            "cost: 0.007746778\n",
            "acc: 0.9799000024795532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtTnpXIiv_to",
        "colab_type": "text"
      },
      "source": [
        "# 이래저래 바꿔보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSNTX3j6upBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# graph에 있는 모든 tensor 초기화!\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28*28])\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "w1 = tf.get_variable(name=\"w1\", shape=[28*28, 512],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([512]))\n",
        "L1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
        "\n",
        "w2 = tf.get_variable(name=\"w2\", shape=[512, 512],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([512]))\n",
        "L2 = tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
        "\n",
        "w3 = tf.get_variable(name=\"w3\", shape=[512, 512],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([512]))\n",
        "L3 = tf.nn.relu(tf.matmul(L2,w3)+b3)\n",
        "\n",
        "w4 = tf.get_variable(name=\"w4\", shape=[512, 256],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b4 = tf.Variable(tf.random_normal([256]))\n",
        "L4 = tf.nn.relu(tf.matmul(L3,w4)+b4)\n",
        "\n",
        "w5 = tf.get_variable(name=\"w5\", shape=[256, 10],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "hf = tf.matmul(L4,w5)+b5\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y))\n",
        "\n",
        "train = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu_OkBukwlyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "1d472dd0-c9be-402a-e3bb-fa222359dee9"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples/batch_size)\n",
        "    for i in range(total_batch):\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      myfeed = {x:batch_xs, y:batch_ys}\n",
        "      cv, _ = sess.run([cost, train], feed_dict=myfeed)\n",
        "      avg_cost += cv/total_batch\n",
        "    print(\"cost: {:.9f}\".format(avg_cost))\n",
        "    \n",
        "  c_pre = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))\n",
        "  acc = tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
        "  print(\"acc: {}\".format(sess.run(acc, feed_dict={x:mnist.test.images,y:mnist.test.labels})))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost: 0.302022672\n",
            "cost: 0.102606575\n",
            "cost: 0.067886870\n",
            "cost: 0.051074103\n",
            "cost: 0.039023360\n",
            "cost: 0.031265473\n",
            "cost: 0.031841049\n",
            "cost: 0.023885246\n",
            "cost: 0.022906675\n",
            "cost: 0.020802240\n",
            "cost: 0.020642349\n",
            "cost: 0.015204034\n",
            "cost: 0.017492373\n",
            "cost: 0.015104875\n",
            "cost: 0.013471740\n",
            "acc: 0.9768000245094299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ib4GwoOxKC0",
        "colab_type": "text"
      },
      "source": [
        "# 지금 또 올려보는 건 쉽지 않다 : DropOut을 써보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgMmhalvwnAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "# graph에 있는 모든 tensor 초기화!\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28*28])\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "w1 = tf.get_variable(name=\"w1\", shape=[28*28, 512],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([512]))\n",
        "L1 = tf.nn.relu(tf.matmul(x,w1)+b1)\n",
        "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
        "\n",
        "w2 = tf.get_variable(name=\"w2\", shape=[512, 512],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([512]))\n",
        "L2 = tf.nn.relu(tf.matmul(L1,w2)+b2)\n",
        "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
        "\n",
        "w3 = tf.get_variable(name=\"w3\", shape=[512, 512],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([512]))\n",
        "L3 = tf.nn.relu(tf.matmul(L2,w3)+b3)\n",
        "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
        "\n",
        "w4 = tf.get_variable(name=\"w4\", shape=[512, 256],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b4 = tf.Variable(tf.random_normal([256]))\n",
        "L4 = tf.nn.relu(tf.matmul(L3,w4)+b4)\n",
        "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
        "\n",
        "w5 = tf.get_variable(name=\"w5\", shape=[256, 10],\\\n",
        "                          initializer = tf.contrib.layers.xavier_initializer())\n",
        "b5 = tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "hf = tf.matmul(L4,w5)+b5\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y))\n",
        "\n",
        "train = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU9XJNjGyBTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "a8a7b8c7-d314-4448-cd39-ea80790a39bd"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples/batch_size)\n",
        "    for i in range(total_batch):\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      myfeed = {x:batch_xs, y:batch_ys, keep_prob:0.7}\n",
        "      cv, _ = sess.run([cost, train], feed_dict=myfeed)\n",
        "      avg_cost += cv/total_batch\n",
        "    print(\"cost: {:.9f}\".format(avg_cost))\n",
        "    \n",
        "  c_pre = tf.equal(tf.argmax(hf,1), tf.argmax(y,1))\n",
        "  acc = tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
        "  print(\"acc: {}\".format(sess.run(acc, feed_dict={x:mnist.test.images,y:mnist.test.labels, keep_prob:1})))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost: 0.500910477\n",
            "cost: 0.182771434\n",
            "cost: 0.136398696\n",
            "cost: 0.113254147\n",
            "cost: 0.096473727\n",
            "cost: 0.084625482\n",
            "cost: 0.077895638\n",
            "cost: 0.070867133\n",
            "cost: 0.062645742\n",
            "cost: 0.059896115\n",
            "cost: 0.057252226\n",
            "cost: 0.053166115\n",
            "cost: 0.049032745\n",
            "cost: 0.048748272\n",
            "cost: 0.045094899\n",
            "acc: 0.9804999828338623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_S_JTooyNi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mnist model based"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmYwntxYm0tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 250\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCv_wUjRm7V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None,28*28]) \n",
        "ximg = tf.reshape(x, [-1, 28, 28, 1]) # img batch*28*28*1(black/white)\n",
        "# input(ximg) : batch , in_height, in_width, in_channels\n",
        "y = tf.placeholder(tf.float32, [None,10])\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "keep_prob_flatten = tf.placeholder(tf.float32)\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([2,2,1,32]))\n",
        "# filter(w) : filter_height, filter_width, in_channels, out_channels 형식으로 준비\n",
        "L1 = tf.nn.conv2d(ximg, w1, strides=[1,1,1,1], padding='SAME') \n",
        "# 양 끝은 고정, 가운데 두개만 상하,좌우 / SAME 하면 같은 크기\n",
        "# 요 conv2d를 하고 나면 batch * height * width * filter의 Tensor가 return됨\n",
        "L1 = tf.nn.relu(L1)\n",
        "# w1_1 = tf.Variable(tf.random_normal([2,2,32,32]))\n",
        "# L1_1 = tf.nn.conv2d(L1, w1, strides=[1,1,1,1], padding='SAME') \n",
        "# L1_1 = tf.nn.relu(L1_1)\n",
        "L1_1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "L1_1 = tf.nn.dropout(L1_1, keep_prob=keep_prob)\n",
        "# L1 이미지 shape => (?, 28, 28, 1)\n",
        "# conv => (?,28,28,32)\n",
        "# relu => (?, 28, 28, 32)\n",
        "# pooling => (?, 14, 14, 32)\n",
        "\n",
        "w2 = tf.Variable(tf.random_normal([3,3,32,64]))\n",
        "L2 = tf.nn.conv2d(L1_1, w2, strides=[1,1,1,1], padding='SAME') \n",
        "L2 = tf.nn.relu(L2)\n",
        "# w2_1 = tf.Variable(tf.random_normal([3,3,64,64]))\n",
        "# L2_1 = tf.nn.conv2d(L2, w2_1, strides=[1,1,1,1], padding='SAME') \n",
        "# L2_1 = tf.nn.relu(L2_1)\n",
        "L2_1 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "L2_1 = tf.nn.dropout(L2_1, keep_prob=keep_prob)\n",
        "\n",
        "# L2 이미지 shape => (?, 14, 14, 32)\n",
        "# conv => (?,14,14,64)\n",
        "# relu => (?, 14, 14, 64)\n",
        "# pooling => (?, 7, 7, 64)\n",
        "# reshape => (?, 7*7*64)\n",
        "\n",
        "w3 = tf.Variable(tf.random_normal([3,3,64,128]))\n",
        "L3 = tf.nn.conv2d(L2_1, w3, strides=[1,1,1,1], padding='SAME') \n",
        "L3 = tf.nn.relu(L3)\n",
        "# w3_1 = tf.Variable(tf.random_normal([3,3,128,128]))\n",
        "# L3_1 = tf.nn.conv2d(L3, w3_1, strides=[1,1,1,1], padding='SAME') \n",
        "# L3_1 = tf.nn.relu(L3_1)\n",
        "L3_1 = tf.nn.max_pool(L3, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
        "L3_1 = tf.nn.dropout(L3_1, keep_prob=keep_prob)\n",
        "\n",
        "L3_flat = tf.reshape(L3_1, [-1,4*4*128])\n",
        "\n",
        "w4 = tf.get_variable(\"w4\", shape=[4*4*128, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([625]))\n",
        "L4 = tf.matmul(L3_flat, w4) + b1\n",
        "L4 = tf.nn.dropout(L4, keep_prob=keep_prob_flatten)\n",
        "\n",
        "w5 = tf.get_variable(\"w5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([10]))\n",
        "logits = tf.matmul(L4, w5) + b2\n",
        "logits = tf.nn.dropout(logits, keep_prob=keep_prob_flatten) \n",
        "\n",
        "c_pre = tf.equal(tf.argmax(logits,1), tf.argmax(y,1))\n",
        "acc = tf.reduce_mean(tf.cast(c_pre, tf.float32))\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits))\n",
        "train = tf.train.RMSPropOptimizer(learning_rate, 0.9).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwyHJwxsoNoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b672919f-381d-4751-cbd8-d80a07be8982"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples/batch_size)\n",
        "    for i in range(total_batch):\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      myfeed = {x:batch_xs, y:batch_ys, keep_prob:0.7, keep_prob_flatten:0.7}\n",
        "      cv, _ = sess.run([cost,train], feed_dict=myfeed)\n",
        "      avg_cost += cv/total_batch\n",
        "    accv = sess.run(acc, feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1,keep_prob_flatten:1})\n",
        "    print(\"cost: {:.9f}, test_acc: {}\".format(avg_cost, accv))\n",
        "\n",
        "  print(\"final_acc: {}\".format(sess.run(acc, feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1,keep_prob_flatten:1})))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost: 701.612975203, test_acc: 0.8959000110626221\n",
            "cost: 16.019158299, test_acc: 0.8398000001907349\n",
            "cost: 3.081187980, test_acc: 0.7818999886512756\n",
            "cost: 1.831232527, test_acc: 0.7318999767303467\n",
            "cost: 1.517682626, test_acc: 0.7272999882698059\n",
            "cost: 1.351400374, test_acc: 0.8341000080108643\n",
            "cost: 1.229608498, test_acc: 0.853600025177002\n",
            "cost: 1.142247755, test_acc: 0.9020000100135803\n",
            "cost: 1.066612816, test_acc: 0.9081000089645386\n",
            "cost: 1.007258495, test_acc: 0.9302999973297119\n",
            "cost: 0.961867248, test_acc: 0.9362000226974487\n",
            "cost: 0.914491587, test_acc: 0.9386000037193298\n",
            "cost: 0.882469982, test_acc: 0.9470000267028809\n",
            "cost: 0.845083625, test_acc: 0.9476000070571899\n",
            "cost: 0.817048594, test_acc: 0.9380000233650208\n",
            "cost: 0.783716107, test_acc: 0.9531999826431274\n",
            "cost: 0.760245128, test_acc: 0.9624999761581421\n",
            "cost: 0.742029335, test_acc: 0.9592999815940857\n",
            "cost: 0.720276666, test_acc: 0.9581999778747559\n",
            "cost: 0.693798021, test_acc: 0.9652000069618225\n",
            "cost: 0.681780291, test_acc: 0.9677000045776367\n",
            "cost: 0.659852578, test_acc: 0.9688000082969666\n",
            "cost: 0.650491647, test_acc: 0.9718999862670898\n",
            "cost: 0.630800199, test_acc: 0.9767000079154968\n",
            "cost: 0.624627397, test_acc: 0.977400004863739\n",
            "cost: 0.613459194, test_acc: 0.9775000214576721\n",
            "cost: 0.596290587, test_acc: 0.9783999919891357\n",
            "cost: 0.587783563, test_acc: 0.9779000282287598\n",
            "cost: 0.580013668, test_acc: 0.978600025177002\n",
            "cost: 0.575172437, test_acc: 0.9800999760627747\n",
            "cost: 0.565441886, test_acc: 0.9801999926567078\n",
            "cost: 0.553234108, test_acc: 0.975600004196167\n",
            "cost: 0.553712987, test_acc: 0.9793000221252441\n",
            "cost: 0.546662158, test_acc: 0.982200026512146\n",
            "cost: 0.541554789, test_acc: 0.9829999804496765\n",
            "cost: 0.538731744, test_acc: 0.9790999889373779\n",
            "cost: 0.539767365, test_acc: 0.9819999933242798\n",
            "cost: 0.536701014, test_acc: 0.9836000204086304\n",
            "cost: 0.534750434, test_acc: 0.9830999970436096\n",
            "cost: 0.530474299, test_acc: 0.9796000123023987\n",
            "cost: 0.532236012, test_acc: 0.9801999926567078\n",
            "cost: 0.532667382, test_acc: 0.9836000204086304\n",
            "cost: 0.526314309, test_acc: 0.9861999750137329\n",
            "cost: 0.524578452, test_acc: 0.9843000173568726\n",
            "cost: 0.522621629, test_acc: 0.9840999841690063\n",
            "cost: 0.521096689, test_acc: 0.9840999841690063\n",
            "cost: 0.526431108, test_acc: 0.9846000075340271\n",
            "cost: 0.520000861, test_acc: 0.9850999712944031\n",
            "cost: 0.512955391, test_acc: 0.9854000210762024\n",
            "cost: 0.508265338, test_acc: 0.9857000112533569\n",
            "cost: 0.509772604, test_acc: 0.984499990940094\n",
            "cost: 0.509368193, test_acc: 0.9857000112533569\n",
            "cost: 0.513455407, test_acc: 0.9855999946594238\n",
            "cost: 0.512699780, test_acc: 0.9833999872207642\n",
            "cost: 0.509726508, test_acc: 0.9872999787330627\n",
            "cost: 0.509131315, test_acc: 0.9840999841690063\n",
            "cost: 0.509591122, test_acc: 0.9825999736785889\n",
            "cost: 0.502529215, test_acc: 0.9853000044822693\n",
            "cost: 0.505587105, test_acc: 0.9869999885559082\n",
            "cost: 0.501921932, test_acc: 0.9879999756813049\n",
            "cost: 0.501555957, test_acc: 0.9884999990463257\n",
            "cost: 0.498064175, test_acc: 0.9866999983787537\n",
            "cost: 0.503501345, test_acc: 0.9883000254631042\n",
            "cost: 0.492579809, test_acc: 0.9869999885559082\n",
            "cost: 0.495552570, test_acc: 0.9884999990463257\n",
            "cost: 0.493490305, test_acc: 0.9876000285148621\n",
            "cost: 0.486992710, test_acc: 0.9865000247955322\n",
            "cost: 0.495086294, test_acc: 0.9884999990463257\n",
            "cost: 0.490188230, test_acc: 0.986299991607666\n",
            "cost: 0.489283353, test_acc: 0.9865000247955322\n",
            "cost: 0.495784289, test_acc: 0.9872000217437744\n",
            "cost: 0.487292601, test_acc: 0.9858999848365784\n",
            "cost: 0.489884327, test_acc: 0.9866999983787537\n",
            "cost: 0.491428072, test_acc: 0.9861999750137329\n",
            "cost: 0.490009838, test_acc: 0.9864000082015991\n",
            "cost: 0.489060206, test_acc: 0.9861999750137329\n",
            "cost: 0.493923897, test_acc: 0.9861999750137329\n",
            "cost: 0.486052972, test_acc: 0.9879000186920166\n",
            "cost: 0.488878447, test_acc: 0.9866999983787537\n",
            "cost: 0.481737015, test_acc: 0.9869999885559082\n",
            "cost: 0.480995272, test_acc: 0.9883999824523926\n",
            "cost: 0.476613939, test_acc: 0.9890000224113464\n",
            "cost: 0.485143029, test_acc: 0.9884999990463257\n",
            "cost: 0.488056303, test_acc: 0.9879000186920166\n",
            "cost: 0.481496507, test_acc: 0.9884999990463257\n",
            "cost: 0.480497130, test_acc: 0.9882000088691711\n",
            "cost: 0.483082479, test_acc: 0.9898999929428101\n",
            "cost: 0.479083212, test_acc: 0.9883999824523926\n",
            "cost: 0.481722047, test_acc: 0.9882000088691711\n",
            "cost: 0.485618777, test_acc: 0.9882000088691711\n",
            "cost: 0.484221214, test_acc: 0.9897000193595886\n",
            "cost: 0.479958374, test_acc: 0.9879000186920166\n",
            "cost: 0.479574968, test_acc: 0.9876000285148621\n",
            "cost: 0.478902132, test_acc: 0.9891999959945679\n",
            "cost: 0.476982152, test_acc: 0.9884999990463257\n",
            "cost: 0.480486180, test_acc: 0.9889000058174133\n",
            "cost: 0.478434212, test_acc: 0.9872999787330627\n",
            "cost: 0.479894659, test_acc: 0.9879999756813049\n",
            "cost: 0.471998073, test_acc: 0.989799976348877\n",
            "cost: 0.473143013, test_acc: 0.9891999959945679\n",
            "cost: 0.480222191, test_acc: 0.989799976348877\n",
            "cost: 0.479319972, test_acc: 0.989300012588501\n",
            "cost: 0.478959514, test_acc: 0.9884999990463257\n",
            "cost: 0.475992237, test_acc: 0.9889000058174133\n",
            "cost: 0.470503658, test_acc: 0.9894999861717224\n",
            "cost: 0.475745119, test_acc: 0.9879999756813049\n",
            "cost: 0.475561692, test_acc: 0.989300012588501\n",
            "cost: 0.471476877, test_acc: 0.9886999726295471\n",
            "cost: 0.479064289, test_acc: 0.9890999794006348\n",
            "cost: 0.471909764, test_acc: 0.9883000254631042\n",
            "cost: 0.469116002, test_acc: 0.9894999861717224\n",
            "cost: 0.472947306, test_acc: 0.9883000254631042\n",
            "cost: 0.467292811, test_acc: 0.9886999726295471\n",
            "cost: 0.474500695, test_acc: 0.9896000027656555\n",
            "cost: 0.471984568, test_acc: 0.9886999726295471\n",
            "cost: 0.469154508, test_acc: 0.9897000193595886\n",
            "cost: 0.468574831, test_acc: 0.9854999780654907\n",
            "cost: 0.472484153, test_acc: 0.9851999878883362\n",
            "cost: 0.468386830, test_acc: 0.9897000193595886\n",
            "cost: 0.464772312, test_acc: 0.9890000224113464\n",
            "cost: 0.473002504, test_acc: 0.9865999817848206\n",
            "cost: 0.472752188, test_acc: 0.989799976348877\n",
            "cost: 0.468760030, test_acc: 0.9898999929428101\n",
            "cost: 0.464474548, test_acc: 0.9878000020980835\n",
            "cost: 0.461529294, test_acc: 0.9898999929428101\n",
            "cost: 0.466745143, test_acc: 0.9894000291824341\n",
            "cost: 0.467265507, test_acc: 0.987500011920929\n",
            "cost: 0.468364205, test_acc: 0.9890999794006348\n",
            "cost: 0.464467327, test_acc: 0.9887999892234802\n",
            "cost: 0.462088796, test_acc: 0.9891999959945679\n",
            "cost: 0.467235594, test_acc: 0.9900000095367432\n",
            "cost: 0.463704884, test_acc: 0.9896000027656555\n",
            "cost: 0.463346368, test_acc: 0.9898999929428101\n",
            "cost: 0.470429206, test_acc: 0.9900000095367432\n",
            "cost: 0.465971512, test_acc: 0.9901999831199646\n",
            "cost: 0.462917635, test_acc: 0.9912999868392944\n",
            "cost: 0.468292773, test_acc: 0.9904999732971191\n",
            "cost: 0.468070377, test_acc: 0.9898999929428101\n",
            "cost: 0.466633005, test_acc: 0.9896000027656555\n",
            "cost: 0.457819370, test_acc: 0.9902999997138977\n",
            "cost: 0.469800109, test_acc: 0.9890999794006348\n",
            "cost: 0.464468636, test_acc: 0.9890999794006348\n",
            "cost: 0.463084290, test_acc: 0.9901000261306763\n",
            "cost: 0.458104878, test_acc: 0.9894999861717224\n",
            "cost: 0.460563117, test_acc: 0.9884999990463257\n",
            "cost: 0.461731515, test_acc: 0.989300012588501\n",
            "cost: 0.457357385, test_acc: 0.9886999726295471\n",
            "cost: 0.458961421, test_acc: 0.9887999892234802\n",
            "cost: 0.459849658, test_acc: 0.9902999997138977\n",
            "cost: 0.461813257, test_acc: 0.9898999929428101\n",
            "cost: 0.458415605, test_acc: 0.9896000027656555\n",
            "cost: 0.468415419, test_acc: 0.9876000285148621\n",
            "cost: 0.462281438, test_acc: 0.9902999997138977\n",
            "cost: 0.469594186, test_acc: 0.9898999929428101\n",
            "cost: 0.463218599, test_acc: 0.9883999824523926\n",
            "cost: 0.461825351, test_acc: 0.989300012588501\n",
            "cost: 0.460481934, test_acc: 0.9890999794006348\n",
            "cost: 0.456954571, test_acc: 0.9883000254631042\n",
            "cost: 0.460558845, test_acc: 0.9896000027656555\n",
            "cost: 0.453867748, test_acc: 0.9896000027656555\n",
            "cost: 0.460026121, test_acc: 0.9900000095367432\n",
            "cost: 0.466313192, test_acc: 0.9907000064849854\n",
            "cost: 0.454435232, test_acc: 0.9886999726295471\n",
            "cost: 0.462100126, test_acc: 0.9901999831199646\n",
            "cost: 0.456044124, test_acc: 0.9894000291824341\n",
            "cost: 0.457854259, test_acc: 0.9911999702453613\n",
            "cost: 0.455767453, test_acc: 0.989799976348877\n",
            "cost: 0.461768070, test_acc: 0.9896000027656555\n",
            "cost: 0.457555240, test_acc: 0.9894000291824341\n",
            "cost: 0.457485401, test_acc: 0.9909999966621399\n",
            "cost: 0.465804735, test_acc: 0.9890000224113464\n",
            "cost: 0.457105791, test_acc: 0.9890999794006348\n",
            "cost: 0.456145593, test_acc: 0.9901999831199646\n",
            "cost: 0.456005381, test_acc: 0.9902999997138977\n",
            "cost: 0.453206753, test_acc: 0.9898999929428101\n",
            "cost: 0.455955395, test_acc: 0.9902999997138977\n",
            "cost: 0.460034269, test_acc: 0.9905999898910522\n",
            "cost: 0.460627657, test_acc: 0.9908000230789185\n",
            "cost: 0.461054674, test_acc: 0.991100013256073\n",
            "cost: 0.458363510, test_acc: 0.9898999929428101\n",
            "cost: 0.455464054, test_acc: 0.989300012588501\n",
            "cost: 0.459840327, test_acc: 0.9883999824523926\n",
            "cost: 0.460801255, test_acc: 0.9894000291824341\n",
            "cost: 0.455197497, test_acc: 0.9901999831199646\n",
            "cost: 0.455671633, test_acc: 0.9907000064849854\n",
            "cost: 0.450717707, test_acc: 0.989799976348877\n",
            "cost: 0.454733181, test_acc: 0.9890999794006348\n",
            "cost: 0.457866846, test_acc: 0.9902999997138977\n",
            "cost: 0.456453471, test_acc: 0.9915000200271606\n",
            "cost: 0.452754626, test_acc: 0.9898999929428101\n",
            "cost: 0.456427570, test_acc: 0.9904000163078308\n",
            "cost: 0.456174981, test_acc: 0.9907000064849854\n",
            "cost: 0.460769611, test_acc: 0.989799976348877\n",
            "cost: 0.458169090, test_acc: 0.9915000200271606\n",
            "cost: 0.453115115, test_acc: 0.9891999959945679\n",
            "cost: 0.456368351, test_acc: 0.9896000027656555\n",
            "cost: 0.451915038, test_acc: 0.9909999966621399\n",
            "cost: 0.449431891, test_acc: 0.9905999898910522\n",
            "cost: 0.455900579, test_acc: 0.9898999929428101\n",
            "cost: 0.445882390, test_acc: 0.9901999831199646\n",
            "cost: 0.449098793, test_acc: 0.9886000156402588\n",
            "cost: 0.453315443, test_acc: 0.9886000156402588\n",
            "cost: 0.455167358, test_acc: 0.9908999800682068\n",
            "cost: 0.455789285, test_acc: 0.9894999861717224\n",
            "cost: 0.451888375, test_acc: 0.9907000064849854\n",
            "cost: 0.449880189, test_acc: 0.991100013256073\n",
            "cost: 0.456821137, test_acc: 0.9916999936103821\n",
            "cost: 0.453725558, test_acc: 0.9908000230789185\n",
            "cost: 0.449124604, test_acc: 0.9897000193595886\n",
            "cost: 0.451745483, test_acc: 0.9901999831199646\n",
            "cost: 0.454695777, test_acc: 0.9904999732971191\n",
            "cost: 0.455500082, test_acc: 0.9911999702453613\n",
            "cost: 0.451012216, test_acc: 0.9904999732971191\n",
            "cost: 0.453412671, test_acc: 0.991100013256073\n",
            "cost: 0.448813963, test_acc: 0.9896000027656555\n",
            "cost: 0.454051625, test_acc: 0.9886000156402588\n",
            "cost: 0.450042755, test_acc: 0.9909999966621399\n",
            "cost: 0.445717902, test_acc: 0.9915000200271606\n",
            "cost: 0.452013045, test_acc: 0.9904000163078308\n",
            "cost: 0.447774748, test_acc: 0.9902999997138977\n",
            "cost: 0.456773577, test_acc: 0.989300012588501\n",
            "cost: 0.447433504, test_acc: 0.989799976348877\n",
            "cost: 0.444705332, test_acc: 0.989300012588501\n",
            "cost: 0.446377608, test_acc: 0.9909999966621399\n",
            "cost: 0.453733842, test_acc: 0.9912999868392944\n",
            "cost: 0.451619527, test_acc: 0.9907000064849854\n",
            "cost: 0.446750419, test_acc: 0.9912999868392944\n",
            "cost: 0.448782087, test_acc: 0.9889000058174133\n",
            "cost: 0.447227272, test_acc: 0.9915000200271606\n",
            "cost: 0.448774391, test_acc: 0.9902999997138977\n",
            "cost: 0.447305146, test_acc: 0.9911999702453613\n",
            "cost: 0.445968723, test_acc: 0.991100013256073\n",
            "cost: 0.445208557, test_acc: 0.9886999726295471\n",
            "cost: 0.443393875, test_acc: 0.9908999800682068\n",
            "cost: 0.445671677, test_acc: 0.9901000261306763\n",
            "cost: 0.440273779, test_acc: 0.9914000034332275\n",
            "cost: 0.447385940, test_acc: 0.9916999936103821\n",
            "cost: 0.448333340, test_acc: 0.991100013256073\n",
            "cost: 0.443018208, test_acc: 0.991599977016449\n",
            "cost: 0.451560191, test_acc: 0.9901000261306763\n",
            "cost: 0.439508730, test_acc: 0.989799976348877\n",
            "cost: 0.445623108, test_acc: 0.991100013256073\n",
            "cost: 0.448334137, test_acc: 0.9918000102043152\n",
            "cost: 0.444904469, test_acc: 0.9922000169754028\n",
            "cost: 0.449831455, test_acc: 0.9907000064849854\n",
            "cost: 0.450812251, test_acc: 0.9897000193595886\n",
            "cost: 0.444146379, test_acc: 0.9911999702453613\n",
            "cost: 0.444787944, test_acc: 0.9914000034332275\n",
            "cost: 0.446904538, test_acc: 0.991599977016449\n",
            "cost: 0.452522560, test_acc: 0.9904999732971191\n",
            "final_acc: 0.9904999732971191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-60VZBrtVDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9c941f9-cb3a-4df1-dcdf-a98971881152"
      },
      "source": [
        "ximg"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Reshape:0' shape=(?, 28, 28, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py77WmwZt8hf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27c00817-c244-4caf-e846-a45f4d70b20d"
      },
      "source": [
        "mnist.test.labels.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDvjYUaXuw10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}