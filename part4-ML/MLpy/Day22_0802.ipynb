{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape # (8,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.28659973e+02, 8.33450012e+02, 9.08100000e+05, 8.28349976e+02],\n",
       "       [8.23020020e+02, 8.28070007e+02, 1.82810000e+06, 8.21655029e+02],\n",
       "       [8.19929993e+02, 8.24400024e+02, 1.43810000e+06, 8.18979980e+02],\n",
       "       [8.16000000e+02, 8.20958984e+02, 1.00810000e+06, 8.15489990e+02],\n",
       "       [8.19359985e+02, 8.23000000e+02, 1.18810000e+06, 8.18469971e+02],\n",
       "       [8.19000000e+02, 8.23000000e+02, 1.19810000e+06, 8.16000000e+02],\n",
       "       [8.11700012e+02, 8.15250000e+02, 1.09810000e+06, 8.09780029e+02],\n",
       "       [8.09510010e+02, 8.16659973e+02, 1.39810000e+06, 8.04539978e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xy[:,0:-1]\n",
    "xdata.shape\n",
    "ydata = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881783]\n",
      " [0.54412549 0.50274824 0.57608696 0.60646801]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134]\n",
      " [0.51436    0.4258239  0.30434783 0.58504805]\n",
      " [0.49556179 0.4258239  0.31521739 0.48131134]\n",
      " [0.11436064 0.         0.20652174 0.22007776]\n",
      " [0.         0.07747099 0.5326087  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def MyScaler(data): # minmaxscaler : 우리는 열 단위로 scaling해야함\n",
    "    de = np.max(data,axis=0) - np.min(data,axis=0)\n",
    "    num = data - np.min(data,axis=0)\n",
    "    return num/de\n",
    "\n",
    "xdata = MyScaler(xdata)\n",
    "print(xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,4])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "w = tf.Variable(tf.random_normal([4,1]))\n",
    "b = tf.Variable(tf.random_uniform([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.matmul(x,w) + b\n",
    "cost = tf.reduce_mean(tf.square(hf-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 673882.0 hf: [[-2.680429  ]\n",
      " [ 0.11222476]\n",
      " [-0.02307516]\n",
      " [-0.24697673]\n",
      " [-0.29400027]\n",
      " [-0.2690459 ]\n",
      " [ 0.90570927]\n",
      " [ 1.3482906 ]]\n",
      "1 cost: 625954.9 hf: [[36.924522]\n",
      " [39.237785]\n",
      " [32.837963]\n",
      " [25.543995]\n",
      " [29.913795]\n",
      " [28.991325]\n",
      " [21.337702]\n",
      " [21.644001]]\n",
      "2 cost: 581608.06 hf: [[74.98391 ]\n",
      " [76.85808 ]\n",
      " [64.44255 ]\n",
      " [50.359306]\n",
      " [58.96869 ]\n",
      " [57.137375]\n",
      " [41.016273]\n",
      " [41.197212]]\n",
      "3 cost: 540573.1 hf: [[111.556946]\n",
      " [113.03067 ]\n",
      " [ 94.838715]\n",
      " [ 74.23623 ]\n",
      " [ 86.914764]\n",
      " [ 84.2117  ]\n",
      " [ 59.970154]\n",
      " [ 60.0362  ]]\n",
      "4 cost: 502601.88 hf: [[146.70055 ]\n",
      " [147.81091 ]\n",
      " [124.07266 ]\n",
      " [ 97.21063 ]\n",
      " [113.794395]\n",
      " [110.25526 ]\n",
      " [ 78.22697 ]\n",
      " [ 78.18817 ]]\n",
      "5 cost: 467464.5 hf: [[180.4695  ]\n",
      " [181.25204 ]\n",
      " [152.18881 ]\n",
      " [119.31698 ]\n",
      " [139.64838 ]\n",
      " [135.30743 ]\n",
      " [ 95.813286]\n",
      " [ 95.67926 ]]\n",
      "6 cost: 434948.5 hf: [[212.91644 ]\n",
      " [213.40527 ]\n",
      " [179.22989 ]\n",
      " [140.58844 ]\n",
      " [164.51587 ]\n",
      " [159.40616 ]\n",
      " [112.754654]\n",
      " [112.534645]]\n",
      "7 cost: 404857.44 hf: [[244.09204]\n",
      " [244.31985]\n",
      " [205.237  ]\n",
      " [161.05693]\n",
      " [188.43463]\n",
      " [182.58783]\n",
      " [129.07565]\n",
      " [128.7785 ]]\n",
      "8 cost: 377009.44 hf: [[274.04504]\n",
      " [274.04315]\n",
      " [230.24966]\n",
      " [180.75311]\n",
      " [211.44092]\n",
      " [204.88751]\n",
      " [144.79994]\n",
      " [144.43414]]\n",
      "9 cost: 351236.4 hf: [[302.82227]\n",
      " [302.62073]\n",
      " [254.30592]\n",
      " [199.70648]\n",
      " [233.56964]\n",
      " [226.33894]\n",
      " [159.95024]\n",
      " [159.52391]]\n",
      "10 cost: 327382.78 hf: [[330.46875]\n",
      " [330.09637]\n",
      " [277.4423 ]\n",
      " [217.94543]\n",
      " [254.8543 ]\n",
      " [246.97452]\n",
      " [174.5484 ]\n",
      " [174.06934]]\n",
      "11 cost: 305304.72 hf: [[357.0279 ]\n",
      " [356.51227]\n",
      " [299.69397]\n",
      " [235.49725]\n",
      " [275.32718]\n",
      " [266.8254 ]\n",
      " [188.6155 ]\n",
      " [188.09116]]\n",
      "12 cost: 284869.1 hf: [[382.54132]\n",
      " [381.90887]\n",
      " [321.09473]\n",
      " [252.38818]\n",
      " [295.01932]\n",
      " [285.92163]\n",
      " [202.1717 ]\n",
      " [201.60922]]\n",
      "13 cost: 265952.75 hf: [[407.04916]\n",
      " [406.3252 ]\n",
      " [341.6772 ]\n",
      " [268.6435 ]\n",
      " [313.96057]\n",
      " [304.29196]\n",
      " [215.2365 ]\n",
      " [214.64275]]\n",
      "14 cost: 248441.9 hf: [[430.58994]\n",
      " [429.79877]\n",
      " [361.4725 ]\n",
      " [284.2874 ]\n",
      " [332.17963]\n",
      " [321.96423]\n",
      " [227.82858]\n",
      " [227.21011]]\n",
      "15 cost: 232231.19 hf: [[453.2007 ]\n",
      " [452.36557]\n",
      " [380.51086]\n",
      " [299.34332]\n",
      " [349.70407]\n",
      " [338.96506]\n",
      " [239.96597]\n",
      " [239.32906]]\n",
      "16 cost: 217223.17 hf: [[474.9172 ]\n",
      " [474.06033]\n",
      " [398.82114]\n",
      " [313.83368]\n",
      " [366.5605 ]\n",
      " [355.32013]\n",
      " [251.66595]\n",
      " [251.0166 ]]\n",
      "17 cost: 203327.72 hf: [[495.77368]\n",
      " [494.91638]\n",
      " [416.4312 ]\n",
      " [327.7801 ]\n",
      " [382.77444]\n",
      " [371.05414]\n",
      " [262.9452 ]\n",
      " [262.28915]]\n",
      "18 cost: 190461.44 hf: [[515.80316]\n",
      " [514.9658 ]\n",
      " [433.36783]\n",
      " [341.20334]\n",
      " [398.37045]\n",
      " [386.19073]\n",
      " [273.8197 ]\n",
      " [273.16248]]\n",
      "19 cost: 178547.25 hf: [[535.03735]\n",
      " [534.2394 ]\n",
      " [449.6567 ]\n",
      " [354.12338]\n",
      " [413.37216]\n",
      " [400.75287]\n",
      " [284.3048 ]\n",
      " [283.65167]]\n",
      "20 cost: 167513.81 hf: [[553.50665]\n",
      " [552.7669 ]\n",
      " [465.32263]\n",
      " [366.55945]\n",
      " [427.80225]\n",
      " [414.7624 ]\n",
      " [294.41544]\n",
      " [293.77142]]\n",
      "21 cost: 157295.16 hf: [[571.2406 ]\n",
      " [570.57684]\n",
      " [480.38943]\n",
      " [378.53003]\n",
      " [441.68262]\n",
      " [428.2405 ]\n",
      " [304.16574]\n",
      " [303.53568]]\n",
      "22 cost: 147830.22 hf: [[588.2673 ]\n",
      " [587.69666]\n",
      " [494.88   ]\n",
      " [390.05286]\n",
      " [455.03424]\n",
      " [441.20746]\n",
      " [313.56946]\n",
      " [312.95792]]\n",
      "23 cost: 139062.56 hf: [[604.6139 ]\n",
      " [604.1527 ]\n",
      " [508.8163 ]\n",
      " [401.14508]\n",
      " [467.8774 ]\n",
      " [453.6828 ]\n",
      " [322.63977]\n",
      " [322.05118]]\n",
      "24 cost: 130939.98 hf: [[620.3065 ]\n",
      " [619.9704 ]\n",
      " [522.2196 ]\n",
      " [411.82312]\n",
      " [480.23145]\n",
      " [465.68533]\n",
      " [331.38934]\n",
      " [330.82788]]\n",
      "25 cost: 123414.12 hf: [[635.37036]\n",
      " [635.1742 ]\n",
      " [535.1102 ]\n",
      " [422.1028 ]\n",
      " [492.11514]\n",
      " [477.2331 ]\n",
      " [339.83032]\n",
      " [339.30008]]\n",
      "26 cost: 116440.36 hf: [[649.82935]\n",
      " [649.7874 ]\n",
      " [547.5078 ]\n",
      " [431.99933]\n",
      " [503.5464 ]\n",
      " [488.34344]\n",
      " [347.9745 ]\n",
      " [347.47922]]\n",
      "27 cost: 109977.32 hf: [[663.7069 ]\n",
      " [663.8328 ]\n",
      " [559.43115]\n",
      " [441.52728]\n",
      " [514.5426 ]\n",
      " [499.03314]\n",
      " [355.83307]\n",
      " [355.37646]]\n",
      "28 cost: 103986.77 hf: [[677.02527]\n",
      " [677.33215]\n",
      " [570.89844]\n",
      " [450.7008 ]\n",
      " [525.12024]\n",
      " [509.31824]\n",
      " [363.41696]\n",
      " [363.00253]]\n",
      "29 cost: 98433.35 hf: [[689.806  ]\n",
      " [690.30615]\n",
      " [581.92706]\n",
      " [459.53342]\n",
      " [535.29553]\n",
      " [519.21423]\n",
      " [370.73657]\n",
      " [370.36765]]\n",
      "30 cost: 93284.37 hf: [[702.0697 ]\n",
      " [702.77496]\n",
      " [592.53375]\n",
      " [468.0381 ]\n",
      " [545.0836 ]\n",
      " [528.73596]\n",
      " [377.8019 ]\n",
      " [377.4817 ]]\n",
      "31 cost: 88509.56 hf: [[713.8362 ]\n",
      " [714.75793]\n",
      " [602.7346 ]\n",
      " [476.22733]\n",
      " [554.49945]\n",
      " [537.8976 ]\n",
      " [384.62262]\n",
      " [384.3541 ]]\n",
      "32 cost: 84080.9 hf: [[725.12463]\n",
      " [726.27356]\n",
      " [612.5453 ]\n",
      " [484.11322]\n",
      " [563.55725]\n",
      " [546.71313]\n",
      " [391.208  ]\n",
      " [390.9941 ]]\n",
      "33 cost: 79972.53 hf: [[735.9534 ]\n",
      " [737.3399 ]\n",
      " [621.98065]\n",
      " [491.7073 ]\n",
      " [572.2706 ]\n",
      " [555.19556]\n",
      " [397.56696]\n",
      " [397.41043]]\n",
      "34 cost: 76160.49 hf: [[746.3402 ]\n",
      " [747.974  ]\n",
      " [631.05493]\n",
      " [499.02075]\n",
      " [580.6527 ]\n",
      " [563.3578 ]\n",
      " [403.7081 ]\n",
      " [403.61157]]\n",
      "35 cost: 72622.6 hf: [[756.302  ]\n",
      " [758.19244]\n",
      " [639.7821 ]\n",
      " [506.06427]\n",
      " [588.7164 ]\n",
      " [571.21204]\n",
      " [409.6397 ]\n",
      " [409.60565]]\n",
      "36 cost: 69338.4 hf: [[765.85516]\n",
      " [768.01105]\n",
      " [648.1753 ]\n",
      " [512.84814]\n",
      " [596.47363]\n",
      " [578.7699 ]\n",
      " [415.36963]\n",
      " [415.40045]]\n",
      "37 cost: 66288.92 hf: [[775.0154 ]\n",
      " [777.4453 ]\n",
      " [656.24725]\n",
      " [519.38226]\n",
      " [603.93616]\n",
      " [586.04285]\n",
      " [420.9056 ]\n",
      " [421.00354]]\n",
      "38 cost: 63456.62 hf: [[783.7978 ]\n",
      " [786.50964]\n",
      " [664.0104 ]\n",
      " [525.67615]\n",
      " [611.11536]\n",
      " [593.04175]\n",
      " [426.2549 ]\n",
      " [426.4221 ]]\n",
      "39 cost: 60825.293 hf: [[792.2169 ]\n",
      " [795.2185 ]\n",
      " [671.47644]\n",
      " [531.739  ]\n",
      " [618.022  ]\n",
      " [599.777  ]\n",
      " [431.42462]\n",
      " [431.66312]]\n",
      "40 cost: 58379.918 hf: [[800.28674]\n",
      " [803.5852 ]\n",
      " [678.6567 ]\n",
      " [537.5796 ]\n",
      " [624.6664 ]\n",
      " [606.2588 ]\n",
      " [436.42157]\n",
      " [436.73328]]\n",
      "41 cost: 56106.625 hf: [[808.0208 ]\n",
      " [811.6231 ]\n",
      " [685.56213]\n",
      " [543.2065 ]\n",
      " [631.0587 ]\n",
      " [612.49664]\n",
      " [441.25223]\n",
      " [441.63904]]\n",
      "42 cost: 53992.57 hf: [[815.432  ]\n",
      " [819.3446 ]\n",
      " [692.2033 ]\n",
      " [548.62775]\n",
      " [637.2085 ]\n",
      " [618.5    ]\n",
      " [445.92294]\n",
      " [446.38654]]\n",
      "43 cost: 52025.883 hf: [[822.5327 ]\n",
      " [826.76184]\n",
      " [698.5902 ]\n",
      " [553.8512 ]\n",
      " [643.12506]\n",
      " [624.27783]\n",
      " [450.4397 ]\n",
      " [450.98178]]\n",
      "44 cost: 50195.562 hf: [[829.33496]\n",
      " [833.8865 ]\n",
      " [704.73267]\n",
      " [558.88446]\n",
      " [648.8173 ]\n",
      " [629.8386 ]\n",
      " [454.80838]\n",
      " [455.43048]]\n",
      "45 cost: 48491.465 hf: [[835.8502 ]\n",
      " [840.7298 ]\n",
      " [710.63995]\n",
      " [563.73474]\n",
      " [654.2938 ]\n",
      " [635.1908 ]\n",
      " [459.03455]\n",
      " [459.73813]]\n",
      "46 cost: 46904.18 hf: [[842.08954]\n",
      " [847.3024 ]\n",
      " [716.32104]\n",
      " [568.40906]\n",
      " [659.56287]\n",
      " [640.34216]\n",
      " [463.12354]\n",
      " [463.91003]]\n",
      "47 cost: 45425.004 hf: [[848.06366]\n",
      " [853.61475]\n",
      " [721.78467]\n",
      " [572.91406]\n",
      " [664.6323 ]\n",
      " [645.30054]\n",
      " [467.0806 ]\n",
      " [467.9513 ]]\n",
      "48 cost: 44045.906 hf: [[853.7828 ]\n",
      " [859.67676]\n",
      " [727.03906]\n",
      " [577.2562 ]\n",
      " [669.5099 ]\n",
      " [650.07324]\n",
      " [470.91064]\n",
      " [471.86676]]\n",
      "49 cost: 42759.453 hf: [[859.2566 ]\n",
      " [865.49805]\n",
      " [732.09216]\n",
      " [581.4417 ]\n",
      " [674.20276]\n",
      " [654.66736]\n",
      " [474.61847]\n",
      " [475.6612 ]]\n",
      "50 cost: 41558.734 hf: [[864.4948 ]\n",
      " [871.08777]\n",
      " [736.9518 ]\n",
      " [585.47656]\n",
      " [678.71814]\n",
      " [659.0897 ]\n",
      " [478.2087 ]\n",
      " [479.33917]]\n",
      "51 cost: 40437.4 hf: [[869.5064 ]\n",
      " [876.4549 ]\n",
      " [741.62524]\n",
      " [589.36646]\n",
      " [683.06274]\n",
      " [663.3468 ]\n",
      " [481.6858 ]\n",
      " [482.90497]]\n",
      "52 cost: 39389.555 hf: [[874.3002 ]\n",
      " [881.60785]\n",
      " [746.1196 ]\n",
      " [593.117  ]\n",
      " [687.24316]\n",
      " [667.44507]\n",
      " [485.05392]\n",
      " [486.36282]]\n",
      "53 cost: 38409.75 hf: [[878.88446]\n",
      " [886.5548 ]\n",
      " [750.4419 ]\n",
      " [596.7334 ]\n",
      " [691.2655 ]\n",
      " [671.39044]\n",
      " [488.31726]\n",
      " [489.71677]]\n",
      "54 cost: 37492.938 hf: [[883.26746]\n",
      " [891.3037 ]\n",
      " [754.5986 ]\n",
      " [600.2209 ]\n",
      " [695.136  ]\n",
      " [675.18884]\n",
      " [491.47968]\n",
      " [492.97067]]\n",
      "55 cost: 36634.473 hf: [[887.4569 ]\n",
      " [895.8622 ]\n",
      " [758.59595]\n",
      " [603.5842 ]\n",
      " [698.86035]\n",
      " [678.8458 ]\n",
      " [494.54504]\n",
      " [496.12827]]\n",
      "56 cost: 35830.023 hf: [[891.4603 ]\n",
      " [900.2374 ]\n",
      " [762.44006]\n",
      " [606.82825]\n",
      " [702.4442 ]\n",
      " [682.3668 ]\n",
      " [497.51694]\n",
      " [499.19318]]\n",
      "57 cost: 35075.61 hf: [[895.2849 ]\n",
      " [904.4365 ]\n",
      " [766.13696]\n",
      " [609.95746]\n",
      " [705.8929 ]\n",
      " [685.75696]\n",
      " [500.39886]\n",
      " [502.1688 ]]\n",
      "58 cost: 34367.54 hf: [[898.9376 ]\n",
      " [908.4661 ]\n",
      " [769.6921 ]\n",
      " [612.9762 ]\n",
      " [709.21155]\n",
      " [689.02136]\n",
      " [503.19424]\n",
      " [505.05847]]\n",
      "59 cost: 33702.383 hf: [[902.42505]\n",
      " [912.3329 ]\n",
      " [773.11084]\n",
      " [615.8888 ]\n",
      " [712.4052 ]\n",
      " [692.1647 ]\n",
      " [505.9063 ]\n",
      " [507.86542]]\n",
      "60 cost: 33077.004 hf: [[905.75366]\n",
      " [916.04285]\n",
      " [776.39856]\n",
      " [618.6991 ]\n",
      " [715.4785 ]\n",
      " [695.19165]\n",
      " [508.53812]\n",
      " [510.59265]]\n",
      "61 cost: 32488.467 hf: [[908.9297 ]\n",
      " [919.60205]\n",
      " [779.5602 ]\n",
      " [621.41113]\n",
      " [718.4363 ]\n",
      " [698.1066 ]\n",
      " [511.0927 ]\n",
      " [513.24316]]\n",
      "62 cost: 31934.062 hf: [[911.95886]\n",
      " [923.0165 ]\n",
      " [782.6006 ]\n",
      " [624.02856]\n",
      " [721.2828 ]\n",
      " [700.91394]\n",
      " [513.573  ]\n",
      " [515.8199 ]]\n",
      "63 cost: 31411.3 hf: [[914.84705]\n",
      " [926.2914 ]\n",
      " [785.5243 ]\n",
      " [626.55505]\n",
      " [724.0222 ]\n",
      " [703.6177 ]\n",
      " [515.9817 ]\n",
      " [518.3254 ]]\n",
      "64 cost: 30917.861 hf: [[917.59973]\n",
      " [929.43225]\n",
      " [788.3358 ]\n",
      " [628.994  ]\n",
      " [726.6588 ]\n",
      " [706.22174]\n",
      " [518.32153]\n",
      " [520.7624 ]]\n",
      "65 cost: 30451.602 hf: [[920.22205]\n",
      " [932.4443 ]\n",
      " [791.03955]\n",
      " [631.3488 ]\n",
      " [729.1964 ]\n",
      " [708.73   ]\n",
      " [520.5951 ]\n",
      " [523.1334 ]]\n",
      "66 cost: 30010.541 hf: [[922.7192 ]\n",
      " [935.3323 ]\n",
      " [793.6394 ]\n",
      " [633.6226 ]\n",
      " [731.63885]\n",
      " [711.1461 ]\n",
      " [522.80475]\n",
      " [525.4409 ]]\n",
      "67 cost: 29592.855 hf: [[925.09595]\n",
      " [938.1011 ]\n",
      " [796.1394 ]\n",
      " [635.8185 ]\n",
      " [733.9897 ]\n",
      " [713.4735 ]\n",
      " [524.95294]\n",
      " [527.6872 ]]\n",
      "68 cost: 29196.832 hf: [[927.3571 ]\n",
      " [940.7552 ]\n",
      " [798.5435 ]\n",
      " [637.93945]\n",
      " [736.2525 ]\n",
      " [715.7157 ]\n",
      " [527.042  ]\n",
      " [529.8745 ]]\n",
      "69 cost: 28820.93 hf: [[929.50714]\n",
      " [943.2991 ]\n",
      " [800.8552 ]\n",
      " [639.9882 ]\n",
      " [738.4306 ]\n",
      " [717.87585]\n",
      " [529.074  ]\n",
      " [532.005  ]]\n",
      "70 cost: 28463.666 hf: [[931.55035]\n",
      " [945.7369 ]\n",
      " [803.0781 ]\n",
      " [641.96765]\n",
      " [740.5273 ]\n",
      " [719.95703]\n",
      " [531.05115]\n",
      " [534.0809 ]]\n",
      "71 cost: 28123.709 hf: [[933.49097]\n",
      " [948.0727 ]\n",
      " [805.2157 ]\n",
      " [643.88043]\n",
      " [742.5456 ]\n",
      " [721.9624 ]\n",
      " [532.97546]\n",
      " [536.104  ]]\n",
      "72 cost: 27799.836 hf: [[935.3329 ]\n",
      " [950.3105 ]\n",
      " [807.271  ]\n",
      " [645.72894]\n",
      " [744.4885 ]\n",
      " [723.89465]\n",
      " [534.8488 ]\n",
      " [538.0763 ]]\n",
      "73 cost: 27490.867 hf: [[937.08014]\n",
      " [952.4539 ]\n",
      " [809.2473 ]\n",
      " [647.5157 ]\n",
      " [746.359  ]\n",
      " [725.75684]\n",
      " [536.6732 ]\n",
      " [539.99976]]\n",
      "74 cost: 27195.75 hf: [[938.7363 ]\n",
      " [954.50665]\n",
      " [811.14764]\n",
      " [649.24304]\n",
      " [748.1598 ]\n",
      " [727.5514 ]\n",
      " [538.45044]\n",
      " [541.87604]]\n",
      "75 cost: 26913.508 hf: [[940.30505]\n",
      " [956.47217]\n",
      " [812.97485]\n",
      " [650.91315]\n",
      " [749.89355]\n",
      " [729.281  ]\n",
      " [540.1822 ]\n",
      " [543.7069 ]]\n",
      "76 cost: 26643.223 hf: [[941.7897 ]\n",
      " [958.3539 ]\n",
      " [814.7318 ]\n",
      " [652.5283 ]\n",
      " [751.56274]\n",
      " [730.9481 ]\n",
      " [541.8701 ]\n",
      " [545.494  ]]\n",
      "77 cost: 26384.055 hf: [[943.1936 ]\n",
      " [960.1549 ]\n",
      " [816.42114]\n",
      " [654.0906 ]\n",
      " [753.17004]\n",
      " [732.55505]\n",
      " [543.5159 ]\n",
      " [547.2389 ]]\n",
      "78 cost: 26135.219 hf: [[944.52   ]\n",
      " [961.87836]\n",
      " [818.0454 ]\n",
      " [655.6019 ]\n",
      " [754.71765]\n",
      " [734.10425]\n",
      " [545.1211 ]\n",
      " [548.9432 ]]\n",
      "79 cost: 25895.996 hf: [[945.7717 ]\n",
      " [963.5272 ]\n",
      " [819.60706]\n",
      " [657.0642 ]\n",
      " [756.2078 ]\n",
      " [735.59784]\n",
      " [546.68713]\n",
      " [550.6082 ]]\n",
      "80 cost: 25665.717 hf: [[946.952  ]\n",
      " [965.10425]\n",
      " [821.10864]\n",
      " [658.47943]\n",
      " [757.6429 ]\n",
      " [737.03784]\n",
      " [548.21545]\n",
      " [552.23553]]\n",
      "81 cost: 25443.762 hf: [[948.06354]\n",
      " [966.6124 ]\n",
      " [822.5523 ]\n",
      " [659.8493 ]\n",
      " [759.0248 ]\n",
      " [738.4265 ]\n",
      " [549.7075 ]\n",
      " [553.8264 ]]\n",
      "82 cost: 25229.57 hf: [[949.10895]\n",
      " [968.0542 ]\n",
      " [823.9403 ]\n",
      " [661.17554]\n",
      " [760.3557 ]\n",
      " [739.7655 ]\n",
      " [551.1645 ]\n",
      " [555.38214]]\n",
      "83 cost: 25022.602 hf: [[950.09094]\n",
      " [969.43225]\n",
      " [825.2748 ]\n",
      " [662.4597 ]\n",
      " [761.6376 ]\n",
      " [741.057  ]\n",
      " [552.58777]\n",
      " [556.90405]]\n",
      "84 cost: 24822.363 hf: [[951.012  ]\n",
      " [970.7489 ]\n",
      " [826.55774]\n",
      " [663.7036 ]\n",
      " [762.8721 ]\n",
      " [742.3026 ]\n",
      " [553.9786 ]\n",
      " [558.3934 ]]\n",
      "85 cost: 24628.414 hf: [[951.8745 ]\n",
      " [972.0066 ]\n",
      " [827.79114]\n",
      " [664.90857]\n",
      " [764.0612 ]\n",
      " [743.50415]\n",
      " [555.338  ]\n",
      " [559.85114]]\n",
      "86 cost: 24440.324 hf: [[952.6809 ]\n",
      " [973.2075 ]\n",
      " [828.97687]\n",
      " [666.07605]\n",
      " [765.20667]\n",
      " [744.6633 ]\n",
      " [556.6673 ]\n",
      " [561.27856]]\n",
      "87 cost: 24257.7 hf: [[953.4332 ]\n",
      " [974.3539 ]\n",
      " [830.1168 ]\n",
      " [667.20764]\n",
      " [766.3102 ]\n",
      " [745.7817 ]\n",
      " [557.9675 ]\n",
      " [562.6767 ]]\n",
      "88 cost: 24080.191 hf: [[954.1338 ]\n",
      " [975.4479 ]\n",
      " [831.2127 ]\n",
      " [668.30457]\n",
      " [767.37317]\n",
      " [746.86084]\n",
      " [559.2397 ]\n",
      " [564.04663]]\n",
      "89 cost: 23907.469 hf: [[954.78467]\n",
      " [976.4914 ]\n",
      " [832.2662 ]\n",
      " [669.36816]\n",
      " [768.3973 ]\n",
      " [747.9022 ]\n",
      " [560.4848 ]\n",
      " [565.3893 ]]\n",
      "90 cost: 23739.209 hf: [[955.3877 ]\n",
      " [977.48645]\n",
      " [833.2788 ]\n",
      " [670.39966]\n",
      " [769.38403]\n",
      " [748.90735]\n",
      " [561.70386]\n",
      " [566.7057 ]]\n",
      "91 cost: 23575.133 hf: [[955.9449 ]\n",
      " [978.4348 ]\n",
      " [834.2523 ]\n",
      " [671.4003 ]\n",
      " [770.33484]\n",
      " [749.8775 ]\n",
      " [562.8978 ]\n",
      " [567.9967 ]]\n",
      "92 cost: 23414.979 hf: [[956.458  ]\n",
      " [979.3384 ]\n",
      " [835.18805]\n",
      " [672.3713 ]\n",
      " [771.251  ]\n",
      " [750.8141 ]\n",
      " [564.06757]\n",
      " [569.26324]]\n",
      "93 cost: 23258.496 hf: [[956.92896]\n",
      " [980.1987 ]\n",
      " [836.0875 ]\n",
      " [673.31366]\n",
      " [772.1339 ]\n",
      " [751.7184 ]\n",
      " [565.2139 ]\n",
      " [570.50616]]\n",
      "94 cost: 23105.46 hf: [[957.35925]\n",
      " [981.0177 ]\n",
      " [836.9521 ]\n",
      " [674.2285 ]\n",
      " [772.98486]\n",
      " [752.5915 ]\n",
      " [566.33777]\n",
      " [571.7263 ]]\n",
      "95 cost: 22955.668 hf: [[957.75073]\n",
      " [981.7969 ]\n",
      " [837.7831 ]\n",
      " [675.1169 ]\n",
      " [773.805  ]\n",
      " [753.43475]\n",
      " [567.43994]\n",
      " [572.92444]]\n",
      "96 cost: 22808.91 hf: [[958.10474]\n",
      " [982.5376 ]\n",
      " [838.5818 ]\n",
      " [675.9798 ]\n",
      " [774.5956 ]\n",
      " [754.2492 ]\n",
      " [568.5211 ]\n",
      " [574.10126]]\n",
      "97 cost: 22665.023 hf: [[958.423  ]\n",
      " [983.2415 ]\n",
      " [839.34937]\n",
      " [676.8182 ]\n",
      " [775.3576 ]\n",
      " [755.036  ]\n",
      " [569.58203]\n",
      " [575.2576 ]]\n",
      "98 cost: 22523.822 hf: [[958.7068 ]\n",
      " [983.91   ]\n",
      " [840.08716]\n",
      " [677.63293]\n",
      " [776.0923 ]\n",
      " [755.79614]\n",
      " [570.62354]\n",
      " [576.39417]]\n",
      "99 cost: 22385.168 hf: [[958.95764]\n",
      " [984.54443]\n",
      " [840.79614]\n",
      " [678.425  ]\n",
      " [776.8006 ]\n",
      " [756.53064]\n",
      " [571.6462 ]\n",
      " [577.5116 ]]\n",
      "100 cost: 22248.898 hf: [[959.17676]\n",
      " [985.146  ]\n",
      " [841.47754]\n",
      " [679.1952 ]\n",
      " [777.4835 ]\n",
      " [757.2405 ]\n",
      " [572.6507 ]\n",
      " [578.61053]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for step in range(101):\n",
    "        cv, hv, _ = sess.run([cost, hf, train], feed_dict={x:xdata, y:ydata})\n",
    "        print(step, \"cost:\", cv, \"hf:\", hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "#y값은 one hot 인코딩 방식으로 초기화 함...(a,b,c)중 하나를 hot하게 함...\n",
    "y_data = [[0, 0, 1],#2\n",
    "          [0, 0, 1],#2\n",
    "          [0, 0, 1],#2\n",
    "          [0, 1, 0],#1\n",
    "          [0, 1, 0],#1\n",
    "          [0, 1, 0],#1\n",
    "          [1, 0, 0],#0\n",
    "          [1, 0, 0]]#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "x = tf.placeholder(\"float\", [None,4])\n",
    "y = tf.placeholder(\"float\", [None,num_classes])\n",
    "w = tf.Variable(tf.random_normal([4,num_classes]))\n",
    "b = tf.Variable(tf.random_uniform([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.nn.softmax(tf.matmul(x,w) + b) \n",
    "# softmax함수를 쓰자! : 이렇게 하면 확률로 return됨\n",
    "# reduce_sum axis=1을 주면 행별로 더함!\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.889047\n",
      "==================================================\n",
      "200 0.9091104\n",
      "==================================================\n",
      "400 0.6618951\n",
      "==================================================\n",
      "600 0.58414507\n",
      "==================================================\n",
      "800 0.5448745\n",
      "==================================================\n",
      "1000 0.518218\n",
      "==================================================\n",
      "1200 0.4977128\n",
      "==================================================\n",
      "1400 0.4809096\n",
      "==================================================\n",
      "1600 0.466586\n",
      "==================================================\n",
      "1800 0.45403522\n",
      "==================================================\n",
      "2000 0.44281203\n",
      "==================================================\n",
      "[[0.5316965  0.4674371  0.00086634]]\n",
      "[0]\n",
      "==================================================\n",
      "[0 0 2]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(train,feed_dict={x:x_data,y:y_data})\n",
    "        if step%200==0:\n",
    "            print(step, sess.run(cost, feed_dict={x:x_data,y:y_data}))\n",
    "            print(\"=\"*50)\n",
    "    res = sess.run(hf,feed_dict={x:np.array([1,11,7,9]).reshape(1,4)})\n",
    "    print(res)\n",
    "    print(sess.run(tf.argmax(res, axis=1))) \n",
    "    # axis=1 기준으로 찾아다니면서 값이 가장 큰 놈으로 출력\n",
    "    print(\"=\"*50)\n",
    "    res2 = sess.run(hf,feed_dict={x:np.array([1,11,7,9,1,3,4,3,1,1,0,1]).reshape(-1,4)})\n",
    "    print(sess.run(tf.argmax(res2, axis=1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 17)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.loadtxt('731data/zoo.csv', delimiter=',', dtype=np.float32)\n",
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 3.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 6.],\n",
       "       [0., 1., 1., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot Tensor(\"one_hot_8:0\", shape=(?, 1, 7), dtype=float32)\n",
      "reshaped_one_hot Tensor(\"Reshape_6:0\", shape=(?, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None,16])\n",
    "y = tf.placeholder(tf.int32, [None,1])\n",
    "y_one_hot = tf.one_hot(y,7) # 3(y) => 0001000(y_one_hot)\n",
    "# tf.one_hot에 들어가는 y는 int형이어야 함!\n",
    "print(\"one_hot\", y_one_hot)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1,7])\n",
    "print(\"reshaped_one_hot\", y_one_hot)\n",
    "# one_hot 함수를 사용하면 차원이 하나 증가됨! : 주의할 점 : reshape해줘야겠다\n",
    "# [[0], [3], ..., [5]] => [None,1] => [[[1000000]], ... ,[[0000010]]] => [None,1,7]\n",
    "# 우리가 원하는 모습은 이런게 아님!\n",
    "# reshpae하면 => tf.shape(y_one_hot, [-1,7]) 코딩하면 [None,7]로 reshape됨\n",
    "\n",
    "# 0~6 : 7가지의 동물 => 분류기 7개\n",
    "# w1x1 + w2x2 + ... + w7x7 => 0번 종류의 동물에 대한 확률\n",
    "# ...\n",
    "# w1x1 + w2x2 + ... + w7x7 => 6번 종류의 동물에 대한 확률\n",
    "# 총 7개의 분류기가 만들어짐!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([16,7]))\n",
    "b = tf.Variable(tf.random_normal([7]))\n",
    "# x : [None, 16], w : [16,7]\n",
    "logit = tf.matmul(x,w) + b\n",
    "hf = tf.nn.softmax(logit)\n",
    "cost_ = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y_one_hot)\n",
    "# 요놈이 reduce_mean은 안해줌\n",
    "cost = tf.reduce_mean(cost_)\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax(hf,1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_one_hot,1))\n",
    "# correct_prediction = tf.equal(prediction, tf.cast(y,tf.int64))\n",
    "# 둘 다 됨\n",
    "# 이거 뒤에꺼 그냥 y주면 안됨?\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 cv:  3.9725056 acc:  0.13861386\n",
      "step:  1000 cv:  0.59789604 acc:  0.84158415\n",
      "step:  2000 cv:  0.38526583 acc:  0.8910891\n",
      "step:  3000 cv:  0.29626173 acc:  0.9108911\n",
      "step:  4000 cv:  0.23855709 acc:  0.9306931\n",
      "step:  5000 cv:  0.19765733 acc:  0.96039605\n",
      "step:  6000 cv:  0.16769 acc:  0.97029704\n",
      "step:  7000 cv:  0.14512414 acc:  0.97029704\n",
      "step:  8000 cv:  0.12764785 acc:  0.980198\n",
      "step:  9000 cv:  0.11375734 acc:  0.990099\n",
      "step:  10000 cv:  0.10247124 acc:  0.990099\n",
      "[0 0 3 0 0 0 0 3 3 0 0 1 3 6 6 6 1 0 3 0 1 1 0 1 5 4 4 0 0 0 5 0 0 1 3 0 0\n",
      " 1 3 5 5 1 5 1 0 0 6 0 0 0 0 5 4 6 0 0 1 1 1 1 3 3 2 0 0 0 0 0 0 0 0 1 6 3\n",
      " 0 0 2 6 1 1 2 6 3 1 0 6 3 1 5 4 1 2 3 0 0 1 0 5 0 6 1]\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 4 실제 y: 4\n",
      "[True] 예측: 4 실제 y: 4\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 4 실제 y: 4\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 2 실제 y: 2\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 2 실제 y: 2\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 2 실제 y: 2\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 4 실제 y: 4\n",
      "[False] 예측: 1 실제 y: 2\n",
      "[True] 예측: 2 실제 y: 2\n",
      "[True] 예측: 3 실제 y: 3\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 1 실제 y: 1\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 5 실제 y: 5\n",
      "[True] 예측: 0 실제 y: 0\n",
      "[True] 예측: 6 실제 y: 6\n",
      "[True] 예측: 1 실제 y: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata, y:ydata})\n",
    "        if step%1000==0:\n",
    "            cv, acc = sess.run([cost, accuracy], feed_dict={x:xdata,y:ydata})\n",
    "            print(\"step: \",step, \"cv: \",cv, \"acc: \",acc)\n",
    "# 전체 데이터로 트레이닝 수행하여 모델 생서\n",
    "# 모델에 전체 데이터를 집어넣어서 정확도 출력\n",
    "# 데이터를 분할하지 않았음\n",
    "    pred = sess.run(prediction, feed_dict={x:xdata})\n",
    "    print(pred)\n",
    "    for p, y in zip(pred, ydata.flatten()):\n",
    "        print(\"[{}] 예측: {} 실제 y: {}\".format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax_4:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'softmax_cross_entropy_with_logits_sg_3/Reshape_2:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
