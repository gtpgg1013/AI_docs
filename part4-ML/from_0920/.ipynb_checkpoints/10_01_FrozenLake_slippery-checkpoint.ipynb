{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros([env.observation_space.n, env.action_space.n]) # Q table 생성!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .75\n",
    "dis = .99\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5075\n",
      "[[6.49751331e-01 4.68968405e-03 3.09179137e-02 3.72378146e-02]\n",
      " [1.00247939e-02 2.80063062e-02 5.73646369e-04 3.52880506e-01]\n",
      " [2.32366584e-03 2.43269812e-03 1.28994514e-02 3.75365460e-01]\n",
      " [1.33273676e-03 1.10948014e-04 2.10403611e-02 4.15654695e-01]\n",
      " [5.59572326e-01 1.38923602e-04 1.60609449e-02 1.46699343e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.63740084e-02 7.40244876e-05 3.41871313e-05 4.03825840e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.03060064e-04 1.67853886e-04 7.17959873e-05 7.41804848e-01]\n",
      " [1.26803233e-03 3.44241104e-01 8.98385808e-04 2.33574167e-03]\n",
      " [8.06720836e-01 2.70914177e-04 2.43631690e-04 2.43406877e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.32077338e-03 1.47769372e-04 9.05371664e-01 8.01948120e-04]\n",
      " [7.47989364e-03 2.92058417e-04 9.55966198e-01 2.21930800e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = np.argmax(Q[state, :] + np.random.randn(1,env.action_space.n)/(i+1))\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        Q[state,action] = (1-learning_rate) * Q[state,action] \\\n",
    "        + learning_rate * (reward + dis*np.max(Q[new_state,:])) # 고집 + 새로운 갱신\n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "    rList.append(rAll)\n",
    "print(sum(rList)/num_episodes)\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandit을 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손잡이 : 4개, 밴딧(슬롯머신) : 3대\n",
    "# 각각의 밴딧은 각각의 손잡이에 대해 서로 다른 성공 확률 가짐\n",
    "# 최고의 결과를 얻어내기 위한 동작\n",
    "# 최고 결과 주는 손잡이를 항상 선택하도록 하는 방법을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contextual_bandit():\n",
    "    def __init__(self): \n",
    "        self.state = 0 # inital state 설정 (속성)\n",
    "        self.bandits = np.array([[0.2,0,-0.1,-5],[0.1,-5,1,0.25],[-5,5,5,5]]) # 슬롯 머신(밴딧 3대)\n",
    "        self.num_bandits = self.bandits.shape[0]\n",
    "        self.num_actions = self.bandits.shape[1]\n",
    "    \n",
    "    def getBandit(self):\n",
    "        self.state = np.random.randint(0, len(self.bandits))\n",
    "        return self.state\n",
    "    \n",
    "    def pullArm(self, action): # action : 레버(4개 중 당긴 레버의 번호)\n",
    "        bandit = self.bandits[self.state, action]\n",
    "        result = np.random.randn(1)\n",
    "        if result > bandit:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, lr, s_size, a_size):\n",
    "        # agent 초기화\n",
    "        self.state_in = tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "        state_in_OH = slim.one_hot_encoding(self.state_in, s_size)\n",
    "        output = slim.fully_connected(state_in_OH, a_size, biases_initializer=None,\\\n",
    "                                     activation_fn=tf.nn.sigmoid,\\\n",
    "                                      weights_initializer=tf.ones_initializer())\n",
    "        self.output = tf.reshape(output, [-1]) # 1차원으로 펼침\n",
    "        self.chosen_action = tf.argmax(self.output, 0) # 최댓값 뽑기\n",
    "        \n",
    "        self.reward_holder = tf.placeholder(shape=[1], dtype=tf.fl32)\n",
    "        self.action_holder = tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "        self.responsible_weight = tf.slice(self.output, self.action_holder, [1])\n",
    "        self.loss = -(tf.log(self.responsible_weight)*self.reward_holder)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "        self.update = optimizer.minimize(self.loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_inputs = tf.placeholder(tf.float32, [None,None,None,1])\n",
    "net_outputs = tf.placeholder(tf.float32, [None,None,None,1])\n",
    "w = tf.Variable(tf.random_normal([11,11,1,10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "net = tf.nn.conv2d(net_inputs, filter=w, strides=[1,4,4,1], padding='SAME')\n",
    "net = tf.nn.bias_add(net, b)\n",
    "net = tf.nn.relu(net)\n",
    "\n",
    "# 2nd layer\n",
    "w = tf.Variable(tf.random_normal([5,5,10,20]))\n",
    "net = tf.nn.conv2d(net, filter=w, strides=[1,2,2,1], padding='SAME')\n",
    "net = tf.nn.relu(net)\n",
    "\n",
    "# 3rd layer\n",
    "w = tf.Variable(tf.random_normal([3,3,20,50]))\n",
    "net = tf.nn.conv2d(net, filter=w, strides=[1,2,2,1], padding='SAME')\n",
    "net = tf.nn.relu(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'fully_connected/weights:0' shape=(3, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable:0' shape=(11, 11, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(5, 5, 10, 20) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(3, 3, 20, 50) dtype=float32_ref>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'fully_connected/weights:0' shape=(3, 4) dtype=float32_ref>\n",
      "<tf.Variable 'Variable:0' shape=(11, 11, 1, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_2:0' shape=(5, 5, 10, 20) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_3:0' shape=(3, 3, 20, 50) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "train_var = [var for var in tf.trainable_variables()]\n",
    "for tv in train_var:\n",
    "    print(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'begin' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-336388e809b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcBandit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContextual_bandit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmyAgent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcBandit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_bandits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcBandit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-0f8c44df7328>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lr, s_size, a_size)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponsible_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_holder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponsible_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_holder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[1;34m(input_, begin, size, name)\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m   \"\"\"\n\u001b[1;32m--> 733\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(input, begin, size, name)\u001b[0m\n\u001b[0;32m  10486\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10487\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m> 10488\u001b[1;33m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[0m\u001b[0;32m  10489\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10490\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    624\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    625\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'begin' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "tf.reset_default_graph()\n",
    "cBandit = Contextual_bandit()\n",
    "myAgent = Agent(lr=0.001, s_size=cBandit.num_bandits, a_size=cBandit.num_actions)\n",
    "weights = tf.trainable_variables()[0]\n",
    "\n",
    "total_episodes = 10000\n",
    "total_reward = np.zeros([cBandit.num_bandits, cBandit.num_actions])\n",
    "e = 0.1\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    i = 0\n",
    "    while i < total_episodes:\n",
    "        s = cBandit.getBandit()\n",
    "        if np.random.rand(1) < e:\n",
    "            action = np.random.randint(cBandit.num_actions)\n",
    "        else:\n",
    "            action = sess.run(myAgent.chosen_action, feed_dict={myAgent.state_in:[s]})\n",
    "        reward = cBandit.pullArm(action)\n",
    "        feed_dict = {myAgent.reward:[reward], myAgent.action_holder:[action],\\\n",
    "                    maAgent.state_in:[s]}\n",
    "        _, ww = sess.run([myAgent.update, weights], feed_dict=feed_dict)\n",
    "        \n",
    "        total_reward[s, action] += reward\n",
    "        if i%500==0:\n",
    "            print(\"각 보상의 평균 : \"+str(cBandit.num_bandits) + \" 밴딧\"\\\n",
    "                  +str(np.mean(total_reward, axis=1)))\n",
    "        i += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
