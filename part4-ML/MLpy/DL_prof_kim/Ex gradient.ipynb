{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0 w :  [[0.67453223 0.7061008 ]]\n",
      "cost :  0.065107286\n",
      "step :  2000 w :  [[0.00546749 0.99759483]]\n",
      "cost :  4.288551e-06\n",
      "step :  4000 w :  [[4.5207114e-05 9.9998027e-01]]\n",
      "cost :  2.9158778e-10\n",
      "step :  6000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "step :  8000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "step :  10000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "step :  12000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "step :  14000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "step :  16000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "step :  18000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "step :  20000 w :  [[4.3508462e-06 9.9999785e-01]]\n",
      "cost :  3.0695446e-12\n",
      "[[199.99957]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "# 회귀모델 (hf=wx+b)\n",
    "## 그래프 생성 부분\n",
    "xtrain = np.array([[1,1,1],[1,2,3]]) # 하나당 하나의 b까지 포함\n",
    "ytrain = np.array([1,2,3]).reshape(1,-1)\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[2,None])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[1,None])\n",
    "# b = tf.Variable(tf.random_uniform([1,1]), name='bias') # 이렇게 해야 2차원으로 만들어지네!\n",
    "w = tf.Variable(tf.random_uniform([1,2]), name='weight')\n",
    "hf = tf.matmul(w,x)\n",
    "cost = tf.reduce_mean(tf.square(hf-y))\n",
    "# 해봤듯이, 만약 직접 구현해보고 싶으면 grad = tf.reduce_mean((hf-ytrain)*x) 해서 for문 돌리면됨\n",
    "# 아 reduce_mean을 하면 row/col 별로 mean을 계산하기 때문에 차원이 줄어드는(reduce)구나!\n",
    "\n",
    "# opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "# train = opt.minimize(cost)\n",
    "\n",
    "## 최적화기 생성 부분\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "## 그래프 실행 부분\n",
    "sess = tf.Session() # 세션 생성\n",
    "sess.run(tf.global_variables_initializer()) # 변수 초기화\n",
    "\n",
    "for step in range(20001):\n",
    "    sess.run([cost, w, train], feed_dict = {x:xtrain, y:ytrain})\n",
    "    if step%2000==0:\n",
    "        print(\"step : \",step, \"w : \",sess.run(w))\n",
    "        print(\"cost : \",sess.run(cost,feed_dict={x:xtrain, y:ytrain}))\n",
    "\n",
    "print(sess.run(hf,feed_dict={x:[[1],[200]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0 w :  [[0.6154371  0.64510995]]\n",
      "cost :  0.11397234\n",
      "gradient:  -0.3142114\n",
      "step :  2000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  4000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  6000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  8000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  10000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  12000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  14000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  16000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  18000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "step :  20000 w :  [[0.6804402  0.71011305]]\n",
      "cost :  0.07311905\n",
      "gradient:  -2.9802322e-05\n",
      "[[136.79816]]\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)\n",
    "## 그래프 생성 부분\n",
    "xtrain = np.array([[1,2,3],[1,1,1]]) # 하나당 하나의 b까지 포함\n",
    "ytrain = np.array([1,2,3]).reshape(1,-1)\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[2,None]) \n",
    "y = tf.placeholder(dtype=tf.float32, shape=[1,None])\n",
    "# b = tf.Variable(tf.random_uniform([1,1]), name='bias') # 이렇게 해야 2차원으로 만들어지네!\n",
    "w = tf.Variable(tf.random_uniform([1,2]), name='weight')\n",
    "hf = tf.matmul(w,x)\n",
    "cost = tf.reduce_mean(tf.square(hf-y))\n",
    "\n",
    "lr = 0.001\n",
    "gradient = tf.reduce_mean((hf-y)*x) # 요기가 잘못!!! 위의 한줄만 곱해줘야!!\n",
    "descent = w - lr*gradient\n",
    "update = w.assign(descent)\n",
    "\n",
    "## 최적화기 생성 부분\n",
    "\n",
    "# train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "## 그래프 실행 부분\n",
    "sess = tf.Session() # 세션 생성\n",
    "sess.run(tf.global_variables_initializer()) # 변수 초기화\n",
    "\n",
    "for step in range(20001):\n",
    "    sess.run([cost, w, update], feed_dict = {x:xtrain, y:ytrain})\n",
    "    if step%2000==0:\n",
    "        print(\"step : \",step, \"w : \",sess.run(w))\n",
    "        print(\"cost : \",sess.run(cost,feed_dict={x:xtrain, y:ytrain}))\n",
    "        print(\"gradient: \",sess.run(gradient,feed_dict={x:xtrain, y:ytrain}))\n",
    "\n",
    "print(sess.run(hf,feed_dict={x:[[200],[1]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
