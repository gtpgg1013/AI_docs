# 2019/05/27

- 이번주 : 구문에 대해서 positive / negative 감성분석
  - 개인 프로젝트(목/금 진행)
- 문서 분류 : feature 추출 후 그것을 이용해 베이지안 필터기 / 회귀 분석 모델(분류기)을 만듬
  - 그리고 그 분류기 이용해 예측
- 추후 챗봇 : 각 관심분야가 다양할 것
  - 그냥 일상 대화 / 의학 QNA / 은행 등등
    - 각 챗봇 만들기 위해 필요만 문자 및 단어 / 문장 / 문서 집합 : corpus
- 문서 변환
  - 문서를 직접 모델링 못함
    - 숫자로 모델링 하기 위해 : Vector Space Model 사용
  - 통일성 및 노이즈 제거 위해 전처리 과정 필요
    - 문장 부호 제거
    - 모두 소문자로
    - 불용어(stop word) 제거
    - 어근 추출 등의 전처리 작업
- 복습 
  - tm_map(corpus, 적용함수, 파라미터)

- KoNLP 패키지(R) 잘 안될경우

  - KoNLP 가장먼저 로드 후, 나머지 패키지 로드
  - 안되면 JAVA PATH설정 (그냥 path 혹은 JAVA_HOME 이름으로 환경변수 생성)
  - Rstudio에서 Sys.setenv함수로도 설정 가능

- 한국어와 영어의 차이

  - 분석 단위 - 영어 : 띄어쓰기 / 한국어 : 조사
    - 영어 : I am a boy => 4개
    - 한국어 : 나는 소년입니다 => 띄어쓰기 : 2개, 품사를 기준으로 단어를 구분
  - 처리 단위
    - 공란, 특수문자, 숫자, 불용어, 대소문자 통일, 어근 동일화, 엔그램
    - 한국어 불용어 사전은 따로 없어서 따로 만들어야 함...
    - 어근 동일화도 없다 : 일반적으로 한국어는 명사 추출로 대신함

- 전처리 과정

  - 한국어
  - 영어

- 머신러닝 알고리즘

  - K-means 알고리즘
    - 목표 : 각 그룹에 대한 중심점을 얻어내는 것
    - 클러스터링 / centroid 이동 : 수렴까지 반복
    - 문제점 : 초기 위치 설정에 따라 결론 바뀔 수 있다
    - sns 결과로 한번 해보자
      - 40차원(컬럼수)의 점들이 30000개 가량 있다!
      - 요거를 비슷한 놈들끼리 묶어보자
    - DTM이긴한데 전체 아니라 많이 나온거 위주로 한 자료
    - 결과가 나올텐데 그 해석은 분석가가 해야 함!
    - 클러스터 그룹 몇개 만들어야함?
      - 엘보우 기법
        - MSE ~ cluster 개수 : 적절한 cluster개수 선정! : 팍 꺾이는 elbow지점

- PCA : 주성분분석

- 한국어 조사분류기가 제대로 안된다...?

  - 이거 딥러닝으로 제대로 해낼 수 있는 방법이 없나?

- 추가자료

  - <https://archive.ics.uci.edu/ml/index.php> : dataset 얻을 수 있는 site

    